{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8oZVDM7dtSP"
   },
   "source": [
    "# Telecom Churn - ML Group Case Study\n",
    "\n",
    "##### By: Nisha Kumar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Business Problem Overview\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    " \n",
    "\n",
    "For many incumbent operators, retaining high profitable customers is the number one business goal.\n",
    " \n",
    " \n",
    "\n",
    "To reduce customer churn, telecom companies need to predict which customers are at high risk of churn.\n",
    "\n",
    " \n",
    "\n",
    "In this project, you will analyse customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn and identify the main indicators of churn.\n",
    "\n",
    "###### Definitions of Churn\n",
    "There are various ways to define churn, such as: 1. Revenue-based churn   2.Usage-based churn\n",
    "\n",
    "For this project, you will use the **usage-based** definition to define churn.\n",
    "\n",
    "**Usage-based churn:** Customers who have not done any usage, either incoming or outgoing - in terms of calls, internet etc. over a period of time.\n",
    "A potential shortcoming of this definition is that when the customer has stopped using the services for a while, it may be too late to take any corrective actions to retain them. For e.g., if you define churn based on a ‘two-months zero usage’ period, predicting churn could be useless since by that time the customer would have already switched to another operator. \n",
    "\n",
    "###### business objective:\n",
    "The business objective is to predict the churn in the last (i.e. the ninth) month using the data (features) from the first three months. To do this task well, understanding the typical customer behaviour during churn will be helpful.\n",
    "\n",
    "Filename: telecom_churn_data_v1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbR1PWaxdtSR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn=pd.read_csv(\"/Users/nisha/Downloads/telecom_churn_data_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "KXQEyrnpHV3j",
    "outputId": "47c768ad-a75e-45af-f5b7-a9b672ac46ba",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_9</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>fb_user_9</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>197.385</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>968</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7001865778</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>34.047</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001625959</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>167.690</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7001204172</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>221.338</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000142493</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>261.636</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0     7000842753        109             0.0             0.0             0.0   \n",
       "1     7001865778        109             0.0             0.0             0.0   \n",
       "2     7001625959        109             0.0             0.0             0.0   \n",
       "3     7001204172        109             0.0             0.0             0.0   \n",
       "4     7000142493        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   \n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  last_date_of_month_9   arpu_6  ...  sachet_3g_9  fb_user_6  fb_user_7  \\\n",
       "0            9/30/2014  197.385  ...            0        1.0        1.0   \n",
       "1            9/30/2014   34.047  ...            0        NaN        1.0   \n",
       "2            9/30/2014  167.690  ...            0        NaN        NaN   \n",
       "3            9/30/2014  221.338  ...            0        NaN        NaN   \n",
       "4            9/30/2014  261.636  ...            0        0.0        NaN   \n",
       "\n",
       "   fb_user_8  fb_user_9   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  sep_vbc_3g  \n",
       "0        1.0        NaN   968        30.4         0.0      101.20        3.58  \n",
       "1        1.0        NaN  1006         0.0         0.0        0.00        0.00  \n",
       "2        NaN        1.0  1103         0.0         0.0        4.17        0.00  \n",
       "3        NaN        NaN  2491         0.0         0.0        0.00        0.00  \n",
       "4        NaN        NaN  1526         0.0         0.0        0.00        0.00  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RlB1ewCDHj12",
    "outputId": "ab0e6276-9d55-4c2f-ef38-482556a58887"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99999, 226)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Handling missing data*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Missing Values more than 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with more than 50% missing values:  40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date_of_last_rech_data_6    74.85\n",
       "date_of_last_rech_data_7    74.43\n",
       "date_of_last_rech_data_8    73.66\n",
       "date_of_last_rech_data_9    74.08\n",
       "total_rech_data_6           74.85\n",
       "total_rech_data_7           74.43\n",
       "total_rech_data_8           73.66\n",
       "total_rech_data_9           74.08\n",
       "max_rech_data_6             74.85\n",
       "max_rech_data_7             74.43\n",
       "max_rech_data_8             73.66\n",
       "max_rech_data_9             74.08\n",
       "count_rech_2g_6             74.85\n",
       "count_rech_2g_7             74.43\n",
       "count_rech_2g_8             73.66\n",
       "count_rech_2g_9             74.08\n",
       "count_rech_3g_6             74.85\n",
       "count_rech_3g_7             74.43\n",
       "count_rech_3g_8             73.66\n",
       "count_rech_3g_9             74.08\n",
       "av_rech_amt_data_6          74.85\n",
       "av_rech_amt_data_7          74.43\n",
       "av_rech_amt_data_8          73.66\n",
       "av_rech_amt_data_9          74.08\n",
       "arpu_3g_6                   74.85\n",
       "arpu_3g_7                   74.43\n",
       "arpu_3g_8                   73.66\n",
       "arpu_3g_9                   74.08\n",
       "arpu_2g_6                   74.85\n",
       "arpu_2g_7                   74.43\n",
       "arpu_2g_8                   73.66\n",
       "arpu_2g_9                   74.08\n",
       "night_pck_user_6            74.85\n",
       "night_pck_user_7            74.43\n",
       "night_pck_user_8            73.66\n",
       "night_pck_user_9            74.08\n",
       "fb_user_6                   74.85\n",
       "fb_user_7                   74.43\n",
       "fb_user_8                   73.66\n",
       "fb_user_9                   74.08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing=round(100*churn.isnull().sum()/len(churn),2)\n",
    "print(\"Columns with more than 50% missing values: \",len(missing.loc[missing>50]))\n",
    "missing.loc[missing>50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Imputing with 0 for few missing values*****\n",
    "Out the these 40 features, many are required and are essential for analysis. The missing values for these features seems to suggest that these customers KPI's did not have any value at that month. We can choose to impute these values with 0 to make enable these features to give value to analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bwzuxqJEdtS5"
   },
   "outputs": [],
   "source": [
    "impute0 = ['av_rech_amt_data_6', 'arpu_2g_6', 'arpu_3g_6', 'count_rech_2g_6', 'count_rech_3g_6',\n",
    "             'max_rech_data_6', 'total_rech_data_6','fb_user_6','night_pck_user_6','av_rech_amt_data_7', 'arpu_2g_7', 'arpu_3g_7', 'count_rech_2g_7', 'count_rech_3g_7',\n",
    "             'max_rech_data_7', 'total_rech_data_7','fb_user_7','night_pck_user_7','av_rech_amt_data_8', 'arpu_2g_8', 'arpu_3g_8', 'count_rech_2g_8', 'count_rech_3g_8',\n",
    "             'max_rech_data_8', 'total_rech_data_8','fb_user_8','night_pck_user_8','av_rech_amt_data_9', 'arpu_2g_9', 'arpu_3g_9', 'count_rech_2g_9', 'count_rech_3g_9',\n",
    "             'max_rech_data_9', 'total_rech_data_9','fb_user_9','night_pck_user_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDT5K1EAdtS-"
   },
   "outputs": [],
   "source": [
    "for i in impute0:\n",
    "    churn[i].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****missing Values more than 50% after 0 imputation*******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5d1NLQZdtTF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_of_last_rech_data_6    74.85\n",
       "date_of_last_rech_data_7    74.43\n",
       "date_of_last_rech_data_8    73.66\n",
       "date_of_last_rech_data_9    74.08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing=round(100*churn.isnull().sum()/len(churn),2)\n",
    "missing.loc[missing>50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****dropping columns with more than 50% missing values****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93oMyYO_dtTP"
   },
   "outputs": [],
   "source": [
    "d=['date_of_last_rech_data_6','date_of_last_rech_data_7','date_of_last_rech_data_8','date_of_last_rech_data_9']\n",
    "churn.drop(d,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****missing values more than 2% for columns*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gGc9IlVIdtTS",
    "outputId": "cb1ae0db-5cb0-4a93-a299-623f3709b9cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values with more tha 3% missing values : 118\n"
     ]
    }
   ],
   "source": [
    "missing=round(100*churn.isnull().sum()/len(churn),2)\n",
    "miss=missing.loc[missing>2]\n",
    "miss=list(miss.index) \n",
    "print(\"Total missing values with more tha 3% missing values :\",len(miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBnJjZXkdtTc"
   },
   "outputs": [],
   "source": [
    "churn=churn[~churn[miss].isnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OMGhf1sFdtTh",
    "outputId": "9f015fe0-8f96-42f8-ff9c-410a6a84e411"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99618, 222)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ldgo2b7dtT3"
   },
   "source": [
    "*********Adding New Features:***********\n",
    "\n",
    "        total_rechg_data6=total_rech_data_6*av_rech_amt_data_6\n",
    "        1. Total rech_6=total rech_amt_6 +total rechg_data_6\n",
    "        2. Total rech_7=total rech_amt_7 +total rechg_data_7\n",
    "        3. avg rechg for 6 &7 =(Total rech_6+Total rech_7)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i2T-KSRwdtT4"
   },
   "outputs": [],
   "source": [
    "churn['rech_data_6_total']=churn['total_rech_data_6']*churn['av_rech_amt_data_6']\n",
    "churn['rech_data_7_total']=churn['total_rech_data_7']*churn['av_rech_amt_data_7']\n",
    "#churn['rech_data_8_total']=churn['total_rech_data_6']*churn['av_rech_amt_data_6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5O2bOq_sdtT8"
   },
   "outputs": [],
   "source": [
    "churn['Total rech_6']=churn['rech_data_6_total']+churn['total_rech_amt_6']\n",
    "churn['Total rech_7']=churn['rech_data_7_total']+churn['total_rech_amt_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baMOuPlfdtT_"
   },
   "outputs": [],
   "source": [
    "churn['avg_amt_6_7']=churn[['Total rech_6','Total rech_7']].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******High profitable customer******\n",
    "    finding 70th percentile and extracting data with more than 70% percentile avg recharge amount for both data & calling -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71A9It8idtUF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "amount_70th_percentile = np.percentile(churn['avg_amt_6_7'], 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8JsfyAv2dtUI",
    "outputId": "28e2ac9b-4a46-4563-83e6-89afa123b5c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479.5\n"
     ]
    }
   ],
   "source": [
    "print(amount_70th_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        ******Deriving records containing only High profitable customer in a DataFrame and resetting index *********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbSb-vvCdtUM"
   },
   "outputs": [],
   "source": [
    "hvc=churn[churn['avg_amt_6_7']>=amount_70th_percentile] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F_cnK6vOdtUQ",
    "outputId": "106895b7-e7f6-462c-de79-f842e0e21ea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29906, 227)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Total Records for High Profitable Customers= 29906********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ip_FqBfydtUY"
   },
   "outputs": [],
   "source": [
    "hvc = hvc.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "sGiuwVKudtUh",
    "outputId": "446db434-418d-43a2-95ab-2731e37eb4ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mobile_number</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>last_date_of_month_9</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>...</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>rech_data_6_total</th>\n",
       "      <th>rech_data_7_total</th>\n",
       "      <th>Total rech_6</th>\n",
       "      <th>Total rech_7</th>\n",
       "      <th>avg_amt_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000842753</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>197.385</td>\n",
       "      <td>...</td>\n",
       "      <td>968</td>\n",
       "      <td>30.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000701601</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>1069.180</td>\n",
       "      <td>...</td>\n",
       "      <td>802</td>\n",
       "      <td>57.74</td>\n",
       "      <td>19.38</td>\n",
       "      <td>18.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7001524846</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>378.721</td>\n",
       "      <td>...</td>\n",
       "      <td>315</td>\n",
       "      <td>21.03</td>\n",
       "      <td>910.65</td>\n",
       "      <td>122.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7002124215</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>514.453</td>\n",
       "      <td>...</td>\n",
       "      <td>720</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000887461</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>9/30/2014</td>\n",
       "      <td>74.350</td>\n",
       "      <td>...</td>\n",
       "      <td>604</td>\n",
       "      <td>40.45</td>\n",
       "      <td>51.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>583.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mobile_number  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0     7000842753        109             0.0             0.0             0.0   \n",
       "1     7000701601        109             0.0             0.0             0.0   \n",
       "2     7001524846        109             0.0             0.0             0.0   \n",
       "3     7002124215        109             0.0             0.0             0.0   \n",
       "4     7000887461        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   \n",
       "1            6/30/2014            7/31/2014            8/31/2014   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   \n",
       "4            6/30/2014            7/31/2014            8/31/2014   \n",
       "\n",
       "  last_date_of_month_9    arpu_6  ...  aon  aug_vbc_3g  jul_vbc_3g  \\\n",
       "0            9/30/2014   197.385  ...  968       30.40        0.00   \n",
       "1            9/30/2014  1069.180  ...  802       57.74       19.38   \n",
       "2            9/30/2014   378.721  ...  315       21.03      910.65   \n",
       "3            9/30/2014   514.453  ...  720        0.00        0.00   \n",
       "4            9/30/2014    74.350  ...  604       40.45       51.86   \n",
       "\n",
       "   jun_vbc_3g  sep_vbc_3g  rech_data_6_total  rech_data_7_total  Total rech_6  \\\n",
       "0      101.20        3.58              252.0              252.0         614.0   \n",
       "1       18.74        0.00                0.0                0.0        1580.0   \n",
       "2      122.16        0.00                0.0              354.0         437.0   \n",
       "3        0.00        0.00                0.0                0.0         600.0   \n",
       "4        0.00        0.00                0.0              712.0           0.0   \n",
       "\n",
       "   Total rech_7  avg_amt_6_7  \n",
       "0         504.0        559.0  \n",
       "1         790.0       1185.0  \n",
       "2         955.0        696.0  \n",
       "3         680.0        640.0  \n",
       "4        1166.0        583.0  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p5jarHk9dtUk"
   },
   "source": [
    "    ****finding columns with 0 variance and dropping them as they have not much significance to show any pattern********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_e2KAU-dtUl"
   },
   "outputs": [],
   "source": [
    "zero_var=hvc.var()==0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "RPz7EmrsdtUn",
    "outputId": "0a2d7ff8-e16e-45f6-866c-d34997bf8f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Index(['circle_id', 'loc_og_t2o_mou', 'std_og_t2o_mou', 'loc_ic_t2o_mou',\n",
      "       'std_og_t2c_mou_6', 'std_og_t2c_mou_7', 'std_og_t2c_mou_8',\n",
      "       'std_og_t2c_mou_9', 'std_ic_t2o_mou_6', 'std_ic_t2o_mou_7',\n",
      "       'std_ic_t2o_mou_8', 'std_ic_t2o_mou_9'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(zero_var.sum())\n",
    "zero_var1=zero_var[zero_var==1].index\n",
    "print(zero_var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5qv1wyrdtUq"
   },
   "outputs": [],
   "source": [
    "hvc.drop(zero_var1,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****Deriving and adding the churn variable using features:\n",
    "total_ic_mou_9,total_ic_mou_9,vol_2g_mb_9,vol_3g_mb_9*****\n",
    "\n",
    "****where :\n",
    "        total_ic_mou_9+total_ic_mou_9+vol_2g_mb_9+vol_3g_mb_9==0-> 1 (churned)\n",
    "    else :\n",
    "        0: not churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjFH_RoZdtU9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hvc['churn']=np.where((hvc['total_ic_mou_9']+hvc['total_og_mou_9']+ hvc['vol_2g_mb_9']+hvc['vol_3g_mb_9']==0),1,0)\n",
    "\n",
    "#hvc['churn']=hvc.apply(lambda x: 1 if ((x.total_ic_mou_9==0) and x.total_og_mou_9==0 and x.vol_2g_mb_9==0 and x.vol_3g_mb_9'==0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7QQ9wxMGdtVE",
    "outputId": "ee27c273-ae62-48e6-f2cb-5675d43f9de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Churned Customers:  2418\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Churned Customers: \",hvc['churn'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D5W5Z6DcdtVV",
    "outputId": "76ffef72-5f26-4328-aaea-e6f115841540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total % of Churned Customers:  8.09\n"
     ]
    }
   ],
   "source": [
    "print(\"Total % of Churned Customers: \" ,round(100* hvc['churn'].sum()/len(hvc),2)) # churn %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******We need to drop the above list of last month columns entirely.********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrmR5-MQdtVh"
   },
   "outputs": [],
   "source": [
    "col_9List = hvc.filter(regex=('_9')).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a5wIyLs6dtVm"
   },
   "outputs": [],
   "source": [
    "hvc.drop(col_9List, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2nX005tfdtVr",
    "outputId": "0b5ef639-830a-494e-da40-483fde0baace"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29906, 165)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Dropping some more columns*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvc.drop(['mobile_number'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvc.drop(['last_date_of_month_6','last_date_of_month_7','last_date_of_month_8'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvc.drop(['date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_8'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "CSN6B2zEdtV_",
    "outputId": "9d4b1617-b35b-42b8-d0df-975b30397ad3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>rech_data_6_total</th>\n",
       "      <th>rech_data_7_total</th>\n",
       "      <th>Total rech_6</th>\n",
       "      <th>Total rech_7</th>\n",
       "      <th>avg_amt_6_7</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197.385</td>\n",
       "      <td>214.816</td>\n",
       "      <td>213.803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>30.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.20</td>\n",
       "      <td>3.58</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1069.180</td>\n",
       "      <td>1349.850</td>\n",
       "      <td>3171.480</td>\n",
       "      <td>57.84</td>\n",
       "      <td>54.68</td>\n",
       "      <td>52.29</td>\n",
       "      <td>453.43</td>\n",
       "      <td>567.16</td>\n",
       "      <td>325.91</td>\n",
       "      <td>16.23</td>\n",
       "      <td>...</td>\n",
       "      <td>57.74</td>\n",
       "      <td>19.38</td>\n",
       "      <td>18.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>378.721</td>\n",
       "      <td>492.223</td>\n",
       "      <td>137.362</td>\n",
       "      <td>413.69</td>\n",
       "      <td>351.03</td>\n",
       "      <td>35.08</td>\n",
       "      <td>94.66</td>\n",
       "      <td>80.63</td>\n",
       "      <td>136.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>21.03</td>\n",
       "      <td>910.65</td>\n",
       "      <td>122.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>514.453</td>\n",
       "      <td>597.753</td>\n",
       "      <td>637.760</td>\n",
       "      <td>102.41</td>\n",
       "      <td>132.11</td>\n",
       "      <td>85.14</td>\n",
       "      <td>757.93</td>\n",
       "      <td>896.68</td>\n",
       "      <td>983.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.350</td>\n",
       "      <td>193.897</td>\n",
       "      <td>366.966</td>\n",
       "      <td>48.96</td>\n",
       "      <td>50.66</td>\n",
       "      <td>33.58</td>\n",
       "      <td>85.41</td>\n",
       "      <td>89.36</td>\n",
       "      <td>205.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>40.45</td>\n",
       "      <td>51.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     arpu_6    arpu_7    arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  \\\n",
       "0   197.385   214.816   213.803          NaN          NaN         0.00   \n",
       "1  1069.180  1349.850  3171.480        57.84        54.68        52.29   \n",
       "2   378.721   492.223   137.362       413.69       351.03        35.08   \n",
       "3   514.453   597.753   637.760       102.41       132.11        85.14   \n",
       "4    74.350   193.897   366.966        48.96        50.66        33.58   \n",
       "\n",
       "   offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  ...  aug_vbc_3g  \\\n",
       "0           NaN           NaN          0.00            NaN  ...       30.40   \n",
       "1        453.43        567.16        325.91          16.23  ...       57.74   \n",
       "2         94.66         80.63        136.48           0.00  ...       21.03   \n",
       "3        757.93        896.68        983.39           0.00  ...        0.00   \n",
       "4         85.41         89.36        205.89           0.00  ...       40.45   \n",
       "\n",
       "   jul_vbc_3g  jun_vbc_3g  sep_vbc_3g  rech_data_6_total  rech_data_7_total  \\\n",
       "0        0.00      101.20        3.58              252.0              252.0   \n",
       "1       19.38       18.74        0.00                0.0                0.0   \n",
       "2      910.65      122.16        0.00                0.0              354.0   \n",
       "3        0.00        0.00        0.00                0.0                0.0   \n",
       "4       51.86        0.00        0.00                0.0              712.0   \n",
       "\n",
       "   Total rech_6  Total rech_7  avg_amt_6_7  churn  \n",
       "0         614.0         504.0        559.0      1  \n",
       "1        1580.0         790.0       1185.0      1  \n",
       "2         437.0         955.0        696.0      0  \n",
       "3         600.0         680.0        640.0      0  \n",
       "4           0.0        1166.0        583.0      0  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHwlHV4OdtWX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from fancyimpute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EYedChalTRQj",
    "outputId": "70f9855d-cb6f-4437-e21c-64b4d57e9470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing=round(100*hvc.isnull().sum()/len(hvc),2)\n",
    "miss=missing.loc[missing>3]\n",
    "miss=list(miss.index) \n",
    "len(miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Using Iterative Imputer to impute columns with more than 3% missing values********\n",
    "    Note- Iterative Imputer used only for a chunk of columns as it was making the system very slow and it was done in parts due to performance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMzlL50oY9uq"
   },
   "outputs": [],
   "source": [
    "temp=hvc[['total_rech_num_6', 'total_rech_num_7', 'total_rech_num_8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UTQyIKJdtWt"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_columns = temp.columns\n",
    "ii = IterativeImputer()\n",
    "dftemp= pd.DataFrame(ii.fit_transform(temp))\n",
    "dftemp.columns=df_columns\n",
    "hvc[['total_rech_num_6', 'total_rech_num_7', 'total_rech_num_8']]=dftemp[['total_rech_num_6', 'total_rech_num_7', 'total_rech_num_8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Kx7hrvfea5aF",
    "outputId": "65dc88d7-2396-4de0-95dc-f76669942c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['onnet_mou_8', 'offnet_mou_8', 'roam_ic_mou_8', 'roam_og_mou_8', 'loc_og_t2t_mou_8', 'loc_og_t2m_mou_8', 'loc_og_t2f_mou_8', 'loc_og_t2c_mou_8', 'loc_og_mou_8', 'std_og_t2t_mou_8', 'std_og_t2m_mou_8', 'std_og_t2f_mou_8', 'std_og_mou_8', 'isd_og_mou_8', 'spl_og_mou_8', 'og_others_8', 'loc_ic_t2t_mou_8', 'loc_ic_t2m_mou_8', 'loc_ic_t2f_mou_8', 'loc_ic_mou_8', 'std_ic_t2t_mou_8', 'std_ic_t2m_mou_8', 'std_ic_t2f_mou_8', 'std_ic_mou_8', 'spl_ic_mou_8', 'isd_ic_mou_8', 'ic_others_8']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(29906, 158)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for i in list(df_clean.columns):\n",
    " # hvc[i]=df_clean[i]\n",
    "missing=round(100*hvc.isnull().sum()/len(hvc),2)\n",
    "miss=missing.loc[missing>3]\n",
    "miss=list(miss.index) \n",
    "len(miss)\n",
    "print(miss)\n",
    "hvc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Iterative Imputation for more columns***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "otVOiVZ6iJno",
    "outputId": "9e2f93e5-e268-48d4-b309-0f58b35c1870"
   },
   "outputs": [],
   "source": [
    "temp2=hvc[['onnet_mou_8', 'offnet_mou_8', 'roam_ic_mou_8', 'roam_og_mou_8', 'loc_og_t2t_mou_8',\n",
    "           'loc_og_t2m_mou_8', 'loc_og_t2f_mou_8', 'loc_og_t2c_mou_8', 'loc_og_mou_8', 'std_og_t2t_mou_8', \n",
    "           'std_og_t2m_mou_8', 'std_og_t2f_mou_8', 'std_og_mou_8', 'isd_og_mou_8', 'spl_og_mou_8', 'og_others_8', \n",
    "           'loc_ic_t2t_mou_8', 'loc_ic_t2m_mou_8', 'loc_ic_t2f_mou_8', 'loc_ic_mou_8', 'std_ic_t2t_mou_8', \n",
    "           'std_ic_t2m_mou_8', 'std_ic_t2f_mou_8', 'std_ic_mou_8', 'spl_ic_mou_8', 'isd_ic_mou_8', 'ic_others_8']]\n",
    "df_columns = temp2.columns    \n",
    "ii = IterativeImputer()\n",
    "dftemp2= pd.DataFrame(ii.fit_transform(temp2))\n",
    "dftemp2.columns=df_columns  \n",
    "hvc[['onnet_mou_8', 'offnet_mou_8', 'roam_ic_mou_8', 'roam_og_mou_8', 'loc_og_t2t_mou_8',\n",
    "           'loc_og_t2m_mou_8', 'loc_og_t2f_mou_8', 'loc_og_t2c_mou_8', 'loc_og_mou_8', 'std_og_t2t_mou_8', \n",
    "           'std_og_t2m_mou_8', 'std_og_t2f_mou_8', 'std_og_mou_8', 'isd_og_mou_8', 'spl_og_mou_8', 'og_others_8', \n",
    "           'loc_ic_t2t_mou_8', 'loc_ic_t2m_mou_8', 'loc_ic_t2f_mou_8', 'loc_ic_mou_8', 'std_ic_t2t_mou_8', \n",
    "           'std_ic_t2m_mou_8', 'std_ic_t2f_mou_8', 'std_ic_mou_8', 'spl_ic_mou_8', 'isd_ic_mou_8', 'ic_others_8']]=dftemp2[['onnet_mou_8', 'offnet_mou_8', 'roam_ic_mou_8', 'roam_og_mou_8', 'loc_og_t2t_mou_8',\n",
    "           'loc_og_t2m_mou_8', 'loc_og_t2f_mou_8', 'loc_og_t2c_mou_8', 'loc_og_mou_8', 'std_og_t2t_mou_8', \n",
    "           'std_og_t2m_mou_8', 'std_og_t2f_mou_8', 'std_og_mou_8', 'isd_og_mou_8', 'spl_og_mou_8', 'og_others_8', \n",
    "           'loc_ic_t2t_mou_8', 'loc_ic_t2m_mou_8', 'loc_ic_t2f_mou_8', 'loc_ic_mou_8', 'std_ic_t2t_mou_8', \n",
    "           'std_ic_t2m_mou_8', 'std_ic_t2f_mou_8', 'std_ic_mou_8', 'spl_ic_mou_8', 'isd_ic_mou_8', 'ic_others_8']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GgZ59wfwdtWx",
    "outputId": "d63d307a-ca2c-44e2-8398-3f3299e2d35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with more than 2-3 % missing Values:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missing=round(100*hvc.isnull().sum()/len(hvc),2)\n",
    "miss=missing.loc[missing>2]\n",
    "print(\"Columns with more than 2-3 % missing Values: \",len(miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Si0ox_SblEpx",
    "outputId": "ff51d70c-de53-443b-cf81-23556b19813a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29906, 158)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zPOnAGSjlJmn",
    "outputId": "3e5ef999-4e86-475b-fa1d-183156869db1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns with missing values i.e more than 0% and less than 3%) :  54\n"
     ]
    }
   ],
   "source": [
    "missing=round(100*hvc.isnull().sum()/len(hvc),2)\n",
    "miss=missing.loc[missing>0]\n",
    "print(\"Remaining columns with missing values i.e more than 0% and less than 3%) : \",len(miss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsYTXlZkKahR"
   },
   "outputs": [],
   "source": [
    "hvc_clean=hvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****Using median Technique to impute remaining columns with missing values (less than 3%)****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OE3y2vTAsv7O",
    "outputId": "29519500-163e-4203-db9b-52c32e5c4916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values columns :  0\n"
     ]
    }
   ],
   "source": [
    "hvc_clean=hvc.fillna(hvc.mean())\n",
    "missing=round(100*hvc_clean.isnull().sum()/len(hvc_clean),2)\n",
    "miss=missing.loc[missing>0]\n",
    "print(\"Missing values columns : \" , len(miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uXt3DFawdtW7",
    "outputId": "ded98c14-3813-45a2-9ecb-d4479bd725b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29906, 158)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvc_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HrJvghYn8-z9"
   },
   "source": [
    "Looking at the problem statement, attributes total_ic_mou_9, total_og_mou_9, vol_2g_mb_9 and vol_3g_mb_9 are used to tag churners. So, it is clearly evident from the problem statement that the individual incoming and outgoing attributes are not used for data analysis. Dropping the individual columns (whose totals are already available like incoming, outgoing, arpu, etc) can help us in better analysis. Also, dropping these individual columns will help in removing the multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "taXEdlCe9LQY"
   },
   "outputs": [],
   "source": [
    "individual_cols = ['loc_ic_t2t_mou_6', 'loc_ic_t2t_mou_7', 'loc_ic_t2t_mou_8',\n",
    "                   'loc_ic_t2m_mou_6', 'loc_ic_t2m_mou_7', 'loc_ic_t2m_mou_8',\n",
    "                   'loc_ic_t2f_mou_6', 'loc_ic_t2f_mou_7', 'loc_ic_t2f_mou_8',\n",
    "                   'std_ic_t2t_mou_6', 'std_ic_t2t_mou_7', 'std_ic_t2t_mou_8',\n",
    "                   'std_ic_t2m_mou_6', 'std_ic_t2m_mou_7', 'std_ic_t2m_mou_8',\n",
    "                   'std_ic_t2f_mou_6', 'std_ic_t2f_mou_7', 'std_ic_t2f_mou_8',\n",
    "                   'loc_og_t2t_mou_6', 'loc_og_t2t_mou_7', 'loc_og_t2t_mou_8',\n",
    "                   'loc_og_t2m_mou_6', 'loc_og_t2m_mou_7', 'loc_og_t2m_mou_8',\n",
    "                   'loc_og_t2f_mou_6', 'loc_og_t2f_mou_7', 'loc_og_t2f_mou_8',\n",
    "                   'loc_og_t2c_mou_6', 'loc_og_t2c_mou_7', 'loc_og_t2c_mou_8',\n",
    "                   'std_og_t2t_mou_6', 'std_og_t2t_mou_7', 'std_og_t2t_mou_8',\n",
    "                   'std_og_t2m_mou_6', 'std_og_t2m_mou_7', 'std_og_t2m_mou_8',\n",
    "                   'std_og_t2f_mou_6', 'std_og_t2f_mou_7', 'std_og_t2f_mou_8',\n",
    "                   'last_day_rch_amt_6', 'last_day_rch_amt_7', 'last_day_rch_amt_8',\n",
    "                   'arpu_3g_6', 'arpu_3g_7', 'arpu_3g_8',\n",
    "                   'arpu_2g_6', 'arpu_2g_7', 'arpu_2g_8',\n",
    "                   'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8']\n",
    "                   \n",
    "hvc_clean.drop(individual_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SGrEd-C89bZ7",
    "outputId": "f18c0b72-bfe3-4013-ffa2-42ade9688a57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29906, 107)"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvc_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZxHID5UW95p0"
   },
   "source": [
    "Variables night_pck_user_6, night_pck_user_7, night_pck_user_8, fb_user_6, fb_user_7 and fb_user_8 are encoded with number 0 and 1. These variables can be considered as Ordered Categorical columns.\n",
    "Also, the datatype of these variables can be converted to integer.Also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sHH3DvwAIC9I"
   },
   "outputs": [],
   "source": [
    "hvc_final=hvc_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "QmtEl5TP9YJO",
    "outputId": "9fcd9480-93da-4495-8816-581b4e47c75f"
   },
   "outputs": [],
   "source": [
    "category_list = ['night_pck_user_6', 'night_pck_user_7', 'night_pck_user_8', 'fb_user_6', 'fb_user_7', 'fb_user_8']\n",
    "\n",
    "hvc_clean[category_list] = hvc_clean[category_list].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-d1334a297fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'max_rech_data_6'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_rech_data_7'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'max_rech_data_8'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "\n",
    "var = ['max_rech_data_6', 'max_rech_data_7','max_rech_data_8']\n",
    "           \n",
    "for i in enumerate(var[0:3]):\n",
    "    plt.subplot(1,3,i[0]+1)\n",
    "    sns.boxplot(x = i[1], data = hvc_clean)\n",
    "    plt.title(i[1])\n",
    "\n",
    "    'roam_og_mou_8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "\n",
    "var = ['roam_og_mou_6',  'roam_og_mou_7', 'roam_og_mou_8']\n",
    "           \n",
    "for i in enumerate(var[0:3]):\n",
    "    plt.subplot(1,3,i[0]+1)\n",
    "    sns.boxplot(x = i[1], data = hvc_clean)\n",
    "    plt.title(i[1])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29906.000000</td>\n",
       "      <td>29906.000000</td>\n",
       "      <td>29906.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.105763</td>\n",
       "      <td>20.545711</td>\n",
       "      <td>20.721445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>116.299660</td>\n",
       "      <td>96.168645</td>\n",
       "      <td>104.802679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>50.510000</td>\n",
       "      <td>31.180000</td>\n",
       "      <td>29.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>145.632500</td>\n",
       "      <td>104.470000</td>\n",
       "      <td>101.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>531.973500</td>\n",
       "      <td>438.512500</td>\n",
       "      <td>427.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3775.110000</td>\n",
       "      <td>2812.040000</td>\n",
       "      <td>5337.040000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       roam_og_mou_6  roam_og_mou_7  roam_og_mou_8\n",
       "count   29906.000000   29906.000000   29906.000000\n",
       "mean       27.105763      20.545711      20.721445\n",
       "std       116.299660      96.168645     104.802679\n",
       "min         0.000000       0.000000       0.000000\n",
       "5%          0.000000       0.000000       0.000000\n",
       "10%         0.000000       0.000000       0.000000\n",
       "25%         0.000000       0.000000       0.000000\n",
       "50%         0.000000       0.000000       0.000000\n",
       "75%         0.000000       0.000000       0.000000\n",
       "90%        50.510000      31.180000      29.025000\n",
       "95%       145.632500     104.470000     101.117500\n",
       "99%       531.973500     438.512500     427.106000\n",
       "max      3775.110000    2812.040000    5337.040000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvc_clean[['roam_og_mou_6',  'roam_og_mou_7', 'roam_og_mou_8']].describe(percentiles = [0.05,.10,.25,.50,.75,.90,.95,.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWPwnGbqEAOJ"
   },
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xmc0RZOsD97T",
    "outputId": "d3d9c8cf-8834-4a16-9677-b7f25dc7dbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29906, 107)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvc_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "colab_type": "code",
    "id": "6ug312dbIOWi",
    "outputId": "040ebe39-5744-4302-caa6-b1e7648e562b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>rech_data_6_total</th>\n",
       "      <th>rech_data_7_total</th>\n",
       "      <th>Total rech_6</th>\n",
       "      <th>Total rech_7</th>\n",
       "      <th>avg_amt_6_7</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arpu_6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673890</td>\n",
       "      <td>0.614850</td>\n",
       "      <td>0.336680</td>\n",
       "      <td>0.216372</td>\n",
       "      <td>0.189865</td>\n",
       "      <td>0.503186</td>\n",
       "      <td>0.341108</td>\n",
       "      <td>0.291456</td>\n",
       "      <td>0.124468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058837</td>\n",
       "      <td>0.055373</td>\n",
       "      <td>0.112206</td>\n",
       "      <td>0.045143</td>\n",
       "      <td>0.089110</td>\n",
       "      <td>-0.023862</td>\n",
       "      <td>0.419419</td>\n",
       "      <td>0.211270</td>\n",
       "      <td>0.368623</td>\n",
       "      <td>0.065642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_7</th>\n",
       "      <td>0.673890</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759918</td>\n",
       "      <td>0.210143</td>\n",
       "      <td>0.314374</td>\n",
       "      <td>0.261969</td>\n",
       "      <td>0.350875</td>\n",
       "      <td>0.482936</td>\n",
       "      <td>0.386513</td>\n",
       "      <td>0.091613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083545</td>\n",
       "      <td>0.102169</td>\n",
       "      <td>0.055121</td>\n",
       "      <td>0.059089</td>\n",
       "      <td>-0.013729</td>\n",
       "      <td>0.091538</td>\n",
       "      <td>0.230773</td>\n",
       "      <td>0.419401</td>\n",
       "      <td>0.384910</td>\n",
       "      <td>-0.011052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_8</th>\n",
       "      <td>0.614850</td>\n",
       "      <td>0.759918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.149375</td>\n",
       "      <td>0.228362</td>\n",
       "      <td>0.331684</td>\n",
       "      <td>0.276933</td>\n",
       "      <td>0.370811</td>\n",
       "      <td>0.505523</td>\n",
       "      <td>0.086920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146394</td>\n",
       "      <td>0.085114</td>\n",
       "      <td>0.073724</td>\n",
       "      <td>0.104801</td>\n",
       "      <td>-0.004020</td>\n",
       "      <td>0.028596</td>\n",
       "      <td>0.215430</td>\n",
       "      <td>0.295716</td>\n",
       "      <td>0.301778</td>\n",
       "      <td>-0.159777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <td>0.336680</td>\n",
       "      <td>0.210143</td>\n",
       "      <td>0.149375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750729</td>\n",
       "      <td>0.623379</td>\n",
       "      <td>0.083074</td>\n",
       "      <td>0.032867</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.022285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104990</td>\n",
       "      <td>-0.110913</td>\n",
       "      <td>-0.102253</td>\n",
       "      <td>-0.034119</td>\n",
       "      <td>-0.098787</td>\n",
       "      <td>-0.101304</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>-0.020083</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>0.077764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <td>0.216372</td>\n",
       "      <td>0.314374</td>\n",
       "      <td>0.228362</td>\n",
       "      <td>0.750729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804208</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>0.077852</td>\n",
       "      <td>0.066843</td>\n",
       "      <td>0.036976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103066</td>\n",
       "      <td>-0.108839</td>\n",
       "      <td>-0.106994</td>\n",
       "      <td>-0.033976</td>\n",
       "      <td>-0.101599</td>\n",
       "      <td>-0.099503</td>\n",
       "      <td>-0.014524</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.027333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <td>0.189865</td>\n",
       "      <td>0.261969</td>\n",
       "      <td>0.331684</td>\n",
       "      <td>0.623379</td>\n",
       "      <td>0.804208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060984</td>\n",
       "      <td>0.080573</td>\n",
       "      <td>0.117753</td>\n",
       "      <td>0.050030</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084375</td>\n",
       "      <td>-0.091661</td>\n",
       "      <td>-0.083225</td>\n",
       "      <td>-0.029142</td>\n",
       "      <td>-0.086766</td>\n",
       "      <td>-0.077776</td>\n",
       "      <td>-0.009964</td>\n",
       "      <td>0.022254</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>-0.033193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <td>0.503186</td>\n",
       "      <td>0.350875</td>\n",
       "      <td>0.276933</td>\n",
       "      <td>0.083074</td>\n",
       "      <td>0.049301</td>\n",
       "      <td>0.060984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738677</td>\n",
       "      <td>0.585810</td>\n",
       "      <td>0.045584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093339</td>\n",
       "      <td>-0.102188</td>\n",
       "      <td>-0.087114</td>\n",
       "      <td>-0.019576</td>\n",
       "      <td>-0.110378</td>\n",
       "      <td>-0.129202</td>\n",
       "      <td>0.076745</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.046484</td>\n",
       "      <td>0.071395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <td>0.341108</td>\n",
       "      <td>0.482936</td>\n",
       "      <td>0.370811</td>\n",
       "      <td>0.032867</td>\n",
       "      <td>0.077852</td>\n",
       "      <td>0.080573</td>\n",
       "      <td>0.738677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.764275</td>\n",
       "      <td>0.060886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094018</td>\n",
       "      <td>-0.103996</td>\n",
       "      <td>-0.099186</td>\n",
       "      <td>-0.021006</td>\n",
       "      <td>-0.116278</td>\n",
       "      <td>-0.122034</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.058003</td>\n",
       "      <td>0.044617</td>\n",
       "      <td>0.018751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <td>0.291456</td>\n",
       "      <td>0.386513</td>\n",
       "      <td>0.505523</td>\n",
       "      <td>0.034148</td>\n",
       "      <td>0.066843</td>\n",
       "      <td>0.117753</td>\n",
       "      <td>0.585810</td>\n",
       "      <td>0.764275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064109</td>\n",
       "      <td>-0.077817</td>\n",
       "      <td>-0.071355</td>\n",
       "      <td>-0.011492</td>\n",
       "      <td>-0.094247</td>\n",
       "      <td>-0.102169</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>0.045225</td>\n",
       "      <td>0.038824</td>\n",
       "      <td>-0.060208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <td>0.124468</td>\n",
       "      <td>0.091613</td>\n",
       "      <td>0.086920</td>\n",
       "      <td>0.022285</td>\n",
       "      <td>0.036976</td>\n",
       "      <td>0.050030</td>\n",
       "      <td>0.045584</td>\n",
       "      <td>0.060886</td>\n",
       "      <td>0.070330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>-0.027176</td>\n",
       "      <td>-0.022674</td>\n",
       "      <td>0.019186</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>0.053387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <td>0.083454</td>\n",
       "      <td>0.091537</td>\n",
       "      <td>0.075989</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>0.006666</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.040497</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>0.038735</td>\n",
       "      <td>0.510178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010751</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>-0.017023</td>\n",
       "      <td>-0.022481</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.012203</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.071773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <td>0.091067</td>\n",
       "      <td>0.090747</td>\n",
       "      <td>0.105062</td>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.034607</td>\n",
       "      <td>0.019631</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>0.055579</td>\n",
       "      <td>0.043211</td>\n",
       "      <td>0.372345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>0.018169</td>\n",
       "      <td>0.021013</td>\n",
       "      <td>0.011155</td>\n",
       "      <td>-0.015496</td>\n",
       "      <td>-0.013236</td>\n",
       "      <td>0.018222</td>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.023201</td>\n",
       "      <td>0.074465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_6</th>\n",
       "      <td>0.193622</td>\n",
       "      <td>0.132633</td>\n",
       "      <td>0.127220</td>\n",
       "      <td>0.075074</td>\n",
       "      <td>0.080194</td>\n",
       "      <td>0.096236</td>\n",
       "      <td>0.117270</td>\n",
       "      <td>0.111390</td>\n",
       "      <td>0.119896</td>\n",
       "      <td>0.645453</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014803</td>\n",
       "      <td>-0.023772</td>\n",
       "      <td>-0.012651</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>-0.039300</td>\n",
       "      <td>-0.035726</td>\n",
       "      <td>0.034844</td>\n",
       "      <td>0.015545</td>\n",
       "      <td>0.029419</td>\n",
       "      <td>0.068277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <td>0.143380</td>\n",
       "      <td>0.177333</td>\n",
       "      <td>0.139405</td>\n",
       "      <td>0.074509</td>\n",
       "      <td>0.066588</td>\n",
       "      <td>0.082141</td>\n",
       "      <td>0.100606</td>\n",
       "      <td>0.107174</td>\n",
       "      <td>0.094025</td>\n",
       "      <td>0.368852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011471</td>\n",
       "      <td>-0.013570</td>\n",
       "      <td>-0.002024</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>-0.030845</td>\n",
       "      <td>-0.032750</td>\n",
       "      <td>0.025966</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>0.035979</td>\n",
       "      <td>0.097692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <td>0.125832</td>\n",
       "      <td>0.148654</td>\n",
       "      <td>0.192735</td>\n",
       "      <td>0.072225</td>\n",
       "      <td>0.080985</td>\n",
       "      <td>0.092154</td>\n",
       "      <td>0.103231</td>\n",
       "      <td>0.117254</td>\n",
       "      <td>0.127114</td>\n",
       "      <td>0.241672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003717</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>-0.025874</td>\n",
       "      <td>-0.025653</td>\n",
       "      <td>0.025228</td>\n",
       "      <td>0.032114</td>\n",
       "      <td>0.033829</td>\n",
       "      <td>0.084833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_mou_6</th>\n",
       "      <td>0.322348</td>\n",
       "      <td>0.211648</td>\n",
       "      <td>0.205902</td>\n",
       "      <td>0.290101</td>\n",
       "      <td>0.198764</td>\n",
       "      <td>0.187931</td>\n",
       "      <td>0.371259</td>\n",
       "      <td>0.234644</td>\n",
       "      <td>0.224549</td>\n",
       "      <td>-0.045898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>-0.013418</td>\n",
       "      <td>-0.004351</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>-0.062817</td>\n",
       "      <td>-0.079649</td>\n",
       "      <td>0.055295</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.032948</td>\n",
       "      <td>-0.052634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_mou_7</th>\n",
       "      <td>0.246894</td>\n",
       "      <td>0.296860</td>\n",
       "      <td>0.258626</td>\n",
       "      <td>0.221321</td>\n",
       "      <td>0.300140</td>\n",
       "      <td>0.251068</td>\n",
       "      <td>0.279074</td>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.283808</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001325</td>\n",
       "      <td>-0.016297</td>\n",
       "      <td>-0.015214</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>-0.069777</td>\n",
       "      <td>-0.079741</td>\n",
       "      <td>0.024651</td>\n",
       "      <td>0.030920</td>\n",
       "      <td>0.032779</td>\n",
       "      <td>-0.079922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <td>0.227920</td>\n",
       "      <td>0.245504</td>\n",
       "      <td>0.327574</td>\n",
       "      <td>0.187777</td>\n",
       "      <td>0.232229</td>\n",
       "      <td>0.324027</td>\n",
       "      <td>0.248762</td>\n",
       "      <td>0.265343</td>\n",
       "      <td>0.368019</td>\n",
       "      <td>0.023215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011171</td>\n",
       "      <td>-0.002409</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>-0.059874</td>\n",
       "      <td>-0.067938</td>\n",
       "      <td>0.027429</td>\n",
       "      <td>0.026041</td>\n",
       "      <td>0.031450</td>\n",
       "      <td>-0.095708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_mou_6</th>\n",
       "      <td>0.380325</td>\n",
       "      <td>0.247334</td>\n",
       "      <td>0.148494</td>\n",
       "      <td>0.625309</td>\n",
       "      <td>0.466829</td>\n",
       "      <td>0.383590</td>\n",
       "      <td>0.591512</td>\n",
       "      <td>0.435050</td>\n",
       "      <td>0.319757</td>\n",
       "      <td>-0.040799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150109</td>\n",
       "      <td>-0.151163</td>\n",
       "      <td>-0.140634</td>\n",
       "      <td>-0.044266</td>\n",
       "      <td>-0.115355</td>\n",
       "      <td>-0.121710</td>\n",
       "      <td>0.028658</td>\n",
       "      <td>-0.026319</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.133404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_mou_7</th>\n",
       "      <td>0.230870</td>\n",
       "      <td>0.375422</td>\n",
       "      <td>0.254126</td>\n",
       "      <td>0.447699</td>\n",
       "      <td>0.623831</td>\n",
       "      <td>0.505982</td>\n",
       "      <td>0.425998</td>\n",
       "      <td>0.616311</td>\n",
       "      <td>0.456904</td>\n",
       "      <td>0.019192</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148175</td>\n",
       "      <td>-0.150983</td>\n",
       "      <td>-0.147738</td>\n",
       "      <td>-0.044472</td>\n",
       "      <td>-0.120745</td>\n",
       "      <td>-0.117962</td>\n",
       "      <td>-0.026494</td>\n",
       "      <td>0.023851</td>\n",
       "      <td>-0.000944</td>\n",
       "      <td>0.066927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_og_mou_8</th>\n",
       "      <td>0.185396</td>\n",
       "      <td>0.297237</td>\n",
       "      <td>0.386341</td>\n",
       "      <td>0.371508</td>\n",
       "      <td>0.504859</td>\n",
       "      <td>0.635303</td>\n",
       "      <td>0.334641</td>\n",
       "      <td>0.477418</td>\n",
       "      <td>0.626756</td>\n",
       "      <td>0.038110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120592</td>\n",
       "      <td>-0.127412</td>\n",
       "      <td>-0.122329</td>\n",
       "      <td>-0.036101</td>\n",
       "      <td>-0.098945</td>\n",
       "      <td>-0.093760</td>\n",
       "      <td>-0.022330</td>\n",
       "      <td>0.020713</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>-0.029261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og_mou_6</th>\n",
       "      <td>0.467276</td>\n",
       "      <td>0.417040</td>\n",
       "      <td>0.394498</td>\n",
       "      <td>-0.015336</td>\n",
       "      <td>-0.013289</td>\n",
       "      <td>-0.012673</td>\n",
       "      <td>0.079478</td>\n",
       "      <td>0.067643</td>\n",
       "      <td>0.072824</td>\n",
       "      <td>-0.004199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>-0.003644</td>\n",
       "      <td>-0.005227</td>\n",
       "      <td>-0.002427</td>\n",
       "      <td>-0.007013</td>\n",
       "      <td>-0.010088</td>\n",
       "      <td>0.157708</td>\n",
       "      <td>0.130690</td>\n",
       "      <td>0.169390</td>\n",
       "      <td>0.014769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og_mou_7</th>\n",
       "      <td>0.421577</td>\n",
       "      <td>0.508579</td>\n",
       "      <td>0.437533</td>\n",
       "      <td>-0.015835</td>\n",
       "      <td>-0.014553</td>\n",
       "      <td>-0.013856</td>\n",
       "      <td>0.073679</td>\n",
       "      <td>0.073803</td>\n",
       "      <td>0.074465</td>\n",
       "      <td>-0.004972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005649</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>-0.000431</td>\n",
       "      <td>-0.005092</td>\n",
       "      <td>-0.004867</td>\n",
       "      <td>0.146122</td>\n",
       "      <td>0.168829</td>\n",
       "      <td>0.185621</td>\n",
       "      <td>0.007721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <td>0.414536</td>\n",
       "      <td>0.451791</td>\n",
       "      <td>0.453813</td>\n",
       "      <td>-0.013748</td>\n",
       "      <td>-0.012626</td>\n",
       "      <td>-0.012247</td>\n",
       "      <td>0.073955</td>\n",
       "      <td>0.071155</td>\n",
       "      <td>0.081030</td>\n",
       "      <td>-0.004194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>-0.000176</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>-0.006368</td>\n",
       "      <td>-0.007860</td>\n",
       "      <td>0.141694</td>\n",
       "      <td>0.145378</td>\n",
       "      <td>0.168983</td>\n",
       "      <td>-0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_og_mou_6</th>\n",
       "      <td>0.118770</td>\n",
       "      <td>0.065878</td>\n",
       "      <td>0.098316</td>\n",
       "      <td>0.095789</td>\n",
       "      <td>0.059666</td>\n",
       "      <td>0.051958</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.073708</td>\n",
       "      <td>0.056568</td>\n",
       "      <td>-0.034164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023900</td>\n",
       "      <td>-0.018095</td>\n",
       "      <td>-0.007365</td>\n",
       "      <td>0.056729</td>\n",
       "      <td>0.014470</td>\n",
       "      <td>-0.001882</td>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.016609</td>\n",
       "      <td>0.039672</td>\n",
       "      <td>0.027645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_og_mou_7</th>\n",
       "      <td>0.068735</td>\n",
       "      <td>0.110754</td>\n",
       "      <td>0.121643</td>\n",
       "      <td>0.077070</td>\n",
       "      <td>0.107708</td>\n",
       "      <td>0.077222</td>\n",
       "      <td>0.075367</td>\n",
       "      <td>0.119898</td>\n",
       "      <td>0.082519</td>\n",
       "      <td>-0.014753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027527</td>\n",
       "      <td>-0.022858</td>\n",
       "      <td>-0.031948</td>\n",
       "      <td>0.051836</td>\n",
       "      <td>-0.004683</td>\n",
       "      <td>0.010451</td>\n",
       "      <td>0.016995</td>\n",
       "      <td>0.043766</td>\n",
       "      <td>0.036082</td>\n",
       "      <td>0.010153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_og_mou_8</th>\n",
       "      <td>0.046421</td>\n",
       "      <td>0.064293</td>\n",
       "      <td>0.097303</td>\n",
       "      <td>0.082996</td>\n",
       "      <td>0.105796</td>\n",
       "      <td>0.127393</td>\n",
       "      <td>0.065514</td>\n",
       "      <td>0.084474</td>\n",
       "      <td>0.114476</td>\n",
       "      <td>-0.009229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015868</td>\n",
       "      <td>-0.022958</td>\n",
       "      <td>-0.023981</td>\n",
       "      <td>0.012238</td>\n",
       "      <td>-0.009517</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.022298</td>\n",
       "      <td>0.017398</td>\n",
       "      <td>-0.028154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others_6</th>\n",
       "      <td>0.052782</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.012253</td>\n",
       "      <td>0.053046</td>\n",
       "      <td>0.027321</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.055392</td>\n",
       "      <td>0.021966</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>-0.019817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030539</td>\n",
       "      <td>-0.030552</td>\n",
       "      <td>-0.025342</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-0.006544</td>\n",
       "      <td>0.016666</td>\n",
       "      <td>-0.000532</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>0.012481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others_7</th>\n",
       "      <td>0.024368</td>\n",
       "      <td>0.025880</td>\n",
       "      <td>0.015584</td>\n",
       "      <td>-0.000705</td>\n",
       "      <td>-0.000591</td>\n",
       "      <td>-0.002038</td>\n",
       "      <td>0.017252</td>\n",
       "      <td>0.015775</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002346</td>\n",
       "      <td>0.014771</td>\n",
       "      <td>-0.002395</td>\n",
       "      <td>-0.002010</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.005715</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.014177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others_8</th>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.017519</td>\n",
       "      <td>0.011764</td>\n",
       "      <td>-0.003387</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>-0.001835</td>\n",
       "      <td>0.015516</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004139</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>-0.002292</td>\n",
       "      <td>-0.002647</td>\n",
       "      <td>-0.001566</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.009364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <td>0.084933</td>\n",
       "      <td>0.117680</td>\n",
       "      <td>0.188343</td>\n",
       "      <td>-0.093900</td>\n",
       "      <td>-0.090389</td>\n",
       "      <td>-0.073101</td>\n",
       "      <td>-0.094915</td>\n",
       "      <td>-0.091956</td>\n",
       "      <td>-0.064168</td>\n",
       "      <td>-0.003603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607443</td>\n",
       "      <td>0.456221</td>\n",
       "      <td>0.423872</td>\n",
       "      <td>0.125203</td>\n",
       "      <td>0.309842</td>\n",
       "      <td>0.378411</td>\n",
       "      <td>0.306932</td>\n",
       "      <td>0.381113</td>\n",
       "      <td>0.405807</td>\n",
       "      <td>-0.085102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night_pck_user_6</th>\n",
       "      <td>0.014175</td>\n",
       "      <td>-0.003247</td>\n",
       "      <td>-0.006162</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.005046</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>-0.026592</td>\n",
       "      <td>-0.025932</td>\n",
       "      <td>-0.023007</td>\n",
       "      <td>-0.014131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021766</td>\n",
       "      <td>0.037178</td>\n",
       "      <td>0.044075</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>0.140656</td>\n",
       "      <td>0.085861</td>\n",
       "      <td>0.131738</td>\n",
       "      <td>0.075632</td>\n",
       "      <td>0.121353</td>\n",
       "      <td>0.005391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night_pck_user_7</th>\n",
       "      <td>-0.004990</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>-0.004581</td>\n",
       "      <td>0.008456</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>-0.021878</td>\n",
       "      <td>-0.022014</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>-0.010533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021912</td>\n",
       "      <td>0.032082</td>\n",
       "      <td>0.024341</td>\n",
       "      <td>0.031148</td>\n",
       "      <td>0.082313</td>\n",
       "      <td>0.113460</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.105001</td>\n",
       "      <td>0.104705</td>\n",
       "      <td>-0.008069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night_pck_user_8</th>\n",
       "      <td>0.009710</td>\n",
       "      <td>0.018681</td>\n",
       "      <td>0.028719</td>\n",
       "      <td>0.017073</td>\n",
       "      <td>0.035554</td>\n",
       "      <td>0.042438</td>\n",
       "      <td>-0.018077</td>\n",
       "      <td>-0.012334</td>\n",
       "      <td>-0.007030</td>\n",
       "      <td>-0.008439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>0.024607</td>\n",
       "      <td>0.028259</td>\n",
       "      <td>0.031567</td>\n",
       "      <td>0.092708</td>\n",
       "      <td>0.102164</td>\n",
       "      <td>0.086691</td>\n",
       "      <td>0.098310</td>\n",
       "      <td>0.109012</td>\n",
       "      <td>-0.021455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_2g_6</th>\n",
       "      <td>-0.038854</td>\n",
       "      <td>-0.081154</td>\n",
       "      <td>-0.053042</td>\n",
       "      <td>-0.107206</td>\n",
       "      <td>-0.112395</td>\n",
       "      <td>-0.098526</td>\n",
       "      <td>-0.109347</td>\n",
       "      <td>-0.110408</td>\n",
       "      <td>-0.090085</td>\n",
       "      <td>-0.025372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150748</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.175155</td>\n",
       "      <td>0.019381</td>\n",
       "      <td>0.042556</td>\n",
       "      <td>-0.012720</td>\n",
       "      <td>0.024107</td>\n",
       "      <td>-0.041163</td>\n",
       "      <td>-0.010830</td>\n",
       "      <td>-0.054739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <td>-0.083853</td>\n",
       "      <td>-0.033438</td>\n",
       "      <td>-0.039188</td>\n",
       "      <td>-0.115068</td>\n",
       "      <td>-0.113961</td>\n",
       "      <td>-0.098440</td>\n",
       "      <td>-0.114120</td>\n",
       "      <td>-0.106342</td>\n",
       "      <td>-0.083210</td>\n",
       "      <td>-0.020620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170981</td>\n",
       "      <td>0.175767</td>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.024214</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.031754</td>\n",
       "      <td>-0.028090</td>\n",
       "      <td>0.017493</td>\n",
       "      <td>-0.005683</td>\n",
       "      <td>-0.073520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <td>-0.060908</td>\n",
       "      <td>-0.048144</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>-0.098770</td>\n",
       "      <td>-0.097434</td>\n",
       "      <td>-0.083134</td>\n",
       "      <td>-0.100682</td>\n",
       "      <td>-0.095830</td>\n",
       "      <td>-0.072166</td>\n",
       "      <td>-0.024196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195279</td>\n",
       "      <td>0.153328</td>\n",
       "      <td>0.129570</td>\n",
       "      <td>0.030955</td>\n",
       "      <td>0.015693</td>\n",
       "      <td>0.011974</td>\n",
       "      <td>-0.009074</td>\n",
       "      <td>-0.006771</td>\n",
       "      <td>-0.009297</td>\n",
       "      <td>-0.095108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <td>-0.158860</td>\n",
       "      <td>-0.183455</td>\n",
       "      <td>-0.153765</td>\n",
       "      <td>-0.131772</td>\n",
       "      <td>-0.133487</td>\n",
       "      <td>-0.115298</td>\n",
       "      <td>-0.167161</td>\n",
       "      <td>-0.172215</td>\n",
       "      <td>-0.147839</td>\n",
       "      <td>-0.051518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026222</td>\n",
       "      <td>-0.023466</td>\n",
       "      <td>-0.011924</td>\n",
       "      <td>0.042172</td>\n",
       "      <td>0.484129</td>\n",
       "      <td>0.333220</td>\n",
       "      <td>0.381097</td>\n",
       "      <td>0.236042</td>\n",
       "      <td>0.361416</td>\n",
       "      <td>-0.003537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_2g_7</th>\n",
       "      <td>-0.194322</td>\n",
       "      <td>-0.151892</td>\n",
       "      <td>-0.137655</td>\n",
       "      <td>-0.130825</td>\n",
       "      <td>-0.122059</td>\n",
       "      <td>-0.106287</td>\n",
       "      <td>-0.171403</td>\n",
       "      <td>-0.162097</td>\n",
       "      <td>-0.141450</td>\n",
       "      <td>-0.038938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028526</td>\n",
       "      <td>-0.023943</td>\n",
       "      <td>-0.036653</td>\n",
       "      <td>0.040735</td>\n",
       "      <td>0.303771</td>\n",
       "      <td>0.529522</td>\n",
       "      <td>0.205465</td>\n",
       "      <td>0.424441</td>\n",
       "      <td>0.373352</td>\n",
       "      <td>-0.035858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <td>-0.152365</td>\n",
       "      <td>-0.132728</td>\n",
       "      <td>-0.075097</td>\n",
       "      <td>-0.108251</td>\n",
       "      <td>-0.100140</td>\n",
       "      <td>-0.080992</td>\n",
       "      <td>-0.137208</td>\n",
       "      <td>-0.132938</td>\n",
       "      <td>-0.111367</td>\n",
       "      <td>-0.033265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007237</td>\n",
       "      <td>-0.024463</td>\n",
       "      <td>-0.032786</td>\n",
       "      <td>0.054278</td>\n",
       "      <td>0.278180</td>\n",
       "      <td>0.366574</td>\n",
       "      <td>0.196976</td>\n",
       "      <td>0.284510</td>\n",
       "      <td>0.284411</td>\n",
       "      <td>-0.091650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <td>0.176918</td>\n",
       "      <td>0.084529</td>\n",
       "      <td>0.089644</td>\n",
       "      <td>-0.081778</td>\n",
       "      <td>-0.084249</td>\n",
       "      <td>-0.072342</td>\n",
       "      <td>-0.070679</td>\n",
       "      <td>-0.078621</td>\n",
       "      <td>-0.057707</td>\n",
       "      <td>0.007745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325545</td>\n",
       "      <td>0.360464</td>\n",
       "      <td>0.455146</td>\n",
       "      <td>0.060111</td>\n",
       "      <td>0.398873</td>\n",
       "      <td>0.231922</td>\n",
       "      <td>0.419530</td>\n",
       "      <td>0.235621</td>\n",
       "      <td>0.383314</td>\n",
       "      <td>-0.010073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <td>0.081124</td>\n",
       "      <td>0.190621</td>\n",
       "      <td>0.123247</td>\n",
       "      <td>-0.082764</td>\n",
       "      <td>-0.081449</td>\n",
       "      <td>-0.067547</td>\n",
       "      <td>-0.075972</td>\n",
       "      <td>-0.071246</td>\n",
       "      <td>-0.053321</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374775</td>\n",
       "      <td>0.439869</td>\n",
       "      <td>0.345166</td>\n",
       "      <td>0.072059</td>\n",
       "      <td>0.207281</td>\n",
       "      <td>0.421464</td>\n",
       "      <td>0.211586</td>\n",
       "      <td>0.446640</td>\n",
       "      <td>0.390213</td>\n",
       "      <td>-0.037983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <td>0.103863</td>\n",
       "      <td>0.132428</td>\n",
       "      <td>0.223722</td>\n",
       "      <td>-0.075896</td>\n",
       "      <td>-0.076312</td>\n",
       "      <td>-0.059915</td>\n",
       "      <td>-0.059807</td>\n",
       "      <td>-0.058983</td>\n",
       "      <td>-0.032930</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456782</td>\n",
       "      <td>0.377455</td>\n",
       "      <td>0.345977</td>\n",
       "      <td>0.106559</td>\n",
       "      <td>0.188509</td>\n",
       "      <td>0.256571</td>\n",
       "      <td>0.203518</td>\n",
       "      <td>0.275729</td>\n",
       "      <td>0.282908</td>\n",
       "      <td>-0.073910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <td>-0.002547</td>\n",
       "      <td>-0.027453</td>\n",
       "      <td>-0.022386</td>\n",
       "      <td>-0.053433</td>\n",
       "      <td>-0.053765</td>\n",
       "      <td>-0.046420</td>\n",
       "      <td>-0.073810</td>\n",
       "      <td>-0.075328</td>\n",
       "      <td>-0.062354</td>\n",
       "      <td>-0.021888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053220</td>\n",
       "      <td>0.066110</td>\n",
       "      <td>0.064912</td>\n",
       "      <td>0.060095</td>\n",
       "      <td>0.450369</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.405456</td>\n",
       "      <td>0.263459</td>\n",
       "      <td>0.391923</td>\n",
       "      <td>0.010633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <td>-0.025182</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>-0.045542</td>\n",
       "      <td>-0.050519</td>\n",
       "      <td>-0.038532</td>\n",
       "      <td>-0.074925</td>\n",
       "      <td>-0.071883</td>\n",
       "      <td>-0.059542</td>\n",
       "      <td>-0.020747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052626</td>\n",
       "      <td>0.064118</td>\n",
       "      <td>0.051939</td>\n",
       "      <td>0.048534</td>\n",
       "      <td>0.320127</td>\n",
       "      <td>0.490771</td>\n",
       "      <td>0.279535</td>\n",
       "      <td>0.446405</td>\n",
       "      <td>0.429234</td>\n",
       "      <td>-0.001350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <td>-0.017355</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.045390</td>\n",
       "      <td>-0.045178</td>\n",
       "      <td>-0.039826</td>\n",
       "      <td>-0.033782</td>\n",
       "      <td>-0.059028</td>\n",
       "      <td>-0.057853</td>\n",
       "      <td>-0.039847</td>\n",
       "      <td>-0.016293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061566</td>\n",
       "      <td>0.049681</td>\n",
       "      <td>0.046142</td>\n",
       "      <td>0.052378</td>\n",
       "      <td>0.284393</td>\n",
       "      <td>0.359136</td>\n",
       "      <td>0.250173</td>\n",
       "      <td>0.324138</td>\n",
       "      <td>0.338873</td>\n",
       "      <td>-0.036830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_user_6</th>\n",
       "      <td>-0.120347</td>\n",
       "      <td>-0.184654</td>\n",
       "      <td>-0.130863</td>\n",
       "      <td>-0.265405</td>\n",
       "      <td>-0.271157</td>\n",
       "      <td>-0.236517</td>\n",
       "      <td>-0.285018</td>\n",
       "      <td>-0.301294</td>\n",
       "      <td>-0.247799</td>\n",
       "      <td>-0.051568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280191</td>\n",
       "      <td>0.294317</td>\n",
       "      <td>0.321850</td>\n",
       "      <td>0.085589</td>\n",
       "      <td>0.301843</td>\n",
       "      <td>0.251926</td>\n",
       "      <td>0.225828</td>\n",
       "      <td>0.158614</td>\n",
       "      <td>0.225423</td>\n",
       "      <td>-0.053756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_user_7</th>\n",
       "      <td>-0.197370</td>\n",
       "      <td>-0.117756</td>\n",
       "      <td>-0.102908</td>\n",
       "      <td>-0.275292</td>\n",
       "      <td>-0.269509</td>\n",
       "      <td>-0.235153</td>\n",
       "      <td>-0.296148</td>\n",
       "      <td>-0.287136</td>\n",
       "      <td>-0.241666</td>\n",
       "      <td>-0.053648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310726</td>\n",
       "      <td>0.326725</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.086429</td>\n",
       "      <td>0.238729</td>\n",
       "      <td>0.325181</td>\n",
       "      <td>0.140494</td>\n",
       "      <td>0.251168</td>\n",
       "      <td>0.231832</td>\n",
       "      <td>-0.099027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_user_8</th>\n",
       "      <td>-0.139852</td>\n",
       "      <td>-0.102191</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>-0.233759</td>\n",
       "      <td>-0.222089</td>\n",
       "      <td>-0.187058</td>\n",
       "      <td>-0.249844</td>\n",
       "      <td>-0.241873</td>\n",
       "      <td>-0.192539</td>\n",
       "      <td>-0.043288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342590</td>\n",
       "      <td>0.297214</td>\n",
       "      <td>0.260761</td>\n",
       "      <td>0.109160</td>\n",
       "      <td>0.230760</td>\n",
       "      <td>0.283920</td>\n",
       "      <td>0.153927</td>\n",
       "      <td>0.218585</td>\n",
       "      <td>0.220004</td>\n",
       "      <td>-0.198278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aon</th>\n",
       "      <td>0.041272</td>\n",
       "      <td>0.031618</td>\n",
       "      <td>0.070913</td>\n",
       "      <td>-0.051094</td>\n",
       "      <td>-0.058321</td>\n",
       "      <td>-0.036139</td>\n",
       "      <td>-0.007856</td>\n",
       "      <td>-0.019267</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.022115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027045</td>\n",
       "      <td>0.023627</td>\n",
       "      <td>0.017619</td>\n",
       "      <td>0.012077</td>\n",
       "      <td>-0.057057</td>\n",
       "      <td>-0.057474</td>\n",
       "      <td>-0.037432</td>\n",
       "      <td>-0.038592</td>\n",
       "      <td>-0.044753</td>\n",
       "      <td>-0.109117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <td>0.058837</td>\n",
       "      <td>0.083545</td>\n",
       "      <td>0.146394</td>\n",
       "      <td>-0.104990</td>\n",
       "      <td>-0.103066</td>\n",
       "      <td>-0.084375</td>\n",
       "      <td>-0.093339</td>\n",
       "      <td>-0.094018</td>\n",
       "      <td>-0.064109</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.697223</td>\n",
       "      <td>0.577951</td>\n",
       "      <td>0.193432</td>\n",
       "      <td>0.166218</td>\n",
       "      <td>0.225215</td>\n",
       "      <td>0.166813</td>\n",
       "      <td>0.231073</td>\n",
       "      <td>0.234931</td>\n",
       "      <td>-0.090287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <td>0.055373</td>\n",
       "      <td>0.102169</td>\n",
       "      <td>0.085114</td>\n",
       "      <td>-0.110913</td>\n",
       "      <td>-0.108839</td>\n",
       "      <td>-0.091661</td>\n",
       "      <td>-0.102188</td>\n",
       "      <td>-0.103996</td>\n",
       "      <td>-0.077817</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667496</td>\n",
       "      <td>0.149011</td>\n",
       "      <td>0.197085</td>\n",
       "      <td>0.285125</td>\n",
       "      <td>0.193573</td>\n",
       "      <td>0.290982</td>\n",
       "      <td>0.286338</td>\n",
       "      <td>-0.055117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <td>0.112206</td>\n",
       "      <td>0.055121</td>\n",
       "      <td>0.073724</td>\n",
       "      <td>-0.102253</td>\n",
       "      <td>-0.106994</td>\n",
       "      <td>-0.083225</td>\n",
       "      <td>-0.087114</td>\n",
       "      <td>-0.099186</td>\n",
       "      <td>-0.071355</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577951</td>\n",
       "      <td>0.667496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138163</td>\n",
       "      <td>0.269508</td>\n",
       "      <td>0.201935</td>\n",
       "      <td>0.277746</td>\n",
       "      <td>0.198919</td>\n",
       "      <td>0.279554</td>\n",
       "      <td>-0.030925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <td>0.045143</td>\n",
       "      <td>0.059089</td>\n",
       "      <td>0.104801</td>\n",
       "      <td>-0.034119</td>\n",
       "      <td>-0.033976</td>\n",
       "      <td>-0.029142</td>\n",
       "      <td>-0.019576</td>\n",
       "      <td>-0.021006</td>\n",
       "      <td>-0.011492</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193432</td>\n",
       "      <td>0.149011</td>\n",
       "      <td>0.138163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066609</td>\n",
       "      <td>0.076194</td>\n",
       "      <td>0.073225</td>\n",
       "      <td>0.088333</td>\n",
       "      <td>0.095258</td>\n",
       "      <td>-0.043677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rech_data_6_total</th>\n",
       "      <td>0.089110</td>\n",
       "      <td>-0.013729</td>\n",
       "      <td>-0.004020</td>\n",
       "      <td>-0.098787</td>\n",
       "      <td>-0.101599</td>\n",
       "      <td>-0.086766</td>\n",
       "      <td>-0.110378</td>\n",
       "      <td>-0.116278</td>\n",
       "      <td>-0.094247</td>\n",
       "      <td>-0.027176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166218</td>\n",
       "      <td>0.197085</td>\n",
       "      <td>0.269508</td>\n",
       "      <td>0.066609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.464224</td>\n",
       "      <td>0.934173</td>\n",
       "      <td>0.412715</td>\n",
       "      <td>0.786293</td>\n",
       "      <td>-0.009918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rech_data_7_total</th>\n",
       "      <td>-0.023862</td>\n",
       "      <td>0.091538</td>\n",
       "      <td>0.028596</td>\n",
       "      <td>-0.101304</td>\n",
       "      <td>-0.099503</td>\n",
       "      <td>-0.077776</td>\n",
       "      <td>-0.129202</td>\n",
       "      <td>-0.122034</td>\n",
       "      <td>-0.102169</td>\n",
       "      <td>-0.022674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225215</td>\n",
       "      <td>0.285125</td>\n",
       "      <td>0.201935</td>\n",
       "      <td>0.076194</td>\n",
       "      <td>0.464224</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409331</td>\n",
       "      <td>0.934690</td>\n",
       "      <td>0.797320</td>\n",
       "      <td>-0.037759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total rech_6</th>\n",
       "      <td>0.419419</td>\n",
       "      <td>0.230773</td>\n",
       "      <td>0.215430</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>-0.014524</td>\n",
       "      <td>-0.009964</td>\n",
       "      <td>0.076745</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>0.019186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166813</td>\n",
       "      <td>0.193573</td>\n",
       "      <td>0.277746</td>\n",
       "      <td>0.073225</td>\n",
       "      <td>0.934173</td>\n",
       "      <td>0.409331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443526</td>\n",
       "      <td>0.842737</td>\n",
       "      <td>0.014483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total rech_7</th>\n",
       "      <td>0.211270</td>\n",
       "      <td>0.419401</td>\n",
       "      <td>0.295716</td>\n",
       "      <td>-0.020083</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.022254</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.058003</td>\n",
       "      <td>0.045225</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231073</td>\n",
       "      <td>0.290982</td>\n",
       "      <td>0.198919</td>\n",
       "      <td>0.088333</td>\n",
       "      <td>0.412715</td>\n",
       "      <td>0.934690</td>\n",
       "      <td>0.443526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.856256</td>\n",
       "      <td>-0.039797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_amt_6_7</th>\n",
       "      <td>0.368623</td>\n",
       "      <td>0.384910</td>\n",
       "      <td>0.301778</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.046484</td>\n",
       "      <td>0.044617</td>\n",
       "      <td>0.038824</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234931</td>\n",
       "      <td>0.286338</td>\n",
       "      <td>0.279554</td>\n",
       "      <td>0.095258</td>\n",
       "      <td>0.786293</td>\n",
       "      <td>0.797320</td>\n",
       "      <td>0.842737</td>\n",
       "      <td>0.856256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <td>0.065642</td>\n",
       "      <td>-0.011052</td>\n",
       "      <td>-0.159777</td>\n",
       "      <td>0.077764</td>\n",
       "      <td>0.027333</td>\n",
       "      <td>-0.033193</td>\n",
       "      <td>0.071395</td>\n",
       "      <td>0.018751</td>\n",
       "      <td>-0.060208</td>\n",
       "      <td>0.053387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090287</td>\n",
       "      <td>-0.055117</td>\n",
       "      <td>-0.030925</td>\n",
       "      <td>-0.043677</td>\n",
       "      <td>-0.009918</td>\n",
       "      <td>-0.037759</td>\n",
       "      <td>0.014483</td>\n",
       "      <td>-0.039797</td>\n",
       "      <td>-0.015556</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     arpu_6    arpu_7    arpu_8  onnet_mou_6  onnet_mou_7  \\\n",
       "arpu_6             1.000000  0.673890  0.614850     0.336680     0.216372   \n",
       "arpu_7             0.673890  1.000000  0.759918     0.210143     0.314374   \n",
       "arpu_8             0.614850  0.759918  1.000000     0.149375     0.228362   \n",
       "onnet_mou_6        0.336680  0.210143  0.149375     1.000000     0.750729   \n",
       "onnet_mou_7        0.216372  0.314374  0.228362     0.750729     1.000000   \n",
       "onnet_mou_8        0.189865  0.261969  0.331684     0.623379     0.804208   \n",
       "offnet_mou_6       0.503186  0.350875  0.276933     0.083074     0.049301   \n",
       "offnet_mou_7       0.341108  0.482936  0.370811     0.032867     0.077852   \n",
       "offnet_mou_8       0.291456  0.386513  0.505523     0.034148     0.066843   \n",
       "roam_ic_mou_6      0.124468  0.091613  0.086920     0.022285     0.036976   \n",
       "roam_ic_mou_7      0.083454  0.091537  0.075989     0.023526     0.006666   \n",
       "roam_ic_mou_8      0.091067  0.090747  0.105062     0.043455     0.034607   \n",
       "roam_og_mou_6      0.193622  0.132633  0.127220     0.075074     0.080194   \n",
       "roam_og_mou_7      0.143380  0.177333  0.139405     0.074509     0.066588   \n",
       "roam_og_mou_8      0.125832  0.148654  0.192735     0.072225     0.080985   \n",
       "loc_og_mou_6       0.322348  0.211648  0.205902     0.290101     0.198764   \n",
       "loc_og_mou_7       0.246894  0.296860  0.258626     0.221321     0.300140   \n",
       "loc_og_mou_8       0.227920  0.245504  0.327574     0.187777     0.232229   \n",
       "std_og_mou_6       0.380325  0.247334  0.148494     0.625309     0.466829   \n",
       "std_og_mou_7       0.230870  0.375422  0.254126     0.447699     0.623831   \n",
       "std_og_mou_8       0.185396  0.297237  0.386341     0.371508     0.504859   \n",
       "isd_og_mou_6       0.467276  0.417040  0.394498    -0.015336    -0.013289   \n",
       "isd_og_mou_7       0.421577  0.508579  0.437533    -0.015835    -0.014553   \n",
       "isd_og_mou_8       0.414536  0.451791  0.453813    -0.013748    -0.012626   \n",
       "spl_og_mou_6       0.118770  0.065878  0.098316     0.095789     0.059666   \n",
       "spl_og_mou_7       0.068735  0.110754  0.121643     0.077070     0.107708   \n",
       "spl_og_mou_8       0.046421  0.064293  0.097303     0.082996     0.105796   \n",
       "og_others_6        0.052782  0.017213  0.012253     0.053046     0.027321   \n",
       "og_others_7        0.024368  0.025880  0.015584    -0.000705    -0.000591   \n",
       "og_others_8        0.015564  0.017519  0.011764    -0.003387     0.002198   \n",
       "...                     ...       ...       ...          ...          ...   \n",
       "vol_3g_mb_8        0.084933  0.117680  0.188343    -0.093900    -0.090389   \n",
       "night_pck_user_6   0.014175 -0.003247 -0.006162    -0.000391    -0.005046   \n",
       "night_pck_user_7  -0.004990  0.008788  0.004271    -0.004581     0.008456   \n",
       "night_pck_user_8   0.009710  0.018681  0.028719     0.017073     0.035554   \n",
       "monthly_2g_6      -0.038854 -0.081154 -0.053042    -0.107206    -0.112395   \n",
       "monthly_2g_7      -0.083853 -0.033438 -0.039188    -0.115068    -0.113961   \n",
       "monthly_2g_8      -0.060908 -0.048144  0.013437    -0.098770    -0.097434   \n",
       "sachet_2g_6       -0.158860 -0.183455 -0.153765    -0.131772    -0.133487   \n",
       "sachet_2g_7       -0.194322 -0.151892 -0.137655    -0.130825    -0.122059   \n",
       "sachet_2g_8       -0.152365 -0.132728 -0.075097    -0.108251    -0.100140   \n",
       "monthly_3g_6       0.176918  0.084529  0.089644    -0.081778    -0.084249   \n",
       "monthly_3g_7       0.081124  0.190621  0.123247    -0.082764    -0.081449   \n",
       "monthly_3g_8       0.103863  0.132428  0.223722    -0.075896    -0.076312   \n",
       "sachet_3g_6       -0.002547 -0.027453 -0.022386    -0.053433    -0.053765   \n",
       "sachet_3g_7       -0.025182  0.010745 -0.002303    -0.045542    -0.050519   \n",
       "sachet_3g_8       -0.017355  0.000923  0.045390    -0.045178    -0.039826   \n",
       "fb_user_6         -0.120347 -0.184654 -0.130863    -0.265405    -0.271157   \n",
       "fb_user_7         -0.197370 -0.117756 -0.102908    -0.275292    -0.269509   \n",
       "fb_user_8         -0.139852 -0.102191  0.007663    -0.233759    -0.222089   \n",
       "aon                0.041272  0.031618  0.070913    -0.051094    -0.058321   \n",
       "aug_vbc_3g         0.058837  0.083545  0.146394    -0.104990    -0.103066   \n",
       "jul_vbc_3g         0.055373  0.102169  0.085114    -0.110913    -0.108839   \n",
       "jun_vbc_3g         0.112206  0.055121  0.073724    -0.102253    -0.106994   \n",
       "sep_vbc_3g         0.045143  0.059089  0.104801    -0.034119    -0.033976   \n",
       "rech_data_6_total  0.089110 -0.013729 -0.004020    -0.098787    -0.101599   \n",
       "rech_data_7_total -0.023862  0.091538  0.028596    -0.101304    -0.099503   \n",
       "Total rech_6       0.419419  0.230773  0.215430     0.027959    -0.014524   \n",
       "Total rech_7       0.211270  0.419401  0.295716    -0.020083     0.018716   \n",
       "avg_amt_6_7        0.368623  0.384910  0.301778     0.004051     0.002871   \n",
       "churn              0.065642 -0.011052 -0.159777     0.077764     0.027333   \n",
       "\n",
       "                   onnet_mou_8  offnet_mou_6  offnet_mou_7  offnet_mou_8  \\\n",
       "arpu_6                0.189865      0.503186      0.341108      0.291456   \n",
       "arpu_7                0.261969      0.350875      0.482936      0.386513   \n",
       "arpu_8                0.331684      0.276933      0.370811      0.505523   \n",
       "onnet_mou_6           0.623379      0.083074      0.032867      0.034148   \n",
       "onnet_mou_7           0.804208      0.049301      0.077852      0.066843   \n",
       "onnet_mou_8           1.000000      0.060984      0.080573      0.117753   \n",
       "offnet_mou_6          0.060984      1.000000      0.738677      0.585810   \n",
       "offnet_mou_7          0.080573      0.738677      1.000000      0.764275   \n",
       "offnet_mou_8          0.117753      0.585810      0.764275      1.000000   \n",
       "roam_ic_mou_6         0.050030      0.045584      0.060886      0.070330   \n",
       "roam_ic_mou_7         0.018601      0.040497      0.036850      0.038735   \n",
       "roam_ic_mou_8         0.019631      0.056898      0.055579      0.043211   \n",
       "roam_og_mou_6         0.096236      0.117270      0.111390      0.119896   \n",
       "roam_og_mou_7         0.082141      0.100606      0.107174      0.094025   \n",
       "roam_og_mou_8         0.092154      0.103231      0.117254      0.127114   \n",
       "loc_og_mou_6          0.187931      0.371259      0.234644      0.224549   \n",
       "loc_og_mou_7          0.251068      0.279074      0.334004      0.283808   \n",
       "loc_og_mou_8          0.324027      0.248762      0.265343      0.368019   \n",
       "std_og_mou_6          0.383590      0.591512      0.435050      0.319757   \n",
       "std_og_mou_7          0.505982      0.425998      0.616311      0.456904   \n",
       "std_og_mou_8          0.635303      0.334641      0.477418      0.626756   \n",
       "isd_og_mou_6         -0.012673      0.079478      0.067643      0.072824   \n",
       "isd_og_mou_7         -0.013856      0.073679      0.073803      0.074465   \n",
       "isd_og_mou_8         -0.012247      0.073955      0.071155      0.081030   \n",
       "spl_og_mou_6          0.051958      0.124200      0.073708      0.056568   \n",
       "spl_og_mou_7          0.077222      0.075367      0.119898      0.082519   \n",
       "spl_og_mou_8          0.127393      0.065514      0.084474      0.114476   \n",
       "og_others_6           0.018100      0.055392      0.021966      0.013617   \n",
       "og_others_7          -0.002038      0.017252      0.015775      0.008085   \n",
       "og_others_8          -0.001835      0.015516      0.013762      0.010719   \n",
       "...                        ...           ...           ...           ...   \n",
       "vol_3g_mb_8          -0.073101     -0.094915     -0.091956     -0.064168   \n",
       "night_pck_user_6     -0.000183     -0.026592     -0.025932     -0.023007   \n",
       "night_pck_user_7      0.009328     -0.021878     -0.022014     -0.020969   \n",
       "night_pck_user_8      0.042438     -0.018077     -0.012334     -0.007030   \n",
       "monthly_2g_6         -0.098526     -0.109347     -0.110408     -0.090085   \n",
       "monthly_2g_7         -0.098440     -0.114120     -0.106342     -0.083210   \n",
       "monthly_2g_8         -0.083134     -0.100682     -0.095830     -0.072166   \n",
       "sachet_2g_6          -0.115298     -0.167161     -0.172215     -0.147839   \n",
       "sachet_2g_7          -0.106287     -0.171403     -0.162097     -0.141450   \n",
       "sachet_2g_8          -0.080992     -0.137208     -0.132938     -0.111367   \n",
       "monthly_3g_6         -0.072342     -0.070679     -0.078621     -0.057707   \n",
       "monthly_3g_7         -0.067547     -0.075972     -0.071246     -0.053321   \n",
       "monthly_3g_8         -0.059915     -0.059807     -0.058983     -0.032930   \n",
       "sachet_3g_6          -0.046420     -0.073810     -0.075328     -0.062354   \n",
       "sachet_3g_7          -0.038532     -0.074925     -0.071883     -0.059542   \n",
       "sachet_3g_8          -0.033782     -0.059028     -0.057853     -0.039847   \n",
       "fb_user_6            -0.236517     -0.285018     -0.301294     -0.247799   \n",
       "fb_user_7            -0.235153     -0.296148     -0.287136     -0.241666   \n",
       "fb_user_8            -0.187058     -0.249844     -0.241873     -0.192539   \n",
       "aon                  -0.036139     -0.007856     -0.019267      0.004592   \n",
       "aug_vbc_3g           -0.084375     -0.093339     -0.094018     -0.064109   \n",
       "jul_vbc_3g           -0.091661     -0.102188     -0.103996     -0.077817   \n",
       "jun_vbc_3g           -0.083225     -0.087114     -0.099186     -0.071355   \n",
       "sep_vbc_3g           -0.029142     -0.019576     -0.021006     -0.011492   \n",
       "rech_data_6_total    -0.086766     -0.110378     -0.116278     -0.094247   \n",
       "rech_data_7_total    -0.077776     -0.129202     -0.122034     -0.102169   \n",
       "Total rech_6         -0.009964      0.076745      0.016966      0.020232   \n",
       "Total rech_7          0.022254      0.003750      0.058003      0.045225   \n",
       "avg_amt_6_7           0.007624      0.046484      0.044617      0.038824   \n",
       "churn                -0.033193      0.071395      0.018751     -0.060208   \n",
       "\n",
       "                   roam_ic_mou_6  ...  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \\\n",
       "arpu_6                  0.124468  ...    0.058837    0.055373    0.112206   \n",
       "arpu_7                  0.091613  ...    0.083545    0.102169    0.055121   \n",
       "arpu_8                  0.086920  ...    0.146394    0.085114    0.073724   \n",
       "onnet_mou_6             0.022285  ...   -0.104990   -0.110913   -0.102253   \n",
       "onnet_mou_7             0.036976  ...   -0.103066   -0.108839   -0.106994   \n",
       "onnet_mou_8             0.050030  ...   -0.084375   -0.091661   -0.083225   \n",
       "offnet_mou_6            0.045584  ...   -0.093339   -0.102188   -0.087114   \n",
       "offnet_mou_7            0.060886  ...   -0.094018   -0.103996   -0.099186   \n",
       "offnet_mou_8            0.070330  ...   -0.064109   -0.077817   -0.071355   \n",
       "roam_ic_mou_6           1.000000  ...    0.007527   -0.002358    0.011203   \n",
       "roam_ic_mou_7           0.510178  ...    0.010751    0.010394    0.023286   \n",
       "roam_ic_mou_8           0.372345  ...    0.011619    0.018169    0.021013   \n",
       "roam_og_mou_6           0.645453  ...   -0.014803   -0.023772   -0.012651   \n",
       "roam_og_mou_7           0.368852  ...   -0.011471   -0.013570   -0.002024   \n",
       "roam_og_mou_8           0.241672  ...   -0.003717   -0.006961    0.007083   \n",
       "loc_og_mou_6           -0.045898  ...    0.000053   -0.013418   -0.004351   \n",
       "loc_og_mou_7            0.002119  ...   -0.001325   -0.016297   -0.015214   \n",
       "loc_og_mou_8            0.023215  ...    0.011171   -0.002409    0.004411   \n",
       "std_og_mou_6           -0.040799  ...   -0.150109   -0.151163   -0.140634   \n",
       "std_og_mou_7            0.019192  ...   -0.148175   -0.150983   -0.147738   \n",
       "std_og_mou_8            0.038110  ...   -0.120592   -0.127412   -0.122329   \n",
       "isd_og_mou_6           -0.004199  ...    0.002667   -0.003644   -0.005227   \n",
       "isd_og_mou_7           -0.004972  ...    0.005649    0.002205   -0.002207   \n",
       "isd_og_mou_8           -0.004194  ...    0.007993   -0.000176   -0.001402   \n",
       "spl_og_mou_6           -0.034164  ...   -0.023900   -0.018095   -0.007365   \n",
       "spl_og_mou_7           -0.014753  ...   -0.027527   -0.022858   -0.031948   \n",
       "spl_og_mou_8           -0.009229  ...   -0.015868   -0.022958   -0.023981   \n",
       "og_others_6            -0.019817  ...   -0.030539   -0.030552   -0.025342   \n",
       "og_others_7             0.000045  ...   -0.002346    0.014771   -0.002395   \n",
       "og_others_8             0.000233  ...   -0.004139    0.002513   -0.001938   \n",
       "...                          ...  ...         ...         ...         ...   \n",
       "vol_3g_mb_8            -0.003603  ...    0.607443    0.456221    0.423872   \n",
       "night_pck_user_6       -0.014131  ...    0.021766    0.037178    0.044075   \n",
       "night_pck_user_7       -0.010533  ...    0.021912    0.032082    0.024341   \n",
       "night_pck_user_8       -0.008439  ...    0.030914    0.024607    0.028259   \n",
       "monthly_2g_6           -0.025372  ...    0.150748    0.154386    0.175155   \n",
       "monthly_2g_7           -0.020620  ...    0.170981    0.175767    0.126858   \n",
       "monthly_2g_8           -0.024196  ...    0.195279    0.153328    0.129570   \n",
       "sachet_2g_6            -0.051518  ...   -0.026222   -0.023466   -0.011924   \n",
       "sachet_2g_7            -0.038938  ...   -0.028526   -0.023943   -0.036653   \n",
       "sachet_2g_8            -0.033265  ...   -0.007237   -0.024463   -0.032786   \n",
       "monthly_3g_6            0.007745  ...    0.325545    0.360464    0.455146   \n",
       "monthly_3g_7            0.004215  ...    0.374775    0.439869    0.345166   \n",
       "monthly_3g_8            0.010322  ...    0.456782    0.377455    0.345977   \n",
       "sachet_3g_6            -0.021888  ...    0.053220    0.066110    0.064912   \n",
       "sachet_3g_7            -0.020747  ...    0.052626    0.064118    0.051939   \n",
       "sachet_3g_8            -0.016293  ...    0.061566    0.049681    0.046142   \n",
       "fb_user_6              -0.051568  ...    0.280191    0.294317    0.321850   \n",
       "fb_user_7              -0.053648  ...    0.310726    0.326725    0.268500   \n",
       "fb_user_8              -0.043288  ...    0.342590    0.297214    0.260761   \n",
       "aon                     0.022115  ...    0.027045    0.023627    0.017619   \n",
       "aug_vbc_3g              0.007527  ...    1.000000    0.697223    0.577951   \n",
       "jul_vbc_3g             -0.002358  ...    0.697223    1.000000    0.667496   \n",
       "jun_vbc_3g              0.011203  ...    0.577951    0.667496    1.000000   \n",
       "sep_vbc_3g              0.006639  ...    0.193432    0.149011    0.138163   \n",
       "rech_data_6_total      -0.027176  ...    0.166218    0.197085    0.269508   \n",
       "rech_data_7_total      -0.022674  ...    0.225215    0.285125    0.201935   \n",
       "Total rech_6            0.019186  ...    0.166813    0.193573    0.277746   \n",
       "Total rech_7            0.010767  ...    0.231073    0.290982    0.198919   \n",
       "avg_amt_6_7             0.017525  ...    0.234931    0.286338    0.279554   \n",
       "churn                   0.053387  ...   -0.090287   -0.055117   -0.030925   \n",
       "\n",
       "                   sep_vbc_3g  rech_data_6_total  rech_data_7_total  \\\n",
       "arpu_6               0.045143           0.089110          -0.023862   \n",
       "arpu_7               0.059089          -0.013729           0.091538   \n",
       "arpu_8               0.104801          -0.004020           0.028596   \n",
       "onnet_mou_6         -0.034119          -0.098787          -0.101304   \n",
       "onnet_mou_7         -0.033976          -0.101599          -0.099503   \n",
       "onnet_mou_8         -0.029142          -0.086766          -0.077776   \n",
       "offnet_mou_6        -0.019576          -0.110378          -0.129202   \n",
       "offnet_mou_7        -0.021006          -0.116278          -0.122034   \n",
       "offnet_mou_8        -0.011492          -0.094247          -0.102169   \n",
       "roam_ic_mou_6        0.006639          -0.027176          -0.022674   \n",
       "roam_ic_mou_7        0.007657          -0.017023          -0.022481   \n",
       "roam_ic_mou_8        0.011155          -0.015496          -0.013236   \n",
       "roam_og_mou_6       -0.000523          -0.039300          -0.035726   \n",
       "roam_og_mou_7        0.002350          -0.030845          -0.032750   \n",
       "roam_og_mou_8        0.012732          -0.025874          -0.025653   \n",
       "loc_og_mou_6         0.002673          -0.062817          -0.079649   \n",
       "loc_og_mou_7         0.000921          -0.069777          -0.079741   \n",
       "loc_og_mou_8         0.004447          -0.059874          -0.067938   \n",
       "std_og_mou_6        -0.044266          -0.115355          -0.121710   \n",
       "std_og_mou_7        -0.044472          -0.120745          -0.117962   \n",
       "std_og_mou_8        -0.036101          -0.098945          -0.093760   \n",
       "isd_og_mou_6        -0.002427          -0.007013          -0.010088   \n",
       "isd_og_mou_7        -0.000431          -0.005092          -0.004867   \n",
       "isd_og_mou_8         0.000330          -0.006368          -0.007860   \n",
       "spl_og_mou_6         0.056729           0.014470          -0.001882   \n",
       "spl_og_mou_7         0.051836          -0.004683           0.010451   \n",
       "spl_og_mou_8         0.012238          -0.009517           0.001899   \n",
       "og_others_6          0.001688           0.000181          -0.006544   \n",
       "og_others_7         -0.002010           0.000125           0.006452   \n",
       "og_others_8         -0.002292          -0.002647          -0.001566   \n",
       "...                       ...                ...                ...   \n",
       "vol_3g_mb_8          0.125203           0.309842           0.378411   \n",
       "night_pck_user_6     0.034885           0.140656           0.085861   \n",
       "night_pck_user_7     0.031148           0.082313           0.113460   \n",
       "night_pck_user_8     0.031567           0.092708           0.102164   \n",
       "monthly_2g_6         0.019381           0.042556          -0.012720   \n",
       "monthly_2g_7         0.024214           0.003490           0.031754   \n",
       "monthly_2g_8         0.030955           0.015693           0.011974   \n",
       "sachet_2g_6          0.042172           0.484129           0.333220   \n",
       "sachet_2g_7          0.040735           0.303771           0.529522   \n",
       "sachet_2g_8          0.054278           0.278180           0.366574   \n",
       "monthly_3g_6         0.060111           0.398873           0.231922   \n",
       "monthly_3g_7         0.072059           0.207281           0.421464   \n",
       "monthly_3g_8         0.106559           0.188509           0.256571   \n",
       "sachet_3g_6          0.060095           0.450369           0.303232   \n",
       "sachet_3g_7          0.048534           0.320127           0.490771   \n",
       "sachet_3g_8          0.052378           0.284393           0.359136   \n",
       "fb_user_6            0.085589           0.301843           0.251926   \n",
       "fb_user_7            0.086429           0.238729           0.325181   \n",
       "fb_user_8            0.109160           0.230760           0.283920   \n",
       "aon                  0.012077          -0.057057          -0.057474   \n",
       "aug_vbc_3g           0.193432           0.166218           0.225215   \n",
       "jul_vbc_3g           0.149011           0.197085           0.285125   \n",
       "jun_vbc_3g           0.138163           0.269508           0.201935   \n",
       "sep_vbc_3g           1.000000           0.066609           0.076194   \n",
       "rech_data_6_total    0.066609           1.000000           0.464224   \n",
       "rech_data_7_total    0.076194           0.464224           1.000000   \n",
       "Total rech_6         0.073225           0.934173           0.409331   \n",
       "Total rech_7         0.088333           0.412715           0.934690   \n",
       "avg_amt_6_7          0.095258           0.786293           0.797320   \n",
       "churn               -0.043677          -0.009918          -0.037759   \n",
       "\n",
       "                   Total rech_6  Total rech_7  avg_amt_6_7     churn  \n",
       "arpu_6                 0.419419      0.211270     0.368623  0.065642  \n",
       "arpu_7                 0.230773      0.419401     0.384910 -0.011052  \n",
       "arpu_8                 0.215430      0.295716     0.301778 -0.159777  \n",
       "onnet_mou_6            0.027959     -0.020083     0.004051  0.077764  \n",
       "onnet_mou_7           -0.014524      0.018716     0.002871  0.027333  \n",
       "onnet_mou_8           -0.009964      0.022254     0.007624 -0.033193  \n",
       "offnet_mou_6           0.076745      0.003750     0.046484  0.071395  \n",
       "offnet_mou_7           0.016966      0.058003     0.044617  0.018751  \n",
       "offnet_mou_8           0.020232      0.045225     0.038824 -0.060208  \n",
       "roam_ic_mou_6          0.019186      0.010767     0.017525  0.053387  \n",
       "roam_ic_mou_7          0.014508      0.012203     0.015692  0.071773  \n",
       "roam_ic_mou_8          0.018222      0.021142     0.023201  0.074465  \n",
       "roam_og_mou_6          0.034844      0.015545     0.029419  0.068277  \n",
       "roam_og_mou_7          0.025966      0.034986     0.035979  0.097692  \n",
       "roam_og_mou_8          0.025228      0.032114     0.033829  0.084833  \n",
       "loc_og_mou_6           0.055295      0.001797     0.032948 -0.052634  \n",
       "loc_og_mou_7           0.024651      0.030920     0.032779 -0.079922  \n",
       "loc_og_mou_8           0.027429      0.026041     0.031450 -0.095708  \n",
       "std_og_mou_6           0.028658     -0.026319     0.000709  0.133404  \n",
       "std_og_mou_7          -0.026494      0.023851    -0.000944  0.066927  \n",
       "std_og_mou_8          -0.022330      0.020713    -0.000428 -0.029261  \n",
       "isd_og_mou_6           0.157708      0.130690     0.169390  0.014769  \n",
       "isd_og_mou_7           0.146122      0.168829     0.185621  0.007721  \n",
       "isd_og_mou_8           0.141694      0.145378     0.168983 -0.000908  \n",
       "spl_og_mou_6           0.051525      0.016609     0.039672  0.027645  \n",
       "spl_og_mou_7           0.016995      0.043766     0.036082  0.010153  \n",
       "spl_og_mou_8           0.006950      0.022298     0.017398 -0.028154  \n",
       "og_others_6            0.016666     -0.000532     0.009286  0.012481  \n",
       "og_others_7            0.005715      0.012390     0.010736  0.014177  \n",
       "og_others_8            0.000860      0.002315     0.001886  0.009364  \n",
       "...                         ...           ...          ...       ...  \n",
       "vol_3g_mb_8            0.306932      0.381113     0.405807 -0.085102  \n",
       "night_pck_user_6       0.131738      0.075632     0.121353  0.005391  \n",
       "night_pck_user_7       0.072245      0.105001     0.104705 -0.008069  \n",
       "night_pck_user_8       0.086691      0.098310     0.109012 -0.021455  \n",
       "monthly_2g_6           0.024107     -0.041163    -0.010830 -0.054739  \n",
       "monthly_2g_7          -0.028090      0.017493    -0.005683 -0.073520  \n",
       "monthly_2g_8          -0.009074     -0.006771    -0.009297 -0.095108  \n",
       "sachet_2g_6            0.381097      0.236042     0.361416 -0.003537  \n",
       "sachet_2g_7            0.205465      0.424441     0.373352 -0.035858  \n",
       "sachet_2g_8            0.196976      0.284510     0.284411 -0.091650  \n",
       "monthly_3g_6           0.419530      0.235621     0.383314 -0.010073  \n",
       "monthly_3g_7           0.211586      0.446640     0.390213 -0.037983  \n",
       "monthly_3g_8           0.203518      0.275729     0.282908 -0.073910  \n",
       "sachet_3g_6            0.405456      0.263459     0.391923  0.010633  \n",
       "sachet_3g_7            0.279535      0.446405     0.429234 -0.001350  \n",
       "sachet_3g_8            0.250173      0.324138     0.338873 -0.036830  \n",
       "fb_user_6              0.225828      0.158614     0.225423 -0.053756  \n",
       "fb_user_7              0.140494      0.251168     0.231832 -0.099027  \n",
       "fb_user_8              0.153927      0.218585     0.220004 -0.198278  \n",
       "aon                   -0.037432     -0.038592    -0.044753 -0.109117  \n",
       "aug_vbc_3g             0.166813      0.231073     0.234931 -0.090287  \n",
       "jul_vbc_3g             0.193573      0.290982     0.286338 -0.055117  \n",
       "jun_vbc_3g             0.277746      0.198919     0.279554 -0.030925  \n",
       "sep_vbc_3g             0.073225      0.088333     0.095258 -0.043677  \n",
       "rech_data_6_total      0.934173      0.412715     0.786293 -0.009918  \n",
       "rech_data_7_total      0.409331      0.934690     0.797320 -0.037759  \n",
       "Total rech_6           1.000000      0.443526     0.842737  0.014483  \n",
       "Total rech_7           0.443526      1.000000     0.856256 -0.039797  \n",
       "avg_amt_6_7            0.842737      0.856256     1.000000 -0.015556  \n",
       "churn                  0.014483     -0.039797    -0.015556  1.000000  \n",
       "\n",
       "[107 rows x 107 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvc_clean.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0vPhh9VZIU19",
    "outputId": "f1de9807-0f90-47cb-be45-ba018736c84e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x2000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "plt.figure(figsize = (25, 20))\n",
    "\n",
    "sns.heatmap(hvc_clean.corr())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****Features with high correlation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "C9xoDsKgJD3C",
    "outputId": "a2dfbbc8-9098-4798-abdb-3d54b539cafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of highly correlated features from the above plot - \n",
      "\n",
      " ['onnet_mou_8', 'loc_og_mou_7', 'loc_og_mou_8', 'isd_og_mou_7', 'isd_og_mou_8', 'total_og_mou_6', 'total_og_mou_7', 'total_og_mou_8', 'loc_ic_mou_7', 'loc_ic_mou_8', 'total_ic_mou_6', 'total_ic_mou_7', 'total_ic_mou_8', 'total_rech_amt_6', 'total_rech_amt_7', 'total_rech_amt_8', 'count_rech_2g_6', 'count_rech_2g_7', 'count_rech_2g_8', 'sachet_2g_6', 'sachet_2g_7', 'sachet_2g_8', 'sachet_3g_6', 'sachet_3g_7', 'sachet_3g_8', 'Total rech_6', 'Total rech_7', 'avg_amt_6_7']\n",
      "\n",
      "\n",
      "Total features with high correlation -  28\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = hvc_clean.corr().abs()\n",
    "\n",
    "#the matrix is symmetric so we need to extract upper triangle matrix without diagonal (k = 1)\n",
    "upper_triangle = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)))\n",
    "\n",
    "highly_correlated_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.80)]\n",
    "print(\"List of highly correlated features from the above plot - \\n\\n\", highly_correlated_features)\n",
    "print(\"\\n\\nTotal features with high correlation - \", len(highly_correlated_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3-CostBK9k7"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE for Class Imbalance \n",
    "    Deriving Train and Test Data for Model building with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "aSFpoZamLPj3",
    "outputId": "c1389434-6994-45c9-a5a9-ef50d08e4d5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nisha/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/nisha/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/nisha/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/nisha/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/nisha/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/nisha/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/nisha/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/nisha/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38483, 106)\n",
      "(38483,)\n",
      "(16493, 106)\n",
      "(16493,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X= hvc_clean.drop('churn', axis = 1)\n",
    "y = hvc_clean[['churn']]\n",
    "df_cols = X.columns\n",
    "X1=X\n",
    "y1=y\n",
    "###################\n",
    "sm = SMOTE(random_state=12, ratio = 1)\n",
    "X, y = sm.fit_sample(X, y)\n",
    "####################\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Test Data and Train data after Class Imbalance for non PCA analysis *****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>rech_data_6_total</th>\n",
       "      <th>rech_data_7_total</th>\n",
       "      <th>Total rech_6</th>\n",
       "      <th>Total rech_7</th>\n",
       "      <th>avg_amt_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1821.176000</td>\n",
       "      <td>2018.948000</td>\n",
       "      <td>2014.693</td>\n",
       "      <td>39.360000</td>\n",
       "      <td>73.33000</td>\n",
       "      <td>16.730000</td>\n",
       "      <td>264.730000</td>\n",
       "      <td>334.110000</td>\n",
       "      <td>132.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>244.00000</td>\n",
       "      <td>2658.31</td>\n",
       "      <td>1956.800000</td>\n",
       "      <td>2259.330000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>1555.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>4020.000000</td>\n",
       "      <td>3885.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317.967000</td>\n",
       "      <td>370.947000</td>\n",
       "      <td>546.528</td>\n",
       "      <td>43.910000</td>\n",
       "      <td>27.28000</td>\n",
       "      <td>62.610000</td>\n",
       "      <td>101.680000</td>\n",
       "      <td>96.890000</td>\n",
       "      <td>110.990000</td>\n",
       "      <td>5.930000</td>\n",
       "      <td>...</td>\n",
       "      <td>879.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>608.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.980000</td>\n",
       "      <td>549.687000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>265.901436</td>\n",
       "      <td>273.09219</td>\n",
       "      <td>243.971718</td>\n",
       "      <td>380.955310</td>\n",
       "      <td>385.396401</td>\n",
       "      <td>348.936043</td>\n",
       "      <td>16.436337</td>\n",
       "      <td>...</td>\n",
       "      <td>205.00000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>655.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1310.000000</td>\n",
       "      <td>655.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128.831677</td>\n",
       "      <td>34.545236</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>243.971718</td>\n",
       "      <td>5.685285</td>\n",
       "      <td>0.365635</td>\n",
       "      <td>348.936043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>320.43514</td>\n",
       "      <td>0.00</td>\n",
       "      <td>138.656642</td>\n",
       "      <td>263.027329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1510.020035</td>\n",
       "      <td>101.537547</td>\n",
       "      <td>1651.203012</td>\n",
       "      <td>142.598083</td>\n",
       "      <td>896.900548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2281.505000</td>\n",
       "      <td>2680.019</td>\n",
       "      <td>265.901436</td>\n",
       "      <td>31.78000</td>\n",
       "      <td>74.280000</td>\n",
       "      <td>380.955310</td>\n",
       "      <td>158.130000</td>\n",
       "      <td>426.060000</td>\n",
       "      <td>16.436337</td>\n",
       "      <td>...</td>\n",
       "      <td>449.00000</td>\n",
       "      <td>109.58</td>\n",
       "      <td>48.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3399.000000</td>\n",
       "      <td>1699.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        arpu_6       arpu_7    arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  \\\n",
       "0  1821.176000  2018.948000  2014.693    39.360000     73.33000    16.730000   \n",
       "1   317.967000   370.947000   546.528    43.910000     27.28000    62.610000   \n",
       "2     4.980000   549.687000     0.000   265.901436    273.09219   243.971718   \n",
       "3   128.831677    34.545236     0.000     0.000000      0.00000   243.971718   \n",
       "4     0.000000  2281.505000  2680.019   265.901436     31.78000    74.280000   \n",
       "\n",
       "   offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  ...        aon  \\\n",
       "0    264.730000    334.110000    132.660000       0.000000  ...  244.00000   \n",
       "1    101.680000     96.890000    110.990000       5.930000  ...  879.00000   \n",
       "2    380.955310    385.396401    348.936043      16.436337  ...  205.00000   \n",
       "3      5.685285      0.365635    348.936043       0.000000  ...  320.43514   \n",
       "4    380.955310    158.130000    426.060000      16.436337  ...  449.00000   \n",
       "\n",
       "   aug_vbc_3g   jul_vbc_3g   jun_vbc_3g  sep_vbc_3g  rech_data_6_total  \\\n",
       "0     2658.31  1956.800000  2259.330000         0.0        1555.000000   \n",
       "1        0.00     0.000000     0.000000         0.0         154.000000   \n",
       "2        0.00     0.000000     0.000000         0.0           0.000000   \n",
       "3        0.00   138.656642   263.027329         0.0        1510.020035   \n",
       "4      109.58    48.050000     0.000000         0.0           0.000000   \n",
       "\n",
       "   rech_data_7_total  Total rech_6  Total rech_7  avg_amt_6_7  \n",
       "0        1555.000000   3751.000000   4020.000000  3885.500000  \n",
       "1         154.000000    548.000000    668.000000   608.000000  \n",
       "2         655.000000      0.000000   1310.000000   655.000000  \n",
       "3         101.537547   1651.203012    142.598083   896.900548  \n",
       "4           0.000000      0.000000   3399.000000  1699.500000  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np=pd.DataFrame(X_train)\n",
    "X_test_np=pd.DataFrame(X_test)\n",
    "\n",
    "X_train_np.columns=df_cols\n",
    "X_test_np.columns=df_cols\n",
    "X_train_np.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>sep_vbc_3g</th>\n",
       "      <th>rech_data_6_total</th>\n",
       "      <th>rech_data_7_total</th>\n",
       "      <th>Total rech_6</th>\n",
       "      <th>Total rech_7</th>\n",
       "      <th>avg_amt_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>696.450337</td>\n",
       "      <td>457.562286</td>\n",
       "      <td>258.567499</td>\n",
       "      <td>207.236209</td>\n",
       "      <td>214.543462</td>\n",
       "      <td>60.232194</td>\n",
       "      <td>398.514540</td>\n",
       "      <td>206.141717</td>\n",
       "      <td>153.512566</td>\n",
       "      <td>21.839614</td>\n",
       "      <td>...</td>\n",
       "      <td>506.675581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.410476</td>\n",
       "      <td>756.109029</td>\n",
       "      <td>664.874933</td>\n",
       "      <td>710.491981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>499.946829</td>\n",
       "      <td>294.848224</td>\n",
       "      <td>35.588019</td>\n",
       "      <td>104.540619</td>\n",
       "      <td>117.285273</td>\n",
       "      <td>204.334766</td>\n",
       "      <td>60.601556</td>\n",
       "      <td>38.376642</td>\n",
       "      <td>244.030051</td>\n",
       "      <td>23.091637</td>\n",
       "      <td>...</td>\n",
       "      <td>513.360407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1014.444802</td>\n",
       "      <td>167.594220</td>\n",
       "      <td>1592.783534</td>\n",
       "      <td>587.247986</td>\n",
       "      <td>1090.015760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>351.471079</td>\n",
       "      <td>507.384328</td>\n",
       "      <td>144.360999</td>\n",
       "      <td>331.773562</td>\n",
       "      <td>622.016320</td>\n",
       "      <td>137.761047</td>\n",
       "      <td>215.006981</td>\n",
       "      <td>312.339813</td>\n",
       "      <td>43.525008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>355.378798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.218593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.851579</td>\n",
       "      <td>461.111316</td>\n",
       "      <td>660.331022</td>\n",
       "      <td>1058.631873</td>\n",
       "      <td>859.481447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681.953774</td>\n",
       "      <td>459.034941</td>\n",
       "      <td>192.076542</td>\n",
       "      <td>1002.189898</td>\n",
       "      <td>815.287732</td>\n",
       "      <td>65.559705</td>\n",
       "      <td>189.718892</td>\n",
       "      <td>150.244562</td>\n",
       "      <td>62.489346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>853.966522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>734.317384</td>\n",
       "      <td>503.146929</td>\n",
       "      <td>618.732156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1049.508653</td>\n",
       "      <td>8.944276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>458.837107</td>\n",
       "      <td>157.583545</td>\n",
       "      <td>243.971718</td>\n",
       "      <td>1925.545889</td>\n",
       "      <td>218.231633</td>\n",
       "      <td>348.936043</td>\n",
       "      <td>35.177682</td>\n",
       "      <td>...</td>\n",
       "      <td>1438.493349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1202.808853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>601.404427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        arpu_6      arpu_7      arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  \\\n",
       "0   696.450337  457.562286  258.567499   207.236209   214.543462    60.232194   \n",
       "1   499.946829  294.848224   35.588019   104.540619   117.285273   204.334766   \n",
       "2   351.471079  507.384328  144.360999   331.773562   622.016320   137.761047   \n",
       "3   681.953774  459.034941  192.076542  1002.189898   815.287732    65.559705   \n",
       "4  1049.508653    8.944276    0.000000   458.837107   157.583545   243.971718   \n",
       "\n",
       "   offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  ...          aon  \\\n",
       "0    398.514540    206.141717    153.512566      21.839614  ...   506.675581   \n",
       "1     60.601556     38.376642    244.030051      23.091637  ...   513.360407   \n",
       "2    215.006981    312.339813     43.525008       0.000000  ...   355.378798   \n",
       "3    189.718892    150.244562     62.489346       0.000000  ...   853.966522   \n",
       "4   1925.545889    218.231633    348.936043      35.177682  ...  1438.493349   \n",
       "\n",
       "   aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  sep_vbc_3g  rech_data_6_total  \\\n",
       "0         0.0         0.0    0.000000         0.0           0.000000   \n",
       "1         0.0         0.0    0.000000         0.0        1014.444802   \n",
       "2         0.0         0.0    3.218593         0.0         243.851579   \n",
       "3         0.0         0.0    0.000000         0.0           0.000000   \n",
       "4         0.0         0.0    0.000000         0.0           0.000000   \n",
       "\n",
       "   rech_data_7_total  Total rech_6  Total rech_7  avg_amt_6_7  \n",
       "0          17.410476    756.109029    664.874933   710.491981  \n",
       "1         167.594220   1592.783534    587.247986  1090.015760  \n",
       "2         461.111316    660.331022   1058.631873   859.481447  \n",
       "3           0.000000    734.317384    503.146929   618.732156  \n",
       "4           0.000000   1202.808853      0.000000   601.404427  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_np.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Class Imbalance rectification analysis-SMOTE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE, the shape of train_X: (38483, 106)\n",
      "After SMOTE, the shape of train_y: (38483,) \n",
      "\n",
      "After SMOTE, counts of label '1': 19206\n",
      "After SMOTE, counts of label '0': 19277\n",
      "After SMOTE, churn event rate : 49.91% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('After SMOTE, the shape of train_X: {}'.format(X_train.shape))\n",
    "print('After SMOTE, the shape of train_y: {} \\n'.format(y_train.shape))\n",
    "\n",
    "print(\"After SMOTE, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"After SMOTE, counts of label '0': {}\".format(sum(y_train==0)))\n",
    "print(\"After SMOTE, churn event rate : {}% \\n\".format(round(sum(y_train==1)/len(y_train)*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Scaling the train and test data****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NjC3vBPgMa5Y"
   },
   "outputs": [],
   "source": [
    "## Scaling the train and test data\n",
    "from sklearn.preprocessing import  StandardScaler,MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train )\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "gtQLojQma6fo",
    "outputId": "ae0955b1-0d17-49b8-9aa7-4574df0c27a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38483, 106)\n",
      "(38483,)\n",
      "(16493, 106)\n",
      "(16493,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJo2FuMhNbcL"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x852dp-xUNlX"
   },
   "source": [
    "### Applying  PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHWBiNJ4UQfJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(svd_solver='randomized', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O9tGMMM6UaRQ",
    "outputId": "df681c3b-4509-4c7b-f1e3-d6f01ff1dd71"
   },
   "outputs": [],
   "source": [
    "df_train_pca = pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.89022587e-03, -2.50511794e-03,  9.69378829e-05, ...,\n",
       "         6.67443250e-03,  9.83099398e-03,  1.25726967e-02],\n",
       "       [-3.61815507e-04,  7.32708468e-03,  1.20529630e-02, ...,\n",
       "        -1.02672092e-02,  1.09919825e-02,  2.98434794e-04],\n",
       "       [ 8.11525749e-03, -3.29775301e-03,  5.11425030e-03, ...,\n",
       "         1.00571994e-02, -1.13694603e-02, -7.45280523e-04],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  7.19172471e-16,  7.09736793e-16, ...,\n",
       "        -1.93491192e-02,  1.87884557e-01, -5.45415722e-02],\n",
       "       [ 0.00000000e+00,  4.50569278e-16,  3.16966032e-16, ...,\n",
       "        -2.30314574e-01, -4.42168570e-02, -2.24891345e-01],\n",
       "       [ 0.00000000e+00, -1.53279142e-14,  1.00951330e-14, ...,\n",
       "        -2.29319761e-01, -1.20845150e-01,  3.57059559e-01]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.66837907e-01, 1.19704697e-01, 8.22492957e-02, 4.95273077e-02,\n",
       "       2.26130403e-02, 2.12219586e-02, 1.74750400e-02, 1.22963370e-02,\n",
       "       1.09240245e-02, 7.83153702e-03, 7.59701673e-03, 7.10710946e-03,\n",
       "       6.72818491e-03, 5.34560727e-03, 5.10781548e-03, 4.19099820e-03,\n",
       "       4.05460915e-03, 3.72749497e-03, 3.52939930e-03, 3.18717919e-03,\n",
       "       2.64050086e-03, 2.46598214e-03, 2.42414772e-03, 2.25153894e-03,\n",
       "       2.16486584e-03, 1.99162160e-03, 1.72564352e-03, 1.48471235e-03,\n",
       "       1.43971461e-03, 1.34734424e-03, 1.32330640e-03, 1.23823606e-03,\n",
       "       1.14886829e-03, 1.05455835e-03, 8.82519048e-04, 8.72386531e-04,\n",
       "       7.36250124e-04, 6.63345058e-04, 6.44863749e-04, 6.16886610e-04,\n",
       "       6.02349161e-04, 5.47696522e-04, 5.34156273e-04, 5.10995852e-04,\n",
       "       4.91390294e-04, 4.36866227e-04, 4.17624336e-04, 4.08889245e-04,\n",
       "       3.94413589e-04, 3.77018776e-04, 3.47548386e-04, 3.39239137e-04,\n",
       "       2.87636686e-04, 2.72494377e-04, 2.66469768e-04, 2.56314259e-04,\n",
       "       2.44731622e-04, 2.42464295e-04, 2.33363761e-04, 2.17921553e-04,\n",
       "       2.08206014e-04, 1.90867864e-04, 1.76383245e-04, 1.66370060e-04,\n",
       "       1.58560567e-04, 1.40348875e-04, 1.11338170e-04, 1.11016816e-04,\n",
       "       1.08320622e-04, 9.77655427e-05, 9.10014500e-05, 8.41513650e-05,\n",
       "       7.82887794e-05, 7.30788259e-05, 6.67481054e-05, 6.34172521e-05,\n",
       "       5.06718614e-05, 4.29319142e-05, 4.07631848e-05, 3.83280927e-05,\n",
       "       3.26133540e-05, 3.11421873e-05, 1.03201408e-05, 7.42233005e-06,\n",
       "       5.84596283e-06, 4.25375962e-06, 3.11456268e-06, 2.48833632e-06,\n",
       "       5.00262767e-07, 2.31581771e-07, 7.33191420e-08, 1.94668116e-13,\n",
       "       1.34174545e-13, 1.13734492e-13, 1.77573757e-29, 4.03455096e-33,\n",
       "       4.03455096e-33, 4.03455096e-33, 4.03455096e-33, 4.03455096e-33,\n",
       "       4.03455096e-33, 4.03455096e-33, 4.03455096e-33, 4.03455096e-33,\n",
       "       4.03455096e-33, 2.64935969e-34])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Variance Explained- n_components derived is 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-d29b968c85f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"--\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"g\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"--\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_cumu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cumulative variance explained\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=[12,8])\n",
    "plt.vlines(x=17, ymax=1, ymin=0, colors=\"r\", linestyles=\"--\")\n",
    "plt.hlines(y=0.95, xmax=30, xmin=0, colors=\"g\", linestyles=\"--\")\n",
    "plt.plot(var_cumu)\n",
    "plt.ylabel(\"Cumulative variance explained\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Incremental PCA****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_final = IncrementalPCA(n_components=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38483, 17)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pca = pca_final.fit_transform(X_train)\n",
    "df_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tuCuUNLfXY1y",
    "outputId": "e56f36da-7124-46d3-9594-c6a354cc7517"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16493, 17)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pca = pca_final.fit_transform(X_test)\n",
    "df_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-1 -> Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Applying Logistic Regression on our principal components****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***using Class_weight=\"balanced\" for class balancing while building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tUS6hno6U0Pg"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "logistic_pca = LogisticRegression(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIurdabdV6Jn"
   },
   "outputs": [],
   "source": [
    "#Training the model on the train data\n",
    "model_pca = logistic_pca.fit(df_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_train1=model_pca.predict(df_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04721767, 0.13752496, 0.75748083, 0.86692538, 0.07924185])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_train = model_pca.predict_proba(df_train_pca)[:,1]\n",
    "pred_probs_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8jggZhqiZ5ZP",
    "outputId": "aeda56d6-5f24-48de-b682-c0ec9f727f7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72214954, 0.62116989, 0.82122323, 0.68487828, 0.75766312,\n",
       "       0.80972516, 0.24244965, 0.7275321 , 0.65553895, 0.78447575])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs_test1 = model_pca.predict(df_test_pca)\n",
    "pred_probs_test = model_pca.predict_proba(df_test_pca)[:,1]\n",
    "pred_probs_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report- Training\n",
      "Accuracy : 0.7596\n",
      "Recall/Sensitivity : 0.7853\n",
      "AUC Score (Train): 0.836468\n",
      "Precision : 0.7045039234655488\n"
     ]
    }
   ],
   "source": [
    "print (\"\\nModel Report- Training\")\n",
    "print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_train, pred_probs_train1))\n",
    "print (\"Recall/Sensitivity : %.4g\" % metrics.recall_score(y_train, pred_probs_train1))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, pred_probs_train))\n",
    "print(\"Precision : {}\".format(metrics.precision_score(y_test,pred_probs_test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Report (Test data)\n",
      "Accuracy : 0.7285515066998121\n",
      "Recall : 0.7913547452306207\n",
      "Precision : 0.7045039234655488\n"
     ]
    }
   ],
   "source": [
    "print (\"\\nEvaluation Report (Test data)\")\n",
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(y_test,pred_probs_test1)))\n",
    "print(\"Recall : {}\".format(metrics.recall_score(y_test,pred_probs_test1)))\n",
    "print(\"Precision : {}\".format(metrics.precision_score(y_test,pred_probs_test1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Evaluating the model with cut-off probability as 0.5****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_P-DKBYaAlb8"
   },
   "outputs": [],
   "source": [
    "predprob=pd.DataFrame({\"Churn\":y_train,\"Probs\":pred_probs_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "bm5L0UPRD7rR",
    "outputId": "7a3b3b9c-8c99-43cf-c0be-90bb44fb91e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.047218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.137525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.757481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.866925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.079242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn     Probs\n",
       "0      0  0.047218\n",
       "1      0  0.137525\n",
       "2      1  0.757481\n",
       "3      1  0.866925\n",
       "4      0  0.079242"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predprob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJFqo4c_EBTH"
   },
   "outputs": [],
   "source": [
    "predprob[\"Train_Predicted\"]=predprob.Probs.map(lambda x:1 if x>0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "shxt5tn3Egpg",
    "outputId": "ed7f2834-41ae-499e-b021-dfcd0e12c993"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Probs</th>\n",
       "      <th>Train_Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.047218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.137525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.757481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.866925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.079242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn     Probs  Train_Predicted\n",
       "0      0  0.047218                0\n",
       "1      0  0.137525                0\n",
       "2      1  0.757481                1\n",
       "3      1  0.866925                1\n",
       "4      0  0.079242                0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predprob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Hfz35pZ2Es_T",
    "outputId": "f3b3bc62-9c33-4abc-a3ec-70168480b93b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 0.5 as cut off probability Accuracy is 0.7615570511654497\n"
     ]
    }
   ],
   "source": [
    "print('For 0.5 as cut off probability Accuracy is', metrics.accuracy_score(predprob.Churn, predprob.Train_Predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Plotting the ROC Curve : An ROC curve demonstrates several things:\n",
    "     1. It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will  be accompanied by a decrease in specificity).\n",
    "    2.The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n",
    "    3. The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SEtxO7_wFNof"
   },
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rosHdeaXFPsi"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( predprob.Churn, predprob.Train_Predicted,\n",
    "                                         drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "O9XWdUSUFYzy",
    "outputId": "7f78a3ca-b85d-40ae-ef5d-ffd520cf4c31"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-3d3cdf78a640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdraw_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChurn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain_Predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-102-069ff4f446a6>\u001b[0m in \u001b[0;36mdraw_roc\u001b[0;34m(actual, probs)\u001b[0m\n\u001b[1;32m      3\u001b[0m                                               drop_intermediate = False )\n\u001b[1;32m      4\u001b[0m     \u001b[0mauc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ROC curve (area = %0.2f)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mauc_score\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "draw_roc(predprob.Churn, predprob.Train_Predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****The roc curve is lying in the top left corner which is a sign of a good fit.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****** Finding Optimal Cutoff Point\n",
    "Since recall or sensitivity is a much more important metrics for churn prediction. A trade off between sensitivity(or recall) and specificity is to be considered in doing so. We will try adjusting the probability threshold which shall lead to higher sensitivity or recall rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ol-lceZeF6EG"
   },
   "outputs": [],
   "source": [
    "def findOptimalCutoff(df):\n",
    "    #Function to find the optimal cutoff for classifing as churn/non-churn\n",
    "    # Let's create columns with different probability cutoffs \n",
    "    numbers = [float(x)/10 for x in range(10)]\n",
    "    for i in numbers:\n",
    "        df[i] = df.Probs.map( lambda x: 1 if x > i else 0)\n",
    "    #print(df.head())\n",
    "    \n",
    "    # Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "    cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    # TP = confusion[1,1] # true positive \n",
    "    # TN = confusion[0,0] # true negatives\n",
    "    # FP = confusion[0,1] # false positives\n",
    "    # FN = confusion[1,0] # false negatives\n",
    "    \n",
    "    num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "    for i in num:\n",
    "        cm1 = metrics.confusion_matrix(df.Churn, df[i] )\n",
    "        total1=sum(sum(cm1))\n",
    "        accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "        \n",
    "        speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "        sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "        cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "    print(cutoff_df)\n",
    "    # Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "    cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "J7dcYpIKF8im",
    "outputId": "3ae83494-6251-45f2-c0ce-ec2aa9b4e50b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prob  accuracy     sensi     speci\n",
      "0.0   0.0  0.500689  1.000000  0.000000\n",
      "0.1   0.1  0.599096  0.985935  0.211189\n",
      "0.2   0.2  0.677052  0.957858  0.395472\n",
      "0.3   0.3  0.725515  0.911459  0.539058\n",
      "0.4   0.4  0.750747  0.849439  0.651782\n",
      "0.5   0.5  0.761557  0.782126  0.740932\n",
      "0.6   0.6  0.757399  0.699294  0.815665\n",
      "0.7   0.7  0.731752  0.572192  0.891751\n",
      "0.8   0.8  0.649300  0.351048  0.948374\n",
      "0.9   0.9  0.539823  0.089682  0.991205\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "findOptimalCutoff(predprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzSdkH44Jduf"
   },
   "source": [
    "*****From the curve above, 0.52 is the optimum point*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Operations on Training set with new cut off Probability value of 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_lDQ0VxJiQw"
   },
   "outputs": [],
   "source": [
    "predprob['Finalpredicted']=predprob.Probs.map(lambda x:1 if x>0.52 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "JNo4WjKCKFbB",
    "outputId": "c5615a90-b3d4-4051-9996-70873c264b45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Probs</th>\n",
       "      <th>Train_Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>Finalpredicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.449957</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.519310</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.291949</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.234129</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.173535</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn     Probs  Train_Predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  \\\n",
       "0      0  0.449957                0    1    1    1    1    1    0    0    0   \n",
       "1      1  0.519310                1    1    1    1    1    1    1    0    0   \n",
       "2      0  0.291949                0    1    1    1    0    0    0    0    0   \n",
       "3      0  0.234129                0    1    1    1    0    0    0    0    0   \n",
       "4      0  0.173535                0    1    1    0    0    0    0    0    0   \n",
       "\n",
       "   0.8  0.9  Finalpredicted  \n",
       "0    0    0               0  \n",
       "1    0    0               0  \n",
       "2    0    0               0  \n",
       "3    0    0               0  \n",
       "4    0    0               0  "
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predprob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ukk7uOqcKoe0",
    "outputId": "d8c25aa8-29b3-479b-839a-76c3bc5a2453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Report with cut off probability-0.52\n",
      "Accuracy : 0.7602058051607203\n",
      "Recall : 0.76453186630683\n",
      "Precision : 0.7584697765420657\n"
     ]
    }
   ],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(predprob.Churn, predprob.Finalpredicted)\n",
    "print(\"Training Data Report with cut off probability-0.52\")\n",
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(predprob.Churn, predprob.Finalpredicted)))\n",
    "print(\"Recall : {}\".format(metrics.recall_score(predprob.Churn, predprob.Finalpredicted)))\n",
    "print(\"Precision : {}\".format(metrics.precision_score(predprob.Churn, predprob.Finalpredicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "ttgQJuQZKy6T",
    "outputId": "8cd0ab78-8c24-49ab-c2fa-29aed21bad41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76     19215\n",
      "           1       0.76      0.76      0.76     19268\n",
      "\n",
      "    accuracy                           0.76     38483\n",
      "   macro avg       0.76      0.76      0.76     38483\n",
      "weighted avg       0.76      0.76      0.76     38483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(predprob.Churn, predprob.Finalpredicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****Making prediction on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drDQO43LMEXr"
   },
   "outputs": [],
   "source": [
    "cutoff_p=0.52\n",
    "predtest=pd.DataFrame({'Churn':y_test,\"Probs\":pred_probs_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTuuF9SPM-S_"
   },
   "outputs": [],
   "source": [
    "predtest[\"Predicted\"]=predtest.Probs.map(lambda x:1 if x>0.52 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "NiOmrvqCNNWL",
    "outputId": "1c9bb906-9bd7-4e1e-9a4b-b6ec9f26b739"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Probs</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.194127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.560061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.683013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn     Probs  Predicted\n",
       "0      0  0.194127          0\n",
       "1      1  0.560061          1\n",
       "2      0  0.683013          1\n",
       "3      1  0.839623          1\n",
       "4      0  0.011113          0"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FA9Vn0U4Nfrb",
    "outputId": "94f5336d-3ad9-4d3d-94aa-d1ee87331d68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7347359485842478"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(predtest.Churn, predtest.Predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Test Data: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69      8286\n",
      "           1       0.68      0.76      0.72      8207\n",
      "\n",
      "    accuracy                           0.70     16493\n",
      "   macro avg       0.71      0.70      0.70     16493\n",
      "weighted avg       0.71      0.70      0.70     16493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report Test Data: \" )\n",
    "print(classification_report(predtest.Churn, predtest.Predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Report on Test Data cut off probability-0.52\n",
      "Accuracy : 0.7347359485842478\n",
      "Recall : 0.7838199513381995\n",
      "Precision : 0.7126424068134056\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation Report on Test Data cut off probability-0.52\")\n",
    "print(\"Accuracy : {}\".format(metrics.accuracy_score(predtest.Churn,predtest.Predicted)))\n",
    "print(\"Recall : {}\".format(metrics.recall_score(predtest.Churn,predtest.Predicted)))\n",
    "print(\"Precision : {}\".format(metrics.precision_score(predtest.Churn,predtest.Predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[5675 2598]\n",
      " [1777 6443]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(predtest.Churn,predtest.Predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-2 -> Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ZJ9Lm1OXFWb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tuning hyperparameters- n_estimators****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'n_estimators': range(50, 800,300)}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf1 = RandomForestClassifier(max_depth=4, class_weight=\"balanced\")\n",
    "rfgs = GridSearchCV(rf1, parameters, \n",
    "                    cv=n_folds, return_train_score=True,\n",
    "                   scoring=\"accuracy\")\n",
    "rfgs.fit(df_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "RTIwVDTGbiYU",
    "outputId": "42ac8c2d-9fc8-4c97-82c6-c93222ffa416"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.154389</td>\n",
       "      <td>0.029149</td>\n",
       "      <td>0.023435</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>50</td>\n",
       "      <td>{'n_estimators': 50}</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>0.748398</td>\n",
       "      <td>0.730287</td>\n",
       "      <td>0.734392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742685</td>\n",
       "      <td>0.008675</td>\n",
       "      <td>3</td>\n",
       "      <td>0.754912</td>\n",
       "      <td>0.749059</td>\n",
       "      <td>0.753379</td>\n",
       "      <td>0.736050</td>\n",
       "      <td>0.750192</td>\n",
       "      <td>0.748718</td>\n",
       "      <td>0.006676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.046226</td>\n",
       "      <td>0.311798</td>\n",
       "      <td>0.134913</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>350</td>\n",
       "      <td>{'n_estimators': 350}</td>\n",
       "      <td>0.758707</td>\n",
       "      <td>0.758986</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.748885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748537</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>1</td>\n",
       "      <td>0.757977</td>\n",
       "      <td>0.758674</td>\n",
       "      <td>0.756026</td>\n",
       "      <td>0.751863</td>\n",
       "      <td>0.752908</td>\n",
       "      <td>0.755490</td>\n",
       "      <td>0.002699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.987780</td>\n",
       "      <td>0.532380</td>\n",
       "      <td>0.261628</td>\n",
       "      <td>0.015967</td>\n",
       "      <td>650</td>\n",
       "      <td>{'n_estimators': 650}</td>\n",
       "      <td>0.757593</td>\n",
       "      <td>0.757871</td>\n",
       "      <td>0.727222</td>\n",
       "      <td>0.748606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748258</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>2</td>\n",
       "      <td>0.757420</td>\n",
       "      <td>0.754912</td>\n",
       "      <td>0.753100</td>\n",
       "      <td>0.751794</td>\n",
       "      <td>0.754580</td>\n",
       "      <td>0.754361</td>\n",
       "      <td>0.001891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.154389      0.029149         0.023435        0.004354   \n",
       "1       8.046226      0.311798         0.134913        0.005352   \n",
       "2      14.987780      0.532380         0.261628        0.015967   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                 50   {'n_estimators': 50}           0.752299   \n",
       "1                350  {'n_estimators': 350}           0.758707   \n",
       "2                650  {'n_estimators': 650}           0.757593   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0           0.748398           0.730287           0.734392  ...   \n",
       "1           0.758986           0.729730           0.748885  ...   \n",
       "2           0.757871           0.727222           0.748606  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.742685        0.008675                3            0.754912   \n",
       "1         0.748537        0.010687                1            0.757977   \n",
       "2         0.748258        0.011182                2            0.757420   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.749059            0.753379            0.736050   \n",
       "1            0.758674            0.756026            0.751863   \n",
       "2            0.754912            0.753100            0.751794   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.750192          0.748718         0.006676  \n",
       "1            0.752908          0.755490         0.002699  \n",
       "2            0.754580          0.754361         0.001891  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rfgs.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wvWTGBTXUz5E",
    "outputId": "53ba0a8d-9acf-4f15-f04b-e80dfb687d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.7485369329609581 using {'n_estimators': 350}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',rfgs.best_score_,'using',rfgs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "v_Nht8wvbv4I",
    "outputId": "527b3819-44f4-4b06-babc-05eb3451506f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with n_estimators\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_n_estimators\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFTwrfC1oo5N"
   },
   "source": [
    "**** HyperTuning Max Depth ******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "vkGCaHtmovDA",
    "outputId": "feead77a-1511-4649-dc62-0a01328e9f19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': range(10, 30, 5)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_depth': range(10, 30, 5)}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf1 = RandomForestClassifier(class_weight=\"balanced\")\n",
    "rfgs = GridSearchCV(rf1, parameters, \n",
    "                    cv=n_folds, return_train_score=True,\n",
    "                   scoring=\"accuracy\")\n",
    "rfgs.fit(df_train_pca, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "colab_type": "code",
    "id": "C-nbE-3hp9ex",
    "outputId": "3bff1935-51a4-478f-fc98-6e26ba17a3c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.933134</td>\n",
       "      <td>0.053682</td>\n",
       "      <td>0.059777</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>0.887748</td>\n",
       "      <td>0.887031</td>\n",
       "      <td>0.890614</td>\n",
       "      <td>0.884165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886930</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>4</td>\n",
       "      <td>0.929420</td>\n",
       "      <td>0.922553</td>\n",
       "      <td>0.928286</td>\n",
       "      <td>0.926435</td>\n",
       "      <td>0.928529</td>\n",
       "      <td>0.927045</td>\n",
       "      <td>0.002447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.503921</td>\n",
       "      <td>0.031481</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 15}</td>\n",
       "      <td>0.912587</td>\n",
       "      <td>0.920946</td>\n",
       "      <td>0.913542</td>\n",
       "      <td>0.914020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915019</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>3</td>\n",
       "      <td>0.980355</td>\n",
       "      <td>0.980594</td>\n",
       "      <td>0.983758</td>\n",
       "      <td>0.981907</td>\n",
       "      <td>0.981311</td>\n",
       "      <td>0.981585</td>\n",
       "      <td>0.001216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.583008</td>\n",
       "      <td>0.056256</td>\n",
       "      <td>0.072929</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 20}</td>\n",
       "      <td>0.920707</td>\n",
       "      <td>0.920946</td>\n",
       "      <td>0.916408</td>\n",
       "      <td>0.921423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919652</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>2</td>\n",
       "      <td>0.995402</td>\n",
       "      <td>0.995999</td>\n",
       "      <td>0.996895</td>\n",
       "      <td>0.996059</td>\n",
       "      <td>0.995761</td>\n",
       "      <td>0.996023</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.758910</td>\n",
       "      <td>0.104177</td>\n",
       "      <td>0.090992</td>\n",
       "      <td>0.031049</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 25}</td>\n",
       "      <td>0.922140</td>\n",
       "      <td>0.922618</td>\n",
       "      <td>0.918319</td>\n",
       "      <td>0.920468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920608</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999821</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.933134      0.053682         0.059777        0.003125   \n",
       "1       4.503921      0.031481         0.071830        0.004123   \n",
       "2       4.583008      0.056256         0.072929        0.003688   \n",
       "3       4.758910      0.104177         0.090992        0.031049   \n",
       "\n",
       "  param_max_depth             params  split0_test_score  split1_test_score  \\\n",
       "0              10  {'max_depth': 10}           0.887748           0.887031   \n",
       "1              15  {'max_depth': 15}           0.912587           0.920946   \n",
       "2              20  {'max_depth': 20}           0.920707           0.920946   \n",
       "3              25  {'max_depth': 25}           0.922140           0.922618   \n",
       "\n",
       "   split2_test_score  split3_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.890614           0.884165  ...         0.886930        0.002248   \n",
       "1           0.913542           0.914020  ...         0.915019        0.003009   \n",
       "2           0.916408           0.921423  ...         0.919652        0.001856   \n",
       "3           0.918319           0.920468  ...         0.920608        0.001606   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                4            0.929420            0.922553   \n",
       "1                3            0.980355            0.980594   \n",
       "2                2            0.995402            0.995999   \n",
       "3                1            0.999761            1.000000   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.928286            0.926435            0.928529   \n",
       "1            0.983758            0.981907            0.981311   \n",
       "2            0.996895            0.996059            0.995761   \n",
       "3            0.999940            0.999821            0.999940   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.927045         0.002447  \n",
       "1          0.981585         0.001216  \n",
       "2          0.996023         0.000493  \n",
       "3          0.999893         0.000088  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rfgs.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SXlmRgRpkQQR",
    "outputId": "0770191c-b2f7-4bf1-c40d-90fef106701b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.9206075707451602 using {'max_depth': 25}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',rfgs.best_score_,'using',rfgs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "XGTUBO_nqIRo",
    "outputId": "11f84792-8ac9-458c-bcfb-cb53fd0964ef"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with n_estimators\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_depth\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "42VKY1IeVLRJ",
    "outputId": "efb6a4a0-9cfa-49d2-c2b6-a96a171a89e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.9206075707451602 using {'max_depth': 25}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',rfgs.best_score_,'using',rfgs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MmeawSQYqrtl"
   },
   "source": [
    "**hypertuning max_features*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vEyqtvPds7Pd"
   },
   "outputs": [],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'max_features': [3, 8, 13,17]}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf1 = RandomForestClassifier(max_depth=10, class_weight=\"balanced\")\n",
    "rfgs = GridSearchCV(rf1, parameters, \n",
    "                    cv=n_folds, return_train_score=True,\n",
    "                   scoring=\"accuracy\")\n",
    "rfgs.fit(df_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "dC-bC9jxtB7I",
    "outputId": "a8ac93d5-1057-48a7-af7b-e93944d71f77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.413739</td>\n",
       "      <td>0.085685</td>\n",
       "      <td>0.055989</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_features': 3}</td>\n",
       "      <td>0.893006</td>\n",
       "      <td>0.874060</td>\n",
       "      <td>0.856785</td>\n",
       "      <td>0.882107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876052</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>2</td>\n",
       "      <td>0.922391</td>\n",
       "      <td>0.922391</td>\n",
       "      <td>0.911105</td>\n",
       "      <td>0.918844</td>\n",
       "      <td>0.920515</td>\n",
       "      <td>0.919049</td>\n",
       "      <td>0.004187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.463211</td>\n",
       "      <td>0.338176</td>\n",
       "      <td>0.062273</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_features': 8}</td>\n",
       "      <td>0.891056</td>\n",
       "      <td>0.870437</td>\n",
       "      <td>0.866537</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877501</td>\n",
       "      <td>0.008957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.924760</td>\n",
       "      <td>0.925805</td>\n",
       "      <td>0.921416</td>\n",
       "      <td>0.920933</td>\n",
       "      <td>0.923163</td>\n",
       "      <td>0.923215</td>\n",
       "      <td>0.001873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.493625</td>\n",
       "      <td>1.489093</td>\n",
       "      <td>0.062968</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_features': 13}</td>\n",
       "      <td>0.890220</td>\n",
       "      <td>0.870437</td>\n",
       "      <td>0.863750</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874659</td>\n",
       "      <td>0.010826</td>\n",
       "      <td>3</td>\n",
       "      <td>0.924133</td>\n",
       "      <td>0.925805</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.923581</td>\n",
       "      <td>0.917311</td>\n",
       "      <td>0.921906</td>\n",
       "      <td>0.003297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.467777</td>\n",
       "      <td>1.356815</td>\n",
       "      <td>0.057345</td>\n",
       "      <td>0.008069</td>\n",
       "      <td>17</td>\n",
       "      <td>{'max_features': 17}</td>\n",
       "      <td>0.884369</td>\n",
       "      <td>0.865422</td>\n",
       "      <td>0.861521</td>\n",
       "      <td>0.879599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869420</td>\n",
       "      <td>0.010775</td>\n",
       "      <td>4</td>\n",
       "      <td>0.919186</td>\n",
       "      <td>0.917375</td>\n",
       "      <td>0.914658</td>\n",
       "      <td>0.918147</td>\n",
       "      <td>0.910414</td>\n",
       "      <td>0.915956</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.413739      0.085685         0.055989        0.002160   \n",
       "1       8.463211      0.338176         0.062273        0.012617   \n",
       "2      15.493625      1.489093         0.062968        0.006723   \n",
       "3      17.467777      1.356815         0.057345        0.008069   \n",
       "\n",
       "  param_max_features                params  split0_test_score  \\\n",
       "0                  3   {'max_features': 3}           0.893006   \n",
       "1                  8   {'max_features': 8}           0.891056   \n",
       "2                 13  {'max_features': 13}           0.890220   \n",
       "3                 17  {'max_features': 17}           0.884369   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0           0.874060           0.856785           0.882107  ...   \n",
       "1           0.870437           0.866537           0.884058  ...   \n",
       "2           0.870437           0.863750           0.884615  ...   \n",
       "3           0.865422           0.861521           0.879599  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.876052        0.011852                2            0.922391   \n",
       "1         0.877501        0.008957                1            0.924760   \n",
       "2         0.874659        0.010826                3            0.924133   \n",
       "3         0.869420        0.010775                4            0.919186   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.922391            0.911105            0.918844   \n",
       "1            0.925805            0.921416            0.920933   \n",
       "2            0.925805            0.918699            0.923581   \n",
       "3            0.917375            0.914658            0.918147   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.920515          0.919049         0.004187  \n",
       "1            0.923163          0.923215         0.001873  \n",
       "2            0.917311          0.921906         0.003297  \n",
       "3            0.910414          0.915956         0.003151  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rfgs.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "sQ3vTIbYtL_C",
    "outputId": "eb1c0abb-a4d4-4ce7-f822-41dbe4564148"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with max_features\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_max_features\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W2-1HZDDu_nT",
    "outputId": "2214c596-ef2a-4392-9888-425168522b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.8775012246325558 using {'max_features': 8}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',rfgs.best_score_,'using',rfgs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aFxayQPOt8BN"
   },
   "source": [
    "***hypertuning hyperparameter Min Samples Leaf***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "bp11t5D-t7Vi",
    "outputId": "f7b21428-142d-41be-ac30-122a19b85062"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=10,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'min_samples_leaf': range(100, 400, 50)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_leaf': range(100, 400, 50)}\n",
    "\n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf1 = RandomForestClassifier(max_depth=10, class_weight=\"balanced\")\n",
    "rfgs = GridSearchCV(rf1, parameters, \n",
    "                    cv=n_folds, return_train_score=True,\n",
    "                   scoring=\"accuracy\")\n",
    "rfgs.fit(df_train_pca, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "nppM-r4lu5ch",
    "outputId": "0fdb5603-ff24-49c6-96b2-3a2ce478897d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.258261</td>\n",
       "      <td>0.079839</td>\n",
       "      <td>0.065393</td>\n",
       "      <td>0.013718</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_leaf': 100}</td>\n",
       "      <td>0.815620</td>\n",
       "      <td>0.818963</td>\n",
       "      <td>0.816097</td>\n",
       "      <td>0.807977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813796</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.822953</td>\n",
       "      <td>0.827491</td>\n",
       "      <td>0.827909</td>\n",
       "      <td>0.824685</td>\n",
       "      <td>0.824516</td>\n",
       "      <td>0.825511</td>\n",
       "      <td>0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.964460</td>\n",
       "      <td>0.031697</td>\n",
       "      <td>0.052615</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>150</td>\n",
       "      <td>{'min_samples_leaf': 150}</td>\n",
       "      <td>0.801767</td>\n",
       "      <td>0.802006</td>\n",
       "      <td>0.803439</td>\n",
       "      <td>0.793647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800707</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>2</td>\n",
       "      <td>0.804204</td>\n",
       "      <td>0.810712</td>\n",
       "      <td>0.814295</td>\n",
       "      <td>0.807548</td>\n",
       "      <td>0.810246</td>\n",
       "      <td>0.809401</td>\n",
       "      <td>0.003371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.807050</td>\n",
       "      <td>0.058211</td>\n",
       "      <td>0.054392</td>\n",
       "      <td>0.009293</td>\n",
       "      <td>200</td>\n",
       "      <td>{'min_samples_leaf': 200}</td>\n",
       "      <td>0.795319</td>\n",
       "      <td>0.794841</td>\n",
       "      <td>0.792692</td>\n",
       "      <td>0.788154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792252</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>3</td>\n",
       "      <td>0.793993</td>\n",
       "      <td>0.801218</td>\n",
       "      <td>0.802651</td>\n",
       "      <td>0.801756</td>\n",
       "      <td>0.799916</td>\n",
       "      <td>0.799907</td>\n",
       "      <td>0.003087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.647471</td>\n",
       "      <td>0.069888</td>\n",
       "      <td>0.050909</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>250</td>\n",
       "      <td>{'min_samples_leaf': 250}</td>\n",
       "      <td>0.787915</td>\n",
       "      <td>0.789348</td>\n",
       "      <td>0.779556</td>\n",
       "      <td>0.781466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785755</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>4</td>\n",
       "      <td>0.785753</td>\n",
       "      <td>0.792978</td>\n",
       "      <td>0.794710</td>\n",
       "      <td>0.790888</td>\n",
       "      <td>0.795797</td>\n",
       "      <td>0.792025</td>\n",
       "      <td>0.003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.571249</td>\n",
       "      <td>0.054979</td>\n",
       "      <td>0.052108</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>300</td>\n",
       "      <td>{'min_samples_leaf': 300}</td>\n",
       "      <td>0.781705</td>\n",
       "      <td>0.783855</td>\n",
       "      <td>0.784094</td>\n",
       "      <td>0.775018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780787</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>5</td>\n",
       "      <td>0.779841</td>\n",
       "      <td>0.790052</td>\n",
       "      <td>0.794829</td>\n",
       "      <td>0.784797</td>\n",
       "      <td>0.784930</td>\n",
       "      <td>0.786890</td>\n",
       "      <td>0.005117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.258261      0.079839         0.065393        0.013718   \n",
       "1       2.964460      0.031697         0.052615        0.003026   \n",
       "2       2.807050      0.058211         0.054392        0.009293   \n",
       "3       2.647471      0.069888         0.050909        0.002653   \n",
       "4       2.571249      0.054979         0.052108        0.004405   \n",
       "\n",
       "  param_min_samples_leaf                     params  split0_test_score  \\\n",
       "0                    100  {'min_samples_leaf': 100}           0.815620   \n",
       "1                    150  {'min_samples_leaf': 150}           0.801767   \n",
       "2                    200  {'min_samples_leaf': 200}           0.795319   \n",
       "3                    250  {'min_samples_leaf': 250}           0.787915   \n",
       "4                    300  {'min_samples_leaf': 300}           0.781705   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0           0.818963           0.816097           0.807977  ...   \n",
       "1           0.802006           0.803439           0.793647  ...   \n",
       "2           0.794841           0.792692           0.788154  ...   \n",
       "3           0.789348           0.779556           0.781466  ...   \n",
       "4           0.783855           0.784094           0.775018  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.813796        0.004032                1            0.822953   \n",
       "1         0.800707        0.003578                2            0.804204   \n",
       "2         0.792252        0.002724                3            0.793993   \n",
       "3         0.785755        0.004401                4            0.785753   \n",
       "4         0.780787        0.003370                5            0.779841   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.827491            0.827909            0.824685   \n",
       "1            0.810712            0.814295            0.807548   \n",
       "2            0.801218            0.802651            0.801756   \n",
       "3            0.792978            0.794710            0.790888   \n",
       "4            0.790052            0.794829            0.784797   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.824516          0.825511         0.001891  \n",
       "1            0.810246          0.809401         0.003371  \n",
       "2            0.799916          0.799907         0.003087  \n",
       "3            0.795797          0.792025         0.003549  \n",
       "4            0.784930          0.786890         0.005117  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rfgs.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LnjF4htPmS77",
    "outputId": "dd618d90-6191-42ce-c020-b5d58be0c92f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.8137955729694134 using {'min_samples_leaf': 100}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',rfgs.best_score_,'using',rfgs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "is6t-k_AvA3n",
    "outputId": "81361467-1050-4acb-a650-1aadbc2b18c8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAELCAYAAAAoUKpTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VFX6+PHPk0JCgAQCCR0SaihJ6CBIr4KgKBZEFBWw4aq7uqtfu7tusaDib9VFBZS1sSgKNnoRpIVO6J0QIIQSEiCQcn5/3JsQISGBzOROJs/79ZoXM/feufNcJvDknHvOc8QYg1JKKXUlPk4HoJRSyvNpslBKKVUoTRZKKaUKpclCKaVUoTRZKKWUKpQmC6WUUoXSZKGUUqpQmiyUUkoVSpOFUkqpQvk5HYCrVKtWzURERDgdhlJKlSpr1qxJNsaEFXac1ySLiIgI4uLinA5DKaVKFRHZX5TjtBtKKaVUoTRZKKWUKpQmC6WUUoXymnsWSqlrk5GRQUJCAunp6U6HotwoMDCQOnXq4O/vf03v12ShVBmXkJBApUqViIiIQEScDke5gTGG48ePk5CQQGRk5DWdQ7uhlCrj0tPTqVq1qiYKLyYiVK1atVitR00WSilNFGVAcb/jMp8sjDF8tGQPJ85ccDoUpZTyWGU+WexJPsObc7YzavIq0s5nOh2OUmXOqVOneP/996/pvQMHDuTUqVNXPObFF19k3rx513R+dVGZTxYNwyry/og2xCeeZsyncaRnZDkdklJlypWSRVbWlf89/vTTT1SuXPmKx7z66qv06dPnmuNzQmam5/3iWuaTBUDvZtV567ZYlu85zmNfriMzK9vpkJQqM5555hl2795Nq1atePrpp1m0aBE9e/bkrrvuIjo6GoCbb76Ztm3b0qJFCyZOnJj73oiICJKTk9m3bx/NmjVjzJgxtGjRgn79+nHu3DkARo0axfTp03OPf+mll2jTpg3R0dFs27YNgGPHjtG3b1/atGnDgw8+SP369UlOTr4s1ocffph27drRokULXnrppdztq1evpnPnzsTGxtKhQwdSU1PJysriqaeeIjo6mpiYGN57773fxQwQFxdHjx49AHj55ZcZO3Ys/fr145577mHfvn107dqVNm3a0KZNG3777bfcz3v99deJjo4mNjY29++vTZs2uft37txJ27Zti/3d5KVDZ203t65NyrkMXpoZz1++2cQbw2Lw8dGbfqpseWVWPFsST7v0nM1rBfPS4BYF7v/nP//J5s2bWb9+PQCLFi1i1apVbN68OXeY56RJkwgNDeXcuXO0b9+eW2+9lapVq/7uPDt37uTLL7/ko48+4vbbb+ebb77h7rvvvuzzqlWrxtq1a3n//fd58803+fjjj3nllVfo1asXzz77LL/88svvElJer732GqGhoWRlZdG7d282btxIVFQUd9xxB19//TXt27fn9OnTlC9fnokTJ7J3717WrVuHn58fJ06cKPTvas2aNSxdupTy5ctz9uxZ5s6dS2BgIDt37mT48OHExcXx888/891337Fy5UqCgoI4ceIEoaGhhISEsH79elq1asXkyZMZNWpUoZ93NTRZ5HFv5whSzmUwfu4OQsr788KNzXSUiFIO6NChw+/mA0yYMIEZM2YAcPDgQXbu3HlZsoiMjKRVq1YAtG3bln379uV77ltuuSX3mG+//RaApUuX5p5/wIABVKlSJd/3Tps2jYkTJ5KZmcnhw4fZsmULIkLNmjVp3749AMHBwQDMmzePhx56CD8/67/Z0NDQQq97yJAhlC9fHrAmS44bN47169fj6+vLjh07cs973333ERQU9Lvzjh49msmTJzN+/Hi+/vprVq1aVejnXQ1NFpd4rFcjTp3NYNKyvVQJ8uex3o2dDkmpEnOlFkBJqlChQu7zRYsWMW/ePJYvX05QUBA9evTId75AQEBA7nNfX9/cbqiCjvP19c29N2CMKTSmvXv38uabb7J69WqqVKnCqFGjSE9PxxiT7y+VBW338/MjO9vq6r70OvJe99tvv0316tXZsGED2dnZBAYGXvG8t956a24LqW3btpcl0+LSexaXEBGeH9SMW9vU4a25O/hs+T6nQ1LKq1WqVInU1NQC96ekpFClShWCgoLYtm0bK1ascHkM119/PdOmTQNgzpw5nDx58rJjTp8+TYUKFQgJCeHo0aP8/PPPAERFRZGYmMjq1asBSE1NJTMzk379+vHhhx/mJqScbqiIiAjWrFkDwDfffFNgTCkpKdSsWRMfHx+mTp2ae7O/X79+TJo0ibNnz/7uvIGBgfTv35+HH36Y++67r9h/J5fSZJEPHx/hX7dG06dZdV78Pp7v1h1yOiSlvFbVqlXp0qULLVu25Omnn75s/4ABA8jMzCQmJoYXXniBTp06uTyGl156iTlz5tCmTRt+/vlnatasSaVKlX53TGxsLK1bt6ZFixbcf//9dOnSBYBy5crx9ddf89hjjxEbG0vfvn1JT09n9OjR1KtXj5iYGGJjY/niiy9yP+vxxx+na9eu+Pr6FhjTI488wqeffkqnTp3YsWNHbqtjwIABDBkyhHbt2tGqVSvefPPN3PeMGDECEaFfv36u/itCitL8Kg3atWtnXL34UXpGFvdNXs2qfSf46J629Iqq7tLzK+UJtm7dSrNmzZwOw1Hnz5/H19cXPz8/li9fzsMPP5x7w700efPNN0lJSeGvf/1rvvvz+65FZI0xpl1h59Z7FlcQ6O/LR/e2466PVvDwf9cy9YGOdIgs/CaVUqp0OXDgALfffjvZ2dmUK1eOjz76yOmQrtrQoUPZvXs3CxYscMv5tWVRBCfOXOC2D38j6fR5vhzbiZa1Q9zyOUo5QVsWZUdxWhZ6z6IIQiuU47+jOxJc3p97J61iz7E0p0NSSqkSpcmiiGqGlGfqAx0AGPnJKhJP5T8sTymlvJEmi6vQIKwin97fgdPnMhj5yUqtVKuUKjM0WVyllrVD+GRUexJOnmPU5FWkpmc4HZJSSrmdJotr0CEylA/ubsOWxNOM+Uwr1SpVHMUpUQ7wzjvv5E5QU+6jyeIa9Yqqzlu3x7Jy7wnGfaGVapW6Vt6QLDyxpLirabIohpta1eaVIS2Yt/Uof/5mI9nZ3jEMWamSdGmJcoA33niD9u3bExMTk1sK/MyZMwwaNIjY2FhatmzJ119/zYQJE0hMTKRnz5707NnzsnO/+uqrtG/fnpYtWzJ27NjcGlC7du2iT58+xMbG0qZNG3bv3g1cXvoboEePHuQMy09OTiYiIgKAKVOmcNtttzF48GD69etHWloavXv3zi1//v333+fG8dlnn+XO5B45ciSpqalERkaSkWF1Y58+fZqIiIjc155IJ+UV0z3XRZByNoO37Eq1L97YXCvVqtLr52fgyCbXnrNGNNzwzwJ3X1qifM6cOezcuZNVq1ZhjGHIkCEsWbKEY8eOUatWLX788UfAqp0UEhLC+PHjWbhwIdWqVbvs3OPGjePFF18EYOTIkfzwww8MHjyYESNG8MwzzzB06FDS09PJzs7Ot/R3YZYvX87GjRsJDQ0lMzOTGTNmEBwcTHJyMp06dWLIkCFs2bKF1157jWXLllGtWjVOnDhBpUqV6NGjBz/++CM333wzX331Fbfeeiv+/v7X8jdcItzashCRASKyXUR2icgz+eyvJyILRWSdiGwUkYH29r4iskZENtl/9nJnnMU1rlcjHrg+ksnL9vHegl1Oh6NUqTZnzhzmzJlD69atadOmDdu2bWPnzp1ER0czb948/vKXv/Drr78SElL45NiFCxfSsWNHoqOjWbBgAfHx8aSmpnLo0CGGDh0KWAX4goKCCiz9fSV9+/bNPc4Yw//93/8RExNDnz59OHToEEePHmXBggUMGzYsN5ldWlIcYPLkyW4p/udKbmtZiIgv8G+gL5AArBaRmcaYLXkOex6YZoz5QESaAz8BEUAyMNgYkygiLYHZQG13xVpcIsJzA5tx6uzFtTDu7RzhdFhKXb0rtABKijGGZ599lgcffPCyfWvWrOGnn37i2WefpV+/frmthvykp6fzyCOPEBcXR926dXn55ZdzS4oX9LnFKSn++eefc+zYMdasWYO/vz8RERFXLGHepUsX9u3bx+LFi8nKyqJly5YFXosncGfLogOwyxizxxhzAfgKuOmSYwwQbD8PARIBjDHrjDGJ9vZ4IFBEAvBgOZVq+zavzksztVKtUkV1aYny/v37M2nSJNLSrEoJhw4dIikpicTERIKCgrj77rt56qmnWLt2bb7vz5HzH3u1atVIS0vLXVo1ODiYOnXq8N133wFWEcGzZ88WWPo7b0nxnHPkJyUlhfDwcPz9/Vm4cCH79+8HoHfv3kybNo3jx4//7rwA99xzD8OHD/f4VgW4N1nUBg7meZ3A5a2Dl4G7RSQBq1XxWD7nuRVYZ4w5744gXcnP14f3hrfmugZV+dP/NjBvy1GnQ1LK411aorxfv37cddddXHfddURHRzNs2DBSU1PZtGkTHTp0oFWrVrz22ms8//zzAIwdO5YbbrjhshvclStXZsyYMURHR3PzzTfnrmQHMHXqVCZMmEBMTAydO3fmyJEjBZb+fuqpp/jggw/o3Llzvuty5xgxYgRxcXG0a9eOzz//nKioKABatGjBc889R/fu3YmNjeWPf/zj795z8uRJhg8f7rK/T3dxWyFBEbkN6G+MGW2/Hgl0MMY8lueYP9oxvCUi1wGfAC2NMdn2/hbATKCfMWZ3Pp8xFhgLUK9evbY5mdxpaeczGfHRCrYdSeWz+zvQsYFrV6xSypW0kKBzpk+fzvfff8/UqVNL5PM8tZBgAlA3z+s62N1MeTwATAMwxiwHAoFqACJSB5gB3JNforDfM9EY084Y0y4sLMzF4V+7igF+TL6vA3VDgxj9aRybD6U4HZJSysM89thjPPPMM7zwwgtOh1Ik7kwWq4HGIhIpIuWAO7FaCXkdAHoDiEgzrGRxTEQqAz8CzxpjlrkxRrcJrVCOqQ90yK1Uu1sr1Sql8njvvffYtWsXTZo0cTqUInFbsjDGZALjsEYybcUa9RQvIq+KyBD7sD8BY0RkA/AlMMpY/WLjgEbACyKy3n6EuytWd8mpVCsCIz9eqZVqlcfylnVtVMGK+x3r4kclID4xhTv/s4Kw4AD+9+B1VK3o0QO7VBmzd+9eKlWqRNWqVXVCqZcyxnD8+PHcmeN5FfWehSaLErJ63wlGfrKSxuGV+GJMRyoFeu5MTVW2ZGRkkJCQcNkcAuVdAgMDqVOnzmWzxDVZeKCF25IY81kcbetX4dP7OxDo7+t0SEqpMs4TRkOpS/SMCuet22NZte8E475YS4ZWqlVKlRKaLErYTa1q8+pNLZm3NYm/TNdKtUqp0kGrzjpgZKf6pJy9wJtzdhBc3p+XBmulWqWUZ9Nk4ZBHezbi5NkMPlm6lypB5Xi8T2OnQ1JKqQJpsnBITqXalHMZvD1vByHl/RjVJbLwNyqllAM0WTjIx0f45y3RnD6XwcuzthAS5M/Q1nWcDksppS6jN7gd5ufrw4ThrencsCpP/W+jVqpVSnkkTRYeINDfl4n3tKNlrWAe+WItK/YcdzokpZT6HU0WHqJigB9T7utAPa1Uq5TyQJosPEgVu1JtSHl/7pm0il1JWqlWKeUZNFl4mJoh5fnv6I74CNzzyUoOaaVapZQH0GThgSKrVeDT+zuQej6TkR+vJDnN41eUVUp5OU0WHqpFrRAmjWpPYso5Rk1eRWp6htMhKaXKME0WHqx9RCgf3N2WbYdTGf1pHOkZWU6HpJQqozRZeLieTbVSrVLKeZosSoG8lWr/rJVqlVIO0HIfANnZ4OPZeXNkp/qcPpfBG7O3E6KVapVSJcyz/4csCedOwse9YcccpyMp1CM9GjL6+kim/LaPd+btdDocpVQZoski8wKYLPjyToib7HQ0VyQiPDeoGbe1rcO783cyedlep0NSSpURmiwqVYdRP0Gj3vDDEzDvFatbykOJCP+4JZr+LarzyqwtfLs2wemQlFJlgCYLgICKcOeX0HYULB0P346BTM+dCOfn68O7d7amS6OqPD19I3O1Uq1Sys00WeTw9YMb34HeL8Hm6TD1Fut+hocK9PflPyPb0bJ2CI9+sZblu7VSrVLKfTRZ5CUCXf8It3wMCavgk/5wcr/TURWoYoAfU0a1p35oEGM+i2NTglaqVUq5hyaL/MTcBiNnQNoR+LgPJK5zOqICWZVqOxJS3p97J2ulWqWUe2iyKEjE9XD/HPALhMkDYcdspyMqUI2QQD4f3REfEUZqpVqllBtosriS8CgYPQ+qNbaH1k5yOqICRVSrwGf3dyBNK9UqpdxAk0VhcofW9oEfnoR5L3vs0NrmtYKZbFeqvXfSKk5rpVqllItosiiK3KG198HStz16aG07u1Lt9iNaqVYp5TqaLIrK1w9ufBv6vOzxQ2t7Ng1n/B2tWL3vBI9+rpVqlVLFp8niaojA9U/CrZ94/NDaIbG1+OtNLZm/LYmn/7dBK9UqpYrFrclCRAaIyHYR2SUiz+Szv56ILBSRdSKyUUQG2tur2tvTROT/uTPGaxI97PdDaw+tdTqifN3dqT5P92/Kd+sTeWVWPMZowlBKXRu3JQsR8QX+DdwANAeGi0jzSw57HphmjGkN3Am8b29PB14AnnJXfMUWcT08MNcaWjtlEGz/xemI8vVIj4aM6RrJp8v387ZWqlVKXSN3tiw6ALuMMXuMMReAr4CbLjnGAMH28xAgEcAYc8YYsxQraXiusKb20Nom8NVwWP2J0xFdRkT4v4HNuL1dHSbM38mkpVqpVil19dyZLGoDB/O8TrC35fUycLeIJAA/AY9dzQeIyFgRiRORuGPHjhUn1mtXqTqM+hEa9YUf/whzX/K4obUiwt+HRjOgRQ1e/WEL36zRSrVKqavjzmSR3zJul3aaDwemGGPqAAOBqSJS5JiMMRONMe2MMe3CwsKKEWoxBVSEO7+AdvfDsnfg29EeN7TWz9eHd4e3okujqvz5m43MiT/idEhKqVLEnckiAaib53Ud7G6mPB4ApgEYY5YDgUA1N8bkPr5+MGg89HkFNn8DU4fC2RNOR/U7AX6+TLQr1Y77ch1TV+zXUVJKqSJxZ7JYDTQWkUgRKYd1A3vmJcccAHoDiEgzrGThUH+SC4jA9U/YQ2tXw6T+cHKf01H9TgW7Um2HiFBe+G4zt/1nOTuOpjodllLKw7ktWRhjMoFxwGxgK9aop3gReVVEhtiH/QkYIyIbgC+BUcYe3yki+4DxwCgRSchnJJXnih4GI7+DtKPwcV+PG1prVartwFu3xbLnWBqDJvzK+Dnbdba3UqpA4i1j79u1a2fi4uKcDuP3jm2Hz4fBmWQYNhmaDnA6osscTzvPaz9u5dt1h2gQVoF/DI2mY4OqToellCohIrLGGNOusON0Brc7hTWFB/IOrf3Y6YguU7ViAOPvaMVn93cgIyubOyau4JlvNpJyVosQKqUu0mThbjlDaxv3gx//BHNf9LihtQDdmoQx+4luPNitAf9bk0Dv8Yv5YWOizvpWSgGaLEpGQEW443No9wAsexe+eQAyPG++YVA5P54d2IzvH+1CzZBAxn2xjtGfxuliSkopTRYlxtcPBr1lDa2N/9Yjh9bmaFk7hBmPdOb5Qc34bfdx+o1fzORle8nSYbZKlVmaLEpS3qG1h+Lgk34eN7Q2h5+vD6O7NmDOk91oFxHKK7O2cMsHv7H18GmnQ1NKOUCThRNyhtaeOebRVWsB6oYGMeW+9rx7ZysSTpxl8HtL+dcv23SYrVJljCYLp0R0sarW+pe3q9b+7HREBRIRbmpVm/l/6s4tbWrzwaLd9H9nCct2JTsdmlKqhGiycFJYExg93xpi+9VdsOojpyO6ospB5Xh9WCxfjOmIACM+Xsmfpm3g5JkLToemlHIzTRZOqxh+cWjtT0957NDavDo3rMYvT3Tj0Z4N+X79IXqPX8x36w7pMFulvFihyUJExolIlZIIpswqV6FUDK3NK9Dfl6f7R/HDH66nXmgQT3y9nnsnr+bgibNOh6aUcoOitCxqAKtFZJq9TGp+pcdVceUMre37qj209maPHVqbV1SNYL55uDOvDGnBmn0n6Pv2YiYu2U1mlme3jpRSV6dItaHsBNEPuA9oh1VW/BNjzG73hld0Hlkb6lpt/gZmPASV68Pd06FKhNMRFUniqXO8+H0887YepUWtYP55SwzRdUKcDkspdQUurQ1lV4I9Yj8ygSrAdBF5vVhRqvy1vBXu+T7P0No1TkdUJLUql+eje9rywYg2JKWe56Z/L+VvP2zh7IVMp0NTShVTUe5Z/EFE1gCvA8uAaGPMw0Bb4FY3x1d21e9sD60Ngik3wrafnI6oSESEG6JrMu+P3bmzQz0+XrqXfm8vYfGO0rtMiVKqaC2LasAtxpj+xpj/GWMyAIwx2cCNbo2urAtrAqPnWUNrvx7h8UNr8wop78/fh0Yz7cHrCPDz4d5Jq3j8q3Ukp3nWcrNKqaIpSrL4Cci90yoilUSkI4AxZqu7AlO23KG1/a2htXNe8PihtXl1iAzlp8e78njvxvy06TB9xi/mf3EHdZitUqVMUZLFB0Bantdn7G2qpJSrAHd+Du1Hw28T4Jv7PX5obV4Bfr482bcJPz/elUZhFXl6+kZGfLySfclnnA5NKVVERUkWYvL8Gmh3P/m5LySVLx9fGPgm9P0rxM8oNUNr82oUXolpD17Ha0Nbsikhhf7vLOHfC3eRocNslfJ4RUkWe+yb3P7243Fgj7sDU/kQgS5/gGGTrBFSn/SDE3udjuqq+PgIIzrWZ96futMrKpw3Zm9n8HtLWXfgpNOhKaWuoCjJ4iGgM3AISAA6AmPdGZQqRN6htZ/0LTVDa/OqHhzIB3e3ZeLItpw6m8EtH/zGyzPjSTuvw2yV8kRFmpRXGnjVpLyiSt4J/70V0pKs1kbUQKcjuiap6Rm8OXs7n63YT43gQP56U0v6NK/udFhKlQlFnZRXaLIQkUDgAaAFEJiz3Rhzf3GDdKUymSzAShRf3AGH18MNr0OHMU5HdM3WHjjJs99sYvvRVAZF1+Slwc0JDw4s/I1KqWvmyhncU7HqQ/UHFgN1gNTihadcpmI4jPohz9Da50vV0Nq82tSrwqzHrufp/k2Zu/Uovccv5stVB8jW5VyVclxRkkUjY8wLwBljzKfAICDavWGpq5I7tHYM/PYeTL+vVA2tzaucnw+P9mzEL493pUWtYJ79dhN3TlzBrqS0wt+slHKboiSLDPvPUyLSEggBItwWkbo2Pr4w8A3o9zfY8h18dlOpG1qbV4Owinw5phOv3xrD9qOpDHz3V96dt5Pzmbqcq1JOKEqymGivZ/E8MBPYAvzLrVGpayMCnR+DYZMhcZ01UqqUDa3NS0S4vX1d5v2xOwNa1uDteTsYNGEpcftKbxJUqrS6YrIQER/gtDHmpDFmiTGmgTEm3BjznxKKT12LlrdYQ2vPHreq1iaUvqG1eYVVCmDC8NZMHtWecxeyGPbhcp6bsYnT6RmFv1kp5RJXTBb2bO1xJRSLcqX611lVa8tVgCmDYNuPTkdUbD2jwpnzZDceuD6SL1cdoM9bi/ll82Gnw1KqTChKN9RcEXlKROqKSGjOw+2RqeKr1tiqWhveDL4aASsnOh1RsVUI8OOFG5vz3aNdqFYxgIf+u5axn8VxOOWc06Ep5dWKMs8iv05vY4xp4J6Qrk2ZnWdRFBfOwDejYftPcN04q76UT5HWvfJoGVnZTFq6l7fn7cDPx4c/D2jK3R3r4+OjK/8qVVQum5RXWmiyKER2Fvz8F1j9ETS/GYb+B/y9Y8Lb/uNneP67zfy6M5k29Srzj1tiaFqjktNhKVUquGxSnojck9+jiEEMEJHtIrJLRJ7JZ389EVkoIutEZKOIDMyz71n7fdtFpH9RPk9dQX5Da08dcDoql6hftQKf3d+B8bfHsjf5DIMm/Mqbs7eTnqHDbJVylaJ0Q72X52Ug0BtYa4wZVsj7fIEdQF+sAoSrgeHGmC15jpkIrDPGfCAizYGfjDER9vMvgQ5ALWAe0MQYU+C/fm1ZXIX4GTDjYcDAdY/C9U9CgHf8Jn7izAX+9uMWvl17iMhqFfj70Giua1jV6bCU8lgua1kYYx7L8xgDtAbKFSGGDsAuY8weY8wF4CvgpktPDwTbz0OARPv5TcBXxpjzxpi9wC77fMoVWgyFcauh2RD49S2Y0AbWfGp1VZVyoRXKMf72Vkx9oANZ2YbhH63gL9M3cursBadDU6pUu5a7nGeBxkU4rjZwMM/rBHtbXi8Dd4tIAtbyrY9dxXtVcVSuC7d+BKPnQ2gkzPoD/Kc77FnsdGQu0bVxGLOf6MZD3RsyfW0CfcYvZuaGRF3OValrVJR7FrNEZKb9+AHYDnxfhHPnNyTl0n+pw4Epxpg6wEBgqj0RsCjvRUTGikiciMQdO3asCCGpy9RpB/fPtmZ9p6fAZ0PgizsheZfTkRVb+XK+PHNDFDPHdaFW5fL84ct1DH3/N37blex0aEqVOkW5Z9E9z8tMYL8xJqHQE4tcB7xsjOlvv34WwBjzjzzHxAMDjDEH7dd7gE5YJdFzjxWR2fa5lhf0eXrPwgUy0mHF+/DreMg8ZxUm7P5nCCr902qysg3T1xzknXk7OZySzvWNqvF0/6bE1q3sdGhKOcqV61lEAoeNMen26/JAdWPMvkLe54d1g7s31ip7q4G7jDHxeY75GfjaGDNFRJoB87G6m5oDX3DxBvd8oLHe4C4haUmw8DVY+xkEBEOPZ6DdA+BXlFtVni09I4v/rtjP+4t2c+LMBQa0qMFT/ZvQKNw7bvArdbVcmSzigM72TWpEpBywzBjTvghBDATeAXyBScaY10TkVSDOGDPTHvX0EVARq5vpz8aYOfZ7nwPux2rNPGGM+flKn6XJwg2OxsPs/4M9iyC0oTXstukNVsHCUi41PYNPlu7l41/3cvZCJkNb1+GJPo2pGxrkdGhKlShXJov1xphWl2zbYIyJLWaMLqXJwk2MgZ1zrEWVkndAZDfo9xrUjHE6Mpc4ceYC7y/cxWcr9mOMYUT2CejlAAAeiklEQVTH+jzasxFhlQKcDk2pEuHKlfKOiciQPCe+CdA7hGWFCDTpDw//Bje8AUc2wX+6wffjIPWI09EVW2iFcjx/Y3MWP92DYW3rMHXFfrq9vpA3Zm8j5ZxWtVUqR1FaFg2Bz7HuHYA1jPUeY4xHDZfRlkUJOXcSlrwJK/8DvuWg65NWvSn/8k5H5hJ7jqXx9rydzNqQSEh5fx7q3pBRnSMoX87X6dCUcguX14YSkYr28R65/rYmixJ2fDfMfRG2/QDBdaDPyxA9zCvuZwDEJ6bw5uztLNx+jPBKATzWuzF3tKtLOb/SX4BRqbxcWRvq7yJS2RiTZoxJFZEqIvI314SpSq2qDa11v+/9wRpa++1oa6Glg6ucjswlWtQKYfJ9HZj24HXUrxrEC99tps/4xcxYl0BWtk7sU2VPUbqh1hljWl+yba0xpo1bI7tK2rJwUHYWbPgK5r8KaUegxS3Q9xWoXM/pyFzCGMOi7cd4ffZ2th4+TdPqlXiqf1P6NAtHvKQlpcouV46G2gi0N8act1+Xxxr62sIlkbqIJgsPcD4Nlr0Lv70HJvtikcLA4MLfWwpkZxt+3HSY8XN3sDf5DG3qVebp/lFaqFCVaq5MFn8GhgCT7U33ATONMa8XO0oX0mThQVISrFbGxq+hQhj0eh5aj7TKpHuBjKxspq9J4N15OzlyOp2ujavx5/5RRNcJcTo0pa6aS29wi8gAoA9WzaaTQE1jzKPFjtKFNFl4oIQ11qS+gysgvAX0fw0a9nQ6KpdJz8hi6vL9vL9oFyfPZnBDyxr8qV9TGoVXdDo0pYrMlfMsAI4A2cCtWOU7thYjNlVW1GkL9/8Ct02BC6kw9Wb44g5I3ul0ZC4R6O/LmG4NWPLnnjzeuzFLdhyj39uLefp/Gzh0StcEV96lwJaFiDQB7sSqDHsc+Bp4yhhTv+TCKzptWXi4jHRY+QEsecsqUtjuAavmlBcUKcxxPO087y/azdQV+8HAiE71eLRnI6pV1NngynMVuxtKRLKBX4EHcibgicgeY0wDl0bqIposSom0Y3aRwk+tIoXd/wLtR3tFkcIciafO8e68nfxvzUEC/X154PpIxnRrQHCgv9OhKXUZVySLoVgti87AL1gr3X1sjIl0ZaCuosmilDkaD7Ofgz0L7SKFf4WmA71mUh/A7mNpjJ+zgx83HaZykD8Pd2/IvZ0jCPT3jhv9yju4cjRUBeBmrO6oXsCnwIyc6rCeQpNFKWQM7JwLc56zihRGdIX+f/eaIoU5Nh9K4Y3Z21m84xjVgwP4Q+/G3N6uLv6+OhtcOc/l5T7sk4YCtwF3GGN6FSM+l9NkUYplZcCaKbDw71btqdYjoNcLUKmG05G51Mo9x3l99nbW7D9JRNUgnuzbhMExtfDx8Z7WlCp93JIsPJkmCy9waZHC65+Ezt5TpBCs2eALtiXxxuztbDuSSlSNSjzdvym9onQ2uHKGJgtVeh3fDfNegq2z7CKFL0HLYeDjPd022dmGWRsTGT93B/uPn6Vd/So83b8pHRvobHBVsjRZqNJv31JrUt/hDVC7LfT/B9Tr6HRULpWRlc20uINMmL+To6fP071JGE/3b0rL2jobXJUMTRbKO2Rnw0a7SGHqYWgxFPq8AlU8crrPNUvPyOKz5ft4f9FuTp3NYFBMTf7YtwkNw3Q2uHIvTRbKu1w4YxUpXDbBLlL4CFz/R68pUpjjdHoGHy/Zw8dL93I+M5thberweJ/G1KrsPfdtlGfRZKG8U8ohu0jhV1aRwp7PQZt7vKZIYY7ktPP8e+EuPl9xAARGdqrPIz0aUlVngysX02ShvNuhNdakvgPL7SKFf4OGHjWa2yUSTp5lwvydTF+TQHl/X0Z3bcDorpFU0tngykU0WSjvZwxs+d5a3vXUfmjcH/r9DcKaOB2Zy+1KSmP83O38tOkIVYL8eaRHI0ZeV19ng6ti02Shyo6MdFj1H2uOxoUz0P4B6PGsVxUpzLEpIYXXZ2/j153J1AgO5PE+jbmtbR38dDa4ukaaLFTZk3YMFv3dmg0eUMkuUjjGq4oU5li++zivz97GugOniKxWgT/2bcKg6Jo6G1xdNU0WquxK2mrdz9g9H0IbQN+/QtQgrypSCNZs8Plbk3hzjjUbvHnNYJ7u35QeTcN0NrgqMk0WSu2cayWN5O12kcLXoGas01G5XFa2YdYGazb4gRNnaR9RhT8PiKJ9hPd1wynX02ShFEBWJqyZbBcpPAGN+kDHh62RU15UPgTgQmY2X8cd5L35O0lKPU/PpmH8qZ/OBldXpslCqbzOnYJVE2H1x5B2FKo2ho4PQuxwCPCuWdLnLmTx6fJ9fLBoNynnMoiqUYnBsbW4MaYm9atWcDo85WE0WSiVn8wLED/DWuI1cR0EhECbkdBhrNeVEEk5l8GMtQn8sPEwcftPAhBTJ4TBMbUYFFNTZ4UrQJOFUldmDBxcZSWNLTMBY90E7/gw1O/sdTfDD506x48bE/lh42E2JqQA0D6iCoNja3FDy5qEVdKZ4WWVJguliiolweqeWjPFWlOjRrSVNFreCv6BTkfncvuSz/DDxkRmbTjM9qOp+Ahc17Aqg2NqMaBlDSoHed9QY1UwTRZKXa0LZ2HTNFjxIRzbCkHVoN391iQ/L1u1L8f2I6l24khk3/Gz+PkI3ZqEMTi2Jn2aVdeyImWARyQLERkAvAv4Ah8bY/55yf63gZ72yyAg3BhT2d73L2CQve+vxpivr/RZmiyUyxgDexbByg9hx2zw8YOWt0DHh6B2G6ejcwtjDPGJp5m1wUociSnpBPj50CsqnBtjatErKpzy5bS0iDdyPFmIiC+wA+gLJACrgeHGmC0FHP8Y0NoYc7+IDAKeAG4AAoDFQC9jzOmCPk+ThXKL47utUVTrPocLqVC3o5U0mg0BXz+no3OL7GzDuoMnmbXhMD9sPExy2nmCyvnSt3l1BsfUomuTagT4aeLwFp6QLK4DXjbG9LdfPwtgjPlHAcf/BrxkjJkrIk8DAcaYv9n7PgFmG2OmFfR5miyUW6WfhvWfW+uDn9wLwbWh/WhoO8ora1DlyMo2rNx7nFkbDvPz5sOcOptBcKAfA1rW4MaYWnRuWFXrUpVynpAshgEDjDGj7dcjgY7GmHH5HFsfWAHUMcZkiUg/4CWsVkkQsAr4tzHmrYI+T5OFKhHZWVbX1MoPYO8S8CsPsXdYrY3wZk5H51YZWdks3ZXMrA2JzIk/Str5TKpWKMcN0TUYHFOL9hGhWpuqFCpqsnBnOzq/n5qCMtOdwHRjTBaAMWaOiLQHfgOOAcuBzMs+QGQsMBagXr16rohZqSvz8YWogdbjaLx1X2PDV9ZIqgY9rFFUjft53exwAH9fH3o2Dadn03DSM7JYtP0YP2xMZPqaBP674gA1ggMZFFOTwbG1iK0TovWpvIxHdEOJyDrgUWPMbwWc6wvgv8aYnwr6PG1ZKMecOQ5rp8CqjyE10Spe2OFBaD3Cqn7r5c6cz2T+tiRmbUhk8fZjXMjKpm5oeW6MqcXgmFo0q1lJE4cH84RuKD+sG9y9gUNYN7jvMsbEX3JcU2A2EGnsYOyb45WNMcdFJAb4AmhljLmsdZFDk4VyXFYGbJ1pDb1NWAUBwdD6bmt2eGik09GViJRzGcyJP8KsjYdZtiuZrGxDw7AKdrmRWjQK967SKt7A8WRhBzEQeAdr6OwkY8xrIvIqEGeMmWkf8zIQaIx5Js/7AoG19svTwEPGmPVX+ixNFsqjJKyx7mvEz7DuczS9wbqvEdnN62aHF+R42nl+iT/CrA2JrNx7AmOgWc1gBsfWZHBMLeqGBjkdosJDkkVJ0mShPNLpwxD3CcRNgrPHrfXCOz4IMbeDf9mpzXT0dDo/bjzMrI2JrDtwCoBWdSszOLYWg6JrUiPE+2bKlxaaLJTyJBnpsHm61UV1dBOUD4V291nDb4NrOR1diTp44iw/bjrMrA2JxCeeRgQ6RIRyY2wtBrasQdWKWqeqJGmyUMoTGQP7l8GKD2Dbj9boquY3WaOo6rZ3OroSt/tYGj9sOMzMDYfYfewMvj5C54ZVGRxbi/4tahBSXsuNuJsmC6U83cl9sOojWDsVzqdA7bZW0mh+k1euG34lxhi25dapOsyBE2cp5+vzuzpVFQK8c8a80zRZKFVanE+DDV9aczaO74JKNa3ihW3vgwrVnI6uxBlj2JiQwqwNVkn1I6fTCfT3oXdUdQbH1qRH03AC/bXciKtoslCqtMnOht3zYcX7sHsB+AZAzG1Wa6NGS6ejc0R2tiFu/0lmbUjk582HSU67QMUAP/o1r87g2Fp0aVSNcn7eNwGyJGmyUKo0O7b94uzwjLMQ0dUaetv0Bus+RxmUmZXNij0nchPH6fRMQsr7c0PLGgyOrUWnBlXx1XIjV02ThVLe4NxJWPuZdW8j5SBUrm8NvW19NwSGOB2dYy5kZvPrzmPM2pDI3C1HOXMhi2oVAxgUXYOB0TVpW7+KFjgsIk0WSnmTrEzY/qM19PbAb1CuIrS6yyorUq2R09E5Kj0ji4Xbkpi1MZH5W5M4n5lN5SB/ejQJo3ez6nRvGkawLuJUIE0WSnmrxPVWF9XmbyDrglW4sOND0LBXmZkdXpC085ks3n6M+duOsnBbEifPZuDnI7SPCKV3s3B6N6tOZLUKTofpUTRZKOXt0pKsmeGrP4EzSRAWZc8OvxPKaSmNrGzDugMnmb8tiflbj7LjaBoADcIq0KdZdXpFhdNOu6s0WShVZmSet2pQrfgADq+HwMrQ9l5oPwYq13U6Oo9x8MRZ5m89yvxtSazYc5yMLENwoB89mobTu1k4PZqEExJU9rqrNFkoVdYYAwdXWklj6yxrW9RAaDnM6qrS1kautPOZ/LrjGPO3JbFwWxLHz1zA10doV78KfZpVp3ezcBqElY0KuZoslCrLTh2E1R9Za4efTQb/ICthNL8JmvSHctpvnyMr27D+4CkWbDvK/K1JbDuSCkBktQr0jgqnV7Nw2keE4u+l3VWaLJRSVnn0/csg/jtrrY0zx6ylYBv3hRY3Q+P+EFA2foMuqoMnzrJwexLztiaxYvdxLmRlExzoR/em4fSOCqdH0zAqB3lPORZNFkqp38vOgv2/wZbvYMtM66a4X3lo3Aea3wxNBmjiuMSZ85n8ujOZ+VuPsnB7EslpF/ARaFf/4uiqhmEVSvVKgJoslFIFy86CA8svtjjSjoJfIDTqAy2GWl1VZWBJ2KuRnW3YkHCKBdusVsfWw6cBqF81iN5R1enTLJz2kaWvu0qThVKqaLKz4MCKiy2OtCMXE0fzm6HpAE0c+Th06hwL7GG5v+0+zoXMbCoF+NGtaRi9o8Lp2TScKhU8v7tKk4VS6uplZ8PBFVaLY8v3VuLwDbBbHHZXVWCw01F6nLMXMlm6M5n5W5OYvy2J5LTz+Ai0rV+FXnaro1F4RY/srtJkoZQqnuxsayjuFjtxpB62E0dvu8VxgyaOfGRnGzYdSsmd0xGfaHVX1QsNoldUOH2aVadDZKjHVMvVZKGUcp3sbEhYdbHFkZoIvuWgYW+rxdH0hjJd2PBKDqfkdFclsWxXMuczs6kY4Ee3JtXoHVWdHk3DHF1KVpOFUso9srMhYfXFFsfpQ3bi6HWxxVG+stNReqRzF7JYtiuZ+facjqTU84hAm3pVclsdTaqXbHeVJgullPtlZ8OhuIstjtMJ4ONvJY4WN0PTgZo4CpCdbYhPPM28rUdZsC2JTYdSAKhTpTy9o6xhuR0bhBLg5971SzRZKKVKVnY2HFpzscWRctBOHD2tFkfUQChfxekoPdaRlHQWbEtiwbajLN2VTHpGNhXK+dK1cRi9m4XTMyqcam7ortJkoZRyjjFW4oifYQ3HTTlgJY4GPawWR9QgTRxXcO5CFsv3JDNvaxILtiZx5HQ6ItCqbuXcirlRNSq5pLtKk4VSyjMYA4fWwpYZEP+9nTj8rMTR3E4cQaFOR+mxjLG6q6xhuUfZmGB1V9WuXJ5eUVbF3E4NqhLof23dVZoslFKexxhIXGvf4/gOTtmJI7K73eK4URNHIZJOW91V87clsXRnMucysoiqUYlfnuh2TefTZKGU8mzGQOI6K2nEfwen9tuJo5vV4mg2WBNHIdIzsli++zhnL2QxKKbmNZ1Dk4VSqvQwBg5vuJg4Tu4F8bUSR4ubIWowVKjqdJReSZOFUqp0MgaObLzYVXVij504ul5scVSo5nSUXkOThVKq9DMGjmy62OI4sdtKHBHXWy2OZkM0cRSTJgullHcxBo5uvtjiOL4LxMdKHM3txFExzOkoSx1NFkop72UMHI2/2OI4vtNKHPW7WN1UDXpAtSbggVVePY1HJAsRGQC8C/gCHxtj/nnJ/reBnvbLICDcGFPZ3vc6MAjwAeYCj5srBKvJQqkyyhhI2nKxxZG8w9pesYZ1gzznUaW+s3F6qKImCz83BuAL/BvoCyQAq0VkpjFmS84xxpgn8xz/GNDaft4Z6ALE2LuXAt2BRe6KVylVSolA9RbWo9dzcHIf7FkMe5fAnkWwaZp1XOX60KC7NacjoitUqu5k1KWO25IF0AHYZYzZAyAiXwE3AVsKOH448JL93ACBQDlAAH/gqBtjVUp5iyoR0DYC2t5rtTqObbcSx97FVs2qtZ9Zx4VFXWx1RFyv5UcK4c5kURs4mOd1AtAxvwNFpD4QCSwAMMYsF5GFwGGsZPH/jDFb83nfWGAsQL169VwavFLKC4hAeJT16DjWWkL2yEY7eSyBdf+FVRMBgZqxdvLoDvU6QUBFp6P3KO5MFvndWSronsOdwHRjTBaAiDQCmgF17P1zRaSbMWbJ705mzERgIlj3LFwStVLKe/n4Qq3W1qPL45B5wSp4mJM8Vn4Iv02wZpLXaX+x5VGnPfg5t0CRJ3BnskgA6uZ5XQdILODYO4FH87weCqwwxqQBiMjPQCdgST7vVUqpa+NXDupfZz16/AUunLXWIM9JHkvegMX/Ar/yUK+j1eqI7G61Qnzd+d+n53Hn1a4GGotIJHAIKyHcdelBItIUqAIsz7P5ADBGRP6B1ULpDrzjxliVUgrKBVkLNzXsZb1OT4F9yy4mj/mvWNsDgq1hupHdrJvmYc3AxzPW1HYXtyULY0ymiIwDZmMNnZ1kjIkXkVeBOGPMTPvQ4cBXlwyLnQ70AjZhdV39YoyZ5a5YlVIqX4Eh1qJNUQOt12nHYN+v1s3yvUtgx8/W9qBqVjmSnHseoQ28bo6HTspTSqlrdeqgnTyWWMN1U+2e9uA6v5/jEVLb2TivwCMm5ZUkTRZKKUcZA8d3X2x17F0C505Y+0Ib2nM8ullzPDyonpUmC6WUclJ2NiTFX0wc+5bBhVRrX/WWF7us6neGwGDHwtRkoZRSniQrEw6vt2aV710CB1dCZrpVRbdW64tdVvU6gX/5EgtLk4VSSnmyjHRIWH1xdvmhNZCdCb7loG7Hi8mjdlvw9XdbGJoslFKqNDmfCgdWWIljz2JrHQ8M+Few5oFE2vc8akRbkwtdxPFCgkoppa5CQCVo3Nd6AJw9AfuWXrznMfcFa3tgZauWVWR366Z5CZVi12ShlFKeKCgUmg+xHgCnD1+c47FnCWz7wdpesbq1hsegt9wajiYLpZQqDYJrQszt1gN+X4o9O9PtH6/JQimlSqO8pdhLgHcXM1FKKeUSmiyUUkoVSpOFUkqpQmmyUEopVShNFkoppQqlyUIppVShNFkopZQqlCYLpZRShfKaQoIicgzYX4xTVAOSXRROaVHWrrmsXS/oNZcVxbnm+saYsMIO8ppkUVwiEleUyovepKxdc1m7XtBrLitK4pq1G0oppVShNFkopZQqlCaLiyY6HYADyto1l7XrBb3mssLt16z3LJRSShVKWxZKKaUKVSaShYhMEpEkEdmcZ1uoiMwVkZ32n1Xs7SIiE0Rkl4hsFJE2zkV+7Qq45pdF5JCIrLcfA/Pse9a+5u0i0t+ZqItHROqKyEIR2Soi8SLyuL3da7/rK1yz137XIhIoIqtEZIN9za/Y2yNFZKX9PX8tIuXs7QH26132/ggn479aV7jeKSKyN8933Mre7p6fa2OM1z+AbkAbYHOeba8Dz9jPnwH+ZT8fCPwMCNAJWOl0/C685peBp/I5tjmwAQgAIoHdgK/T13AN11wTaGM/rwTssK/Na7/rK1yz137X9vdV0X7uD6y0v79pwJ329g+Bh+3njwAf2s/vBL52+hpcdL1TgGH5HO+Wn+sy0bIwxiwBTlyy+SbgU/v5p8DNebZ/ZiwrgMoiUrNkInWdAq65IDcBXxljzhtj9gK7gA5uC85NjDGHjTFr7eepwFagNl78XV/hmgtS6r9r+/tKs1/62w8D9AKm29sv/Z5zvv/pQG8RkRIKt9iucL0FccvPdZlIFgWobow5DNY/OCDc3l4bOJjnuASu/I+vtBlnN00n5XTH4IXXbHc1tMb6LaxMfNeXXDN48XctIr4ish5IAuZitZBOGWNyFqPOe12512zvTwGqlmzExXPp9Rpjcr7j1+zv+G0RCbC3ueU7LsvJoiD5/cbhLUPGPgAaAq2Aw8Bb9navumYRqQh8AzxhjDl9pUPz2VYqrzufa/bq79oYk2WMaQXUwWoZNcvvMPvPUn/Nl16viLQEngWigPZAKPAX+3C3XG9ZThZHc5pm9p9J9vYEoG6e4+oAiSUcm1sYY47aP3TZwEdc7H7wmmsWEX+s/zQ/N8Z8a2/26u86v2suC981gDHmFLAIq2++soj42bvyXlfuNdv7Qyh6F61HyXO9A+wuSGOMOQ9Mxs3fcVlOFjOBe+3n9wLf59l+jz2ioBOQktOFUdpd0m85FMgZKTUTuNMeNRIJNAZWlXR8xWX3Q38CbDXGjM+zy2u/64Ku2Zu/axEJE5HK9vPyQB+sezULgWH2YZd+zznf/zBggbHvBJcGBVzvtjy/AAnW/Zm837Hrf66dvtNfEg/gS6ymeAZW1n0Aq89yPrDT/jPUXBx58G+sPtBNQDun43fhNU+1r2mj/QNVM8/xz9nXvB24wen4r/Gar8dqbm8E1tuPgd78XV/hmr32uwZigHX2tW0GXrS3N8BKfLuA/wEB9vZA+/Uue38Dp6/BRde7wP6ONwP/5eKIKbf8XOsMbqWUUoUqy91QSimlikiThVJKqUJpslBKKVUoTRZKKaUKpclCKaVUoTRZKKWUKpQmC+W1RGSIiDzjdByFEZF9IlLNReeaIiLDCj8y3/eG2SW814lIV1fEo7yHX+GHKFU6GWNmYk1IU0XTG9hmjLm30CNVmaMtC1UqiUiEiGwTkY9FZLOIfC4ifURkmb34TQcRGSUi/88+foq9IMxvIrLnSr99i0hNEVliLyizOee3bBH5QETi8i5AY2/fJyJ/F5Hl9v42IjJbRHaLyEP2MT3sc84QkS0i8qGIXPbvT0TuFmuhm/Ui8h+72qivHf9mEdkkIk8W8e+orYgsFpE1djw55SHGiMhqsRbT+UZEgsRaOOd1YKD92eWv5vtQ3k+ThSrNGgHvYpVDiALuwip/8RTwf/kcX9PefyPwzyuc9y5gtrGqfMZildAAeM4Y087+vO4iEpPnPQeNMdcBv2IvSoNV3O7VPMd0AP4ERGNVhL0l74eKSDPgDqCL/dlZwAisyrG1jTEtjTHRWEXjrsguLvge1uI4bYFJwGv27m+NMe2NMbFYNZUeMMasB17EWhiolTHmXGGfocoW7YZSpdleY8wmABGJB+YbY4yIbAIi8jn+O2NVYd0iItWvcN7VwCT7P9zv7P9IAW4XkbFY/25qYq06t9Hel9PdtQmrRk8qkCoi6TlF4IBVxpg9drxfYiWunMV6wOoGagustmrDUR6rQu4soIGIvAf8CMwp7C8GaAq0BOba5/LFqhUG0FJE/gZUBioCs4twPlXGabJQpdn5PM+z87zOJv+f7bzHF7hSmjFmiYh0AwYBU0XkDawWw1NAe2PMSRGZglWg7tJz543j0lguLcR26WsBPjXGPHtpTCISC/QHHgVuB+4vKP4854q3WzuXmgLcbIzZICKjgB6FnEsp7YZS6lIiUh9IMsZ8hFX+uw0QDJwBUuxWyQ3XcOoOIhJp36u4A1h6yf75wDARCbfjCBWR+vZIKR9jzDfAC3Y8hdkOhInIdfa5/EWkhb2vEnDYbjmNuIbrUGWQtiyUulwP4GkRyQDSgHuMMXtFZB0QD+wBll3DeZdj3SuJBpYAM/LuNMZsEZHngTl2QsnAakmcAybnuSF+WcvjUsaYC/ZN/AkiEoL1b/0dO/4XsJZe3Y/VbVbpGq5FlTFaolypEiAiPYCnjDE3Oh2LUtdCu6GUUkoVSlsWqswSkWisFeXyOm+M6ehEPFdDRP4NdLlk87vGmEKH1Sp1LTRZKKWUKpR2QymllCqUJgullFKF0mShlFKqUJoslFJKFUqThVJKqUL9f62IT4/KkKp1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with min_sample_leaf\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_leaf\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gUQn7ygiwAd4"
   },
   "source": [
    "***hypertuning hyperparameter Min Samples Split***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "zkkZBKpLwGpX",
    "outputId": "5e0a41be-7cb7-45d0-87c3-cc6dec9f70b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=10,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'min_samples_split': range(50, 300, 50)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify number of folds for k-fold CV\n",
    "n_folds = 5\n",
    "\n",
    "# parameters to build the model on\n",
    "parameters = {'min_samples_split': range(50, 300, 50)}\n",
    "  \n",
    "# instantiate the model (note we are specifying a max_depth)\n",
    "rf1 = RandomForestClassifier(max_depth=10, class_weight=\"balanced\")\n",
    "rfgs = GridSearchCV(rf1, parameters, \n",
    "                    cv=n_folds, return_train_score=True,\n",
    "                   scoring=\"accuracy\")\n",
    "rfgs.fit(df_train_pca, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "zJOYjfCExTDn",
    "outputId": "92ff1868-71cb-4522-b196-89704bc1451b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.058382</td>\n",
       "      <td>0.102550</td>\n",
       "      <td>0.064116</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_split': 50}</td>\n",
       "      <td>0.875806</td>\n",
       "      <td>0.876761</td>\n",
       "      <td>0.869596</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872361</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903923</td>\n",
       "      <td>0.897355</td>\n",
       "      <td>0.903147</td>\n",
       "      <td>0.895802</td>\n",
       "      <td>0.900167</td>\n",
       "      <td>0.900079</td>\n",
       "      <td>0.003159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.912810</td>\n",
       "      <td>0.068948</td>\n",
       "      <td>0.061389</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_split': 100}</td>\n",
       "      <td>0.857416</td>\n",
       "      <td>0.858849</td>\n",
       "      <td>0.855027</td>\n",
       "      <td>0.850967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>2</td>\n",
       "      <td>0.879740</td>\n",
       "      <td>0.876217</td>\n",
       "      <td>0.882904</td>\n",
       "      <td>0.878247</td>\n",
       "      <td>0.879627</td>\n",
       "      <td>0.879347</td>\n",
       "      <td>0.002186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.803410</td>\n",
       "      <td>0.028911</td>\n",
       "      <td>0.058375</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>150</td>\n",
       "      <td>{'min_samples_split': 150}</td>\n",
       "      <td>0.851445</td>\n",
       "      <td>0.849295</td>\n",
       "      <td>0.840220</td>\n",
       "      <td>0.839264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845992</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>3</td>\n",
       "      <td>0.864692</td>\n",
       "      <td>0.861289</td>\n",
       "      <td>0.868573</td>\n",
       "      <td>0.860512</td>\n",
       "      <td>0.866790</td>\n",
       "      <td>0.864371</td>\n",
       "      <td>0.003099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.759199</td>\n",
       "      <td>0.136453</td>\n",
       "      <td>0.057979</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>200</td>\n",
       "      <td>{'min_samples_split': 200}</td>\n",
       "      <td>0.839026</td>\n",
       "      <td>0.842130</td>\n",
       "      <td>0.835204</td>\n",
       "      <td>0.830428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835913</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>4</td>\n",
       "      <td>0.855437</td>\n",
       "      <td>0.852272</td>\n",
       "      <td>0.853944</td>\n",
       "      <td>0.848749</td>\n",
       "      <td>0.851146</td>\n",
       "      <td>0.852310</td>\n",
       "      <td>0.002301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.564885</td>\n",
       "      <td>0.057454</td>\n",
       "      <td>0.052718</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>250</td>\n",
       "      <td>{'min_samples_split': 250}</td>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.832099</td>\n",
       "      <td>0.829233</td>\n",
       "      <td>0.823262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828604</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>5</td>\n",
       "      <td>0.843673</td>\n",
       "      <td>0.842658</td>\n",
       "      <td>0.844987</td>\n",
       "      <td>0.840509</td>\n",
       "      <td>0.839563</td>\n",
       "      <td>0.842278</td>\n",
       "      <td>0.001997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       4.058382      0.102550         0.064116        0.005752   \n",
       "1       3.912810      0.068948         0.061389        0.004724   \n",
       "2       3.803410      0.028911         0.058375        0.006574   \n",
       "3       3.759199      0.136453         0.057979        0.006735   \n",
       "4       3.564885      0.057454         0.052718        0.001757   \n",
       "\n",
       "  param_min_samples_split                      params  split0_test_score  \\\n",
       "0                      50   {'min_samples_split': 50}           0.875806   \n",
       "1                     100  {'min_samples_split': 100}           0.857416   \n",
       "2                     150  {'min_samples_split': 150}           0.851445   \n",
       "3                     200  {'min_samples_split': 200}           0.839026   \n",
       "4                     250  {'min_samples_split': 250}           0.832816   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0           0.876761           0.869596           0.867925  ...   \n",
       "1           0.858849           0.855027           0.850967  ...   \n",
       "2           0.849295           0.840220           0.839264  ...   \n",
       "3           0.842130           0.835204           0.830428  ...   \n",
       "4           0.832099           0.829233           0.823262  ...   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.872361        0.003434                1            0.903923   \n",
       "1         0.856502        0.003261                2            0.879740   \n",
       "2         0.845992        0.005162                3            0.864692   \n",
       "3         0.835913        0.004214                4            0.855437   \n",
       "4         0.828604        0.003684                5            0.843673   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.897355            0.903147            0.895802   \n",
       "1            0.876217            0.882904            0.878247   \n",
       "2            0.861289            0.868573            0.860512   \n",
       "3            0.852272            0.853944            0.848749   \n",
       "4            0.842658            0.844987            0.840509   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.900167          0.900079         0.003159  \n",
       "1            0.879627          0.879347         0.002186  \n",
       "2            0.866790          0.864371         0.003099  \n",
       "3            0.851146          0.852310         0.002301  \n",
       "4            0.839563          0.842278         0.001997  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores of GridSearch CV\n",
    "scores = rfgs.cv_results_\n",
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pxqqaxCjmcbm",
    "outputId": "3b91867a-26e6-4586-95a9-3799d6e13a57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can get accuracy of 0.8723607220081815 using {'min_samples_split': 50}\n"
     ]
    }
   ],
   "source": [
    "print('We can get accuracy of',rfgs.best_score_,'using',rfgs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "Vpg6viBBxZGF",
    "outputId": "3a92d31f-e9e0-46d0-b433-568ff182ebb3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting accuracies with min_sample_split\n",
    "plt.figure()\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_train_score\"], \n",
    "         label=\"training accuracy\")\n",
    "plt.plot(scores[\"param_min_samples_split\"], \n",
    "         scores[\"mean_test_score\"], \n",
    "         label=\"test accuracy\")\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "om90vkTryHSN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T27tv39Ryede"
   },
   "source": [
    "# Fitting the final model with the best parameters obtained from grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewxDDNr5oMyY"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(bootstrap=True,class_weight=\"balanced\",\n",
    "                             max_depth=10,\n",
    "                             min_samples_leaf=100, \n",
    "                             min_samples_split=50,\n",
    "                             max_features=8,\n",
    "                             n_estimators=350,\n",
    "                             random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "t1a6hFn5pMEh",
    "outputId": "ba1deafc-1f6d-4006-c8b7-69f1f7ce7eaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=10, max_features=8,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=100, min_samples_split=50,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
       "                       n_jobs=None, oob_score=False, random_state=10, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(df_train_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Checking Performance ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "LAt-sghgs9cm",
    "outputId": "838de270-5628-4871-d917-4ba8d4ed5f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model parameters: \n",
      "Accuracy : 0.8494\n",
      "Recall/Sensitivity : 0.8617\n",
      "AUC Score (Train): 0.927490\n"
     ]
    }
   ],
   "source": [
    "dtrain_predict=rfc.predict(df_train_pca)\n",
    "dtrain_predprob = rfc.predict_proba(df_train_pca)[:,1]\n",
    "print(\"Training Model parameters: \")\n",
    "print (\"Accuracy : %.4g\" % metrics.roc_auc_score(y_train, dtrain_predict))\n",
    "print (\"Recall/Sensitivity : %.4g\" % metrics.recall_score(y_train, dtrain_predict))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob))\n",
    "#print(\"Precision : {}\".format(metrics.precision_score(predprob.Churn, predprob.Finalpredicted)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Model Performance on Test Data ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VsE6Qx9jzHlo"
   },
   "outputs": [],
   "source": [
    "predict_test = rfc.predict(df_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "f7lxY67ezgzi",
    "outputId": "aa7499fe-f6a7-490c-f030-3721f4bf5201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on Test data \n",
      "Accuracy : 0.795\n",
      "Recall/Sensitivity : 0.853\n",
      "AUC Score (Train): 0.795009\n"
     ]
    }
   ],
   "source": [
    "print(\"Model performance on Test data \")\n",
    "print (\"Accuracy : %.4g\" % metrics.roc_auc_score(y_test, predict_test))\n",
    "print (\"Recall/Sensitivity : %.4g\" % metrics.recall_score(y_test, predict_test))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_test, predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Notes***\n",
    "    The Model Performs quite satisfactorily in Random Forest as:\n",
    "        1. Accuracy is good in both Training and Test Data sets\n",
    "        2. Recall/Sensitivity is maintained and is above 85% in both Training and Test Data sets\n",
    "        3. AUC score is satisfactory but there is a variation of 20% between Training and Test which we will try to improve once we define the threshold probability and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oz6kzfTt-mD"
   },
   "outputs": [],
   "source": [
    "rfpred_train=pd.DataFrame({'Churn':y_train,'Probs':dtrain_predprob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "lLnKgPgnwJu3",
    "outputId": "6b9d24f4-24e0-4f43-8a3b-8b77907822be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.286831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.939682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.179675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.160300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.061806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn     Probs\n",
       "0      0  0.286831\n",
       "1      1  0.939682\n",
       "2      0  0.179675\n",
       "3      0  0.160300\n",
       "4      0  0.061806"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfpred_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNMBa-9qwNjI"
   },
   "outputs": [],
   "source": [
    "rfpred_train['predicted']=rfpred_train.Probs.map(lambda x:1 if x>0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "uMpeJqE0wfzK",
    "outputId": "0fb00f52-85f4-4315-95f4-19e14d46ec61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Probs</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.286831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.939682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.179675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn     Probs  predicted\n",
       "0      0  0.286831          0\n",
       "1      1  0.939682          1\n",
       "2      0  0.179675          0\n",
       "3      0  0.160300          0\n",
       "4      0  0.061806          0"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfpred_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "mQ00dXUcxB22",
    "outputId": "35934395-fdf2-49a8-9d49-11f86dd56d35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prob  accuracy     sensi     speci\n",
      "0.0   0.0  0.500689  1.000000  0.000000\n",
      "0.1   0.1  0.662240  0.996056  0.327505\n",
      "0.2   0.2  0.750981  0.977579  0.523757\n",
      "0.3   0.3  0.802848  0.951889  0.653396\n",
      "0.4   0.4  0.834732  0.917947  0.751288\n",
      "0.5   0.5  0.849414  0.861688  0.837106\n",
      "0.6   0.6  0.837747  0.775535  0.900130\n",
      "0.7   0.7  0.810280  0.677963  0.942961\n",
      "0.8   0.8  0.749994  0.525171  0.975436\n",
      "0.9   0.9  0.615596  0.234326  0.997918\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "findOptimalCutoff(rfpred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53YTa9t-yPHd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edSHJRCwyQPn"
   },
   "source": [
    "# From the curve above, 0.52 is the optimal point with high enough sensitivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fine tuning/Evaluating the model with Threshold probability of 0.52***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QmzpssiyYqu"
   },
   "outputs": [],
   "source": [
    "rfpred_train['Finalpredicted']=rfpred_train.Probs.map(lambda x:1 if x>0.52 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "mdoFoHUMyvZb",
    "outputId": "ec82d824-6eaf-4abe-efc7-50138180000a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Probs</th>\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>Finalpredicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.286831</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.939682</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.179675</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn     Probs  predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  \\\n",
       "0      0  0.286831          0    1    1    1    0    0    0    0    0    0   \n",
       "1      1  0.939682          1    1    1    1    1    1    1    1    1    1   \n",
       "2      0  0.179675          0    1    1    0    0    0    0    0    0    0   \n",
       "3      0  0.160300          0    1    1    0    0    0    0    0    0    0   \n",
       "4      0  0.061806          0    1    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   0.9  Finalpredicted  \n",
       "0    0               0  \n",
       "1    1               1  \n",
       "2    0               0  \n",
       "3    0               0  \n",
       "4    0               0  "
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfpred_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "XEMnuxf52rwj",
    "outputId": "d549a2a5-a4c6-4662-840b-44cbae527409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     19215\n",
      "           1       0.85      0.85      0.85     19268\n",
      "\n",
      "    accuracy                           0.85     38483\n",
      "   macro avg       0.85      0.85      0.85     38483\n",
      "weighted avg       0.85      0.85      0.85     38483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(rfpred_train.Churn, rfpred_train.Finalpredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DHn9R8lQ3n8z"
   },
   "outputs": [],
   "source": [
    "rfpred_t =rfc.predict_proba(df_test_pca)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8J97vjw3HK0"
   },
   "outputs": [],
   "source": [
    "rfpred_test=pd.DataFrame({'Churn':y_test,'Probs':rfpred_t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "DTh8BQ914HEn",
    "outputId": "7292c131-288d-4e79-e438-1cc4da5fb668"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.279869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.525919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.766447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.543565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.117195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn     Probs\n",
       "0      0  0.279869\n",
       "1      1  0.525919\n",
       "2      0  0.766447\n",
       "3      1  0.543565\n",
       "4      0  0.117195"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfpred_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feMphhgt4Lh6"
   },
   "outputs": [],
   "source": [
    "rfpred_test['Predicted']=rfpred_test.Probs.map(lambda x:1 if x>0.52 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "preDk-z_4bnx",
    "outputId": "39f60a73-50ce-444a-a700-305b356d3623"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Probs</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.279869</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.525919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.766447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.543565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.117195</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn     Probs  Predicted\n",
       "0      0  0.279869          0\n",
       "1      1  0.525919          1\n",
       "2      0  0.766447          1\n",
       "3      1  0.543565          1\n",
       "4      0  0.117195          0"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfpred_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "1hNRYSyM4eIK",
    "outputId": "e4005aad-11fa-4ef3-d6c3-468c3b9b12b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.75      0.79      8273\n",
      "           1       0.77      0.84      0.81      8220\n",
      "\n",
      "    accuracy                           0.80     16493\n",
      "   macro avg       0.80      0.80      0.80     16493\n",
      "weighted avg       0.80      0.80      0.80     16493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(rfpred_test.Churn, rfpred_test.Predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "iCeikUph5Dcx",
    "outputId": "d809278f-65b8-49d0-e307-cb69682be0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model parameters: \n",
      "Accuracy : 0.8493\n",
      "Recall/Sensitivity : 0.8468\n",
      "AUC Score (Train): 0.927490\n",
      "Precision : 0.8513435950952257\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Model parameters: \")\n",
    "print (\"Accuracy : %.4g\" % metrics.roc_auc_score(y_train, rfpred_train.Finalpredicted))\n",
    "print (\"Recall/Sensitivity : %.4g\" % metrics.recall_score(y_train, rfpred_train.Finalpredicted))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob))\n",
    "print(\"Precision : {}\".format(metrics.precision_score(y_train, rfpred_train.Finalpredicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Dz5UWYYb6FsI",
    "outputId": "ae1a2d8e-0cc1-486a-dfc2-6bc023a350f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Model parameters: \n",
      "Accuracy : 0.7979\n",
      "Recall/Sensitivity : 0.8438\n",
      "AUC Score (Test): 0.870826\n",
      "Precision : 0.7716955941255007\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Model parameters: \")\n",
    "print (\"Accuracy : %.4g\" % metrics.roc_auc_score(y_test, rfpred_test.Predicted))\n",
    "print (\"Recall/Sensitivity : %.4g\" % metrics.recall_score(y_test, rfpred_test.Predicted))\n",
    "print (\"AUC Score (Test): %f\" % metrics.roc_auc_score(y_test, rfpred_t))\n",
    "print(\"Precision : {}\".format(metrics.precision_score(y_test, rfpred_test.Predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[6221 2052]\n",
      " [1284 6936]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, rfpred_test.Predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****Notes****\n",
    "    1. Accuracy of model is good in both Training and Test Data sets\n",
    "    2. Recall/Sensitivity is also good and maintained in both Training and Test Data sets\n",
    "    3. Precison is also good as above 70%\n",
    "    4. AUC score of the model has improved to 84.5% post the threshold Probability of 0.52 \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preferred Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression:**\n",
    "        --Accuracy : 0.7347359485842478\n",
    "        --Recall : 0.7838199513381995\n",
    "        --Precision : 0.7126424068134056\n",
    "**Random Forest:** \n",
    "        --Accuracy : 0.7979\n",
    "        --Recall/Sensitivity : 0.8438\n",
    "        --Precision : 0.7716955941255007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preferred Model/ Winner :    Random Forest\n",
    "\n",
    "1. **Random Forest is the preferred Model as Accuracy of the model is better than Logistic Model**\n",
    "2. **The Recall/Sensitivity & Precison factors are also better and maintained in Random Forest\n",
    "3. **The model is not overfitting and is generic as there is no drastic difference between Training and Test Results. So the model performs better on unseen data\n",
    "4. **AUC Score of Model is also good as it is 87%\n",
    "5. **Comparing the f1 scores and Confusion matrices of both logistic and Random Forest Models Random Forest emerges as the clear winner\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model without PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** Building the model on training data sets without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfcnp = RandomForestClassifier(bootstrap=True,class_weight=\"balanced\",\n",
    "                             max_depth=10,\n",
    "                             min_samples_leaf=100, \n",
    "                             min_samples_split=50,\n",
    "                             max_features=8,\n",
    "                             n_estimators=350,\n",
    "                             random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=10, max_features=8,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=100, min_samples_split=50,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
       "                       n_jobs=None, oob_score=False, random_state=10, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcnp.fit(X_train_np,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model parameters-Training Set: \n",
      "Accuracy : 0.919\n",
      "Recall/Sensitivity : 0.9114\n",
      "AUC Score (Train): 0.974261\n"
     ]
    }
   ],
   "source": [
    "dtrain_predict_np=rfcnp.predict(X_train_np)\n",
    "dtrain_predprob_np = rfcnp.predict_proba(X_train_np)[:,1]\n",
    "print(\"Training Model parameters-Training Set: \")\n",
    "print (\"Accuracy : %.4g\" % metrics.roc_auc_score(y_train, dtrain_predict_np))\n",
    "print (\"Recall/Sensitivity : %.4g\" % metrics.recall_score(y_train, dtrain_predict_np))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evluation report on Test Data: \n",
      "Accuracy : 0.9135\n",
      "Recall/Sensitivity : 0.9028\n",
      "AUC Score (Train): 0.970386\n"
     ]
    }
   ],
   "source": [
    "dtest_predict_np=rfcnp.predict(X_test_np)\n",
    "dtest_predprob_np = rfcnp.predict_proba(X_test_np)[:,1]\n",
    "print(\"Evluation report on Test Data: \")\n",
    "print (\"Accuracy : %.4g\" % metrics.roc_auc_score(y_test, dtest_predict_np))\n",
    "print (\"Recall/Sensitivity : %.4g\" % metrics.recall_score(y_test ,dtest_predict_np))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_test, dtest_predprob_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes\n",
    "    1. Model has done very well with Accuracy of 91%\n",
    "    2. Sensitivity of the model is very good approx 90%\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****Deriving feature importance*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.28406129e-04, 1.46933881e-03, 4.99775909e-02, 1.06645913e-03,\n",
       "       1.19060770e-03, 3.76053500e-03, 7.88559306e-04, 1.11976740e-03,\n",
       "       4.60896835e-03, 1.79070852e-03, 1.93241880e-02, 1.42151004e-01,\n",
       "       2.82342698e-03, 2.36997904e-02, 1.46970850e-01, 1.28715924e-03,\n",
       "       3.34782708e-03, 1.92605665e-02, 3.06355989e-03, 3.88396719e-03,\n",
       "       5.55624398e-03, 1.28872254e-03, 1.14078208e-03, 2.08157597e-02,\n",
       "       6.75915442e-03, 5.17215525e-03, 2.74383157e-03, 4.67885679e-03,\n",
       "       1.70227840e-03, 2.67741121e-02, 9.55609555e-04, 2.14797361e-03,\n",
       "       3.33455616e-02, 8.58912093e-04, 2.04809262e-03, 2.33877004e-02,\n",
       "       9.73027147e-04, 1.27485719e-03, 4.48493437e-03, 1.42073412e-03,\n",
       "       2.96178745e-03, 7.63403344e-02, 5.29574932e-03, 1.08817509e-03,\n",
       "       8.37034371e-03, 1.88695311e-03, 6.34319645e-04, 4.68574534e-03,\n",
       "       1.38418725e-03, 7.84641863e-04, 2.72854647e-03, 1.17336010e-03,\n",
       "       2.89634812e-03, 1.19944299e-02, 3.44923205e-04, 1.28900048e-03,\n",
       "       5.18553960e-02, 1.53882013e-03, 1.98838638e-03, 3.41786505e-02,\n",
       "       1.97939775e-03, 3.06894265e-03, 3.44285821e-02, 1.82570034e-03,\n",
       "       2.64333292e-03, 2.78338842e-02, 1.20040173e-03, 2.18236196e-03,\n",
       "       1.42132265e-02, 1.37492546e-03, 1.45509452e-03, 5.83906024e-03,\n",
       "       1.00036596e-03, 1.26076474e-03, 8.28397975e-03, 8.17013409e-04,\n",
       "       1.14378826e-03, 1.02167552e-02, 1.97575998e-06, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.17886092e-03, 8.54015131e-04, 2.48225053e-03,\n",
       "       9.49852812e-04, 1.27472303e-03, 5.06610689e-03, 5.31594133e-04,\n",
       "       4.95524284e-04, 1.71566556e-03, 3.16088047e-04, 7.38318797e-04,\n",
       "       1.15123772e-04, 2.91408135e-03, 4.82000023e-03, 5.23007174e-02,\n",
       "       2.23309280e-03, 1.89962982e-03, 4.00858912e-04, 4.69535011e-04,\n",
       "       5.93217828e-04, 8.68655739e-04, 2.10360117e-03, 3.38462871e-04,\n",
       "       1.09797081e-03, 5.09820424e-04])"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp=rfcnp.feature_importances_\n",
    "imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****mapping column names with importance****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arpu_6 = 0.000428406128694019\n",
      "arpu_7 = 0.001469338809749534\n",
      "arpu_8 = 0.04997759093744338\n",
      "onnet_mou_6 = 0.0010664591255723727\n",
      "onnet_mou_7 = 0.0011906076989066274\n",
      "onnet_mou_8 = 0.003760534995909619\n",
      "offnet_mou_6 = 0.0007885593059849056\n",
      "offnet_mou_7 = 0.0011197673996465522\n",
      "offnet_mou_8 = 0.004608968351902497\n",
      "roam_ic_mou_6 = 0.0017907085242518947\n",
      "roam_ic_mou_7 = 0.01932418799101418\n",
      "roam_ic_mou_8 = 0.14215100384340487\n",
      "roam_og_mou_6 = 0.002823426976749755\n",
      "roam_og_mou_7 = 0.023699790380323636\n",
      "roam_og_mou_8 = 0.14697084992987614\n",
      "loc_og_mou_6 = 0.0012871592444620395\n",
      "loc_og_mou_7 = 0.0033478270757533245\n",
      "loc_og_mou_8 = 0.019260566543982654\n",
      "std_og_mou_6 = 0.003063559885434841\n",
      "std_og_mou_7 = 0.003883967186024259\n",
      "std_og_mou_8 = 0.005556243977794144\n",
      "isd_og_mou_6 = 0.0012887225382097866\n",
      "isd_og_mou_7 = 0.0011407820835001943\n",
      "isd_og_mou_8 = 0.020815759711131705\n",
      "spl_og_mou_6 = 0.006759154416626769\n",
      "spl_og_mou_7 = 0.005172155252757629\n",
      "spl_og_mou_8 = 0.0027438315663630285\n",
      "og_others_6 = 0.004678856789222028\n",
      "og_others_7 = 0.0017022784019672169\n",
      "og_others_8 = 0.02677411207547937\n",
      "total_og_mou_6 = 0.0009556095554990137\n",
      "total_og_mou_7 = 0.00214797360600002\n",
      "total_og_mou_8 = 0.033345561592081546\n",
      "loc_ic_mou_6 = 0.0008589120932630188\n",
      "loc_ic_mou_7 = 0.002048092618519195\n",
      "loc_ic_mou_8 = 0.02338770044172436\n",
      "std_ic_mou_6 = 0.0009730271471843873\n",
      "std_ic_mou_7 = 0.001274857192012496\n",
      "std_ic_mou_8 = 0.004484934372663194\n",
      "total_ic_mou_6 = 0.001420734118494782\n",
      "total_ic_mou_7 = 0.002961787453630681\n",
      "total_ic_mou_8 = 0.07634033436774731\n",
      "spl_ic_mou_6 = 0.005295749322722625\n",
      "spl_ic_mou_7 = 0.0010881750914075873\n",
      "spl_ic_mou_8 = 0.008370343712221888\n",
      "isd_ic_mou_6 = 0.0018869531076647153\n",
      "isd_ic_mou_7 = 0.0006343196447684852\n",
      "isd_ic_mou_8 = 0.004685745344232016\n",
      "ic_others_6 = 0.0013841872464140405\n",
      "ic_others_7 = 0.0007846418629660333\n",
      "ic_others_8 = 0.0027285464664759855\n",
      "total_rech_num_6 = 0.0011733601019935122\n",
      "total_rech_num_7 = 0.0028963481179398514\n",
      "total_rech_num_8 = 0.011994429944571675\n",
      "total_rech_amt_6 = 0.0003449232048335955\n",
      "total_rech_amt_7 = 0.001289000480204327\n",
      "total_rech_amt_8 = 0.05185539597954208\n",
      "max_rech_amt_6 = 0.0015388201284257629\n",
      "max_rech_amt_7 = 0.0019883863837016607\n",
      "max_rech_amt_8 = 0.034178650488380646\n",
      "total_rech_data_6 = 0.001979397754019947\n",
      "total_rech_data_7 = 0.0030689426456023744\n",
      "total_rech_data_8 = 0.0344285820592214\n",
      "max_rech_data_6 = 0.0018257003421222379\n",
      "max_rech_data_7 = 0.002643332915545892\n",
      "max_rech_data_8 = 0.027833884208403985\n",
      "count_rech_2g_6 = 0.0012004017327724877\n",
      "count_rech_2g_7 = 0.002182361963848955\n",
      "count_rech_2g_8 = 0.014213226532918495\n",
      "count_rech_3g_6 = 0.001374925455146684\n",
      "count_rech_3g_7 = 0.0014550945183788705\n",
      "count_rech_3g_8 = 0.005839060243450501\n",
      "vol_2g_mb_6 = 0.0010003659601310897\n",
      "vol_2g_mb_7 = 0.0012607647388504463\n",
      "vol_2g_mb_8 = 0.008283979750134231\n",
      "vol_3g_mb_6 = 0.0008170134090197137\n",
      "vol_3g_mb_7 = 0.0011437882643459234\n",
      "vol_3g_mb_8 = 0.010216755162265577\n",
      "night_pck_user_6 = 1.9757599814280796e-06\n",
      "night_pck_user_7 = 0.0\n",
      "night_pck_user_8 = 0.0\n",
      "monthly_2g_6 = 0.001178860918650319\n",
      "monthly_2g_7 = 0.0008540151307726339\n",
      "monthly_2g_8 = 0.002482250530946055\n",
      "sachet_2g_6 = 0.0009498528119304991\n",
      "sachet_2g_7 = 0.0012747230326319173\n",
      "sachet_2g_8 = 0.005066106890423425\n",
      "monthly_3g_6 = 0.0005315941327581485\n",
      "monthly_3g_7 = 0.0004955242844644428\n",
      "monthly_3g_8 = 0.001715665563693029\n",
      "sachet_3g_6 = 0.00031608804718760095\n",
      "sachet_3g_7 = 0.0007383187974787073\n",
      "sachet_3g_8 = 0.00011512377208791548\n",
      "fb_user_6 = 0.002914081353352586\n",
      "fb_user_7 = 0.004820000227692812\n",
      "fb_user_8 = 0.052300717373213075\n",
      "aon = 0.0022330927999574227\n",
      "aug_vbc_3g = 0.0018996298177419927\n",
      "jul_vbc_3g = 0.0004008589117957976\n",
      "jun_vbc_3g = 0.00046953501056817343\n",
      "sep_vbc_3g = 0.0005932178284611293\n",
      "rech_data_6_total = 0.0008686557394525258\n",
      "rech_data_7_total = 0.0021036011673263508\n",
      "Total rech_6 = 0.00033846287119815527\n",
      "Total rech_7 = 0.0010979708103992583\n",
      "avg_amt_6_7 = 0.0005098204242302779\n"
     ]
    }
   ],
   "source": [
    "#for name, importance in zip(df_cols, imp):\n",
    "for name, importance in zip(df_cols, imp):\n",
    "    print(name, \"=\", importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "featmap=list(zip(df_cols, imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arpu_6', 0.000428406128694019),\n",
       " ('arpu_7', 0.001469338809749534),\n",
       " ('arpu_8', 0.04997759093744338),\n",
       " ('onnet_mou_6', 0.0010664591255723727),\n",
       " ('onnet_mou_7', 0.0011906076989066274),\n",
       " ('onnet_mou_8', 0.003760534995909619),\n",
       " ('offnet_mou_6', 0.0007885593059849056),\n",
       " ('offnet_mou_7', 0.0011197673996465522),\n",
       " ('offnet_mou_8', 0.004608968351902497),\n",
       " ('roam_ic_mou_6', 0.0017907085242518947),\n",
       " ('roam_ic_mou_7', 0.01932418799101418),\n",
       " ('roam_ic_mou_8', 0.14215100384340487),\n",
       " ('roam_og_mou_6', 0.002823426976749755),\n",
       " ('roam_og_mou_7', 0.023699790380323636),\n",
       " ('roam_og_mou_8', 0.14697084992987614),\n",
       " ('loc_og_mou_6', 0.0012871592444620395),\n",
       " ('loc_og_mou_7', 0.0033478270757533245),\n",
       " ('loc_og_mou_8', 0.019260566543982654),\n",
       " ('std_og_mou_6', 0.003063559885434841),\n",
       " ('std_og_mou_7', 0.003883967186024259),\n",
       " ('std_og_mou_8', 0.005556243977794144),\n",
       " ('isd_og_mou_6', 0.0012887225382097866),\n",
       " ('isd_og_mou_7', 0.0011407820835001943),\n",
       " ('isd_og_mou_8', 0.020815759711131705),\n",
       " ('spl_og_mou_6', 0.006759154416626769),\n",
       " ('spl_og_mou_7', 0.005172155252757629),\n",
       " ('spl_og_mou_8', 0.0027438315663630285),\n",
       " ('og_others_6', 0.004678856789222028),\n",
       " ('og_others_7', 0.0017022784019672169),\n",
       " ('og_others_8', 0.02677411207547937),\n",
       " ('total_og_mou_6', 0.0009556095554990137),\n",
       " ('total_og_mou_7', 0.00214797360600002),\n",
       " ('total_og_mou_8', 0.033345561592081546),\n",
       " ('loc_ic_mou_6', 0.0008589120932630188),\n",
       " ('loc_ic_mou_7', 0.002048092618519195),\n",
       " ('loc_ic_mou_8', 0.02338770044172436),\n",
       " ('std_ic_mou_6', 0.0009730271471843873),\n",
       " ('std_ic_mou_7', 0.001274857192012496),\n",
       " ('std_ic_mou_8', 0.004484934372663194),\n",
       " ('total_ic_mou_6', 0.001420734118494782),\n",
       " ('total_ic_mou_7', 0.002961787453630681),\n",
       " ('total_ic_mou_8', 0.07634033436774731),\n",
       " ('spl_ic_mou_6', 0.005295749322722625),\n",
       " ('spl_ic_mou_7', 0.0010881750914075873),\n",
       " ('spl_ic_mou_8', 0.008370343712221888),\n",
       " ('isd_ic_mou_6', 0.0018869531076647153),\n",
       " ('isd_ic_mou_7', 0.0006343196447684852),\n",
       " ('isd_ic_mou_8', 0.004685745344232016),\n",
       " ('ic_others_6', 0.0013841872464140405),\n",
       " ('ic_others_7', 0.0007846418629660333),\n",
       " ('ic_others_8', 0.0027285464664759855),\n",
       " ('total_rech_num_6', 0.0011733601019935122),\n",
       " ('total_rech_num_7', 0.0028963481179398514),\n",
       " ('total_rech_num_8', 0.011994429944571675),\n",
       " ('total_rech_amt_6', 0.0003449232048335955),\n",
       " ('total_rech_amt_7', 0.001289000480204327),\n",
       " ('total_rech_amt_8', 0.05185539597954208),\n",
       " ('max_rech_amt_6', 0.0015388201284257629),\n",
       " ('max_rech_amt_7', 0.0019883863837016607),\n",
       " ('max_rech_amt_8', 0.034178650488380646),\n",
       " ('total_rech_data_6', 0.001979397754019947),\n",
       " ('total_rech_data_7', 0.0030689426456023744),\n",
       " ('total_rech_data_8', 0.0344285820592214),\n",
       " ('max_rech_data_6', 0.0018257003421222379),\n",
       " ('max_rech_data_7', 0.002643332915545892),\n",
       " ('max_rech_data_8', 0.027833884208403985),\n",
       " ('count_rech_2g_6', 0.0012004017327724877),\n",
       " ('count_rech_2g_7', 0.002182361963848955),\n",
       " ('count_rech_2g_8', 0.014213226532918495),\n",
       " ('count_rech_3g_6', 0.001374925455146684),\n",
       " ('count_rech_3g_7', 0.0014550945183788705),\n",
       " ('count_rech_3g_8', 0.005839060243450501),\n",
       " ('vol_2g_mb_6', 0.0010003659601310897),\n",
       " ('vol_2g_mb_7', 0.0012607647388504463),\n",
       " ('vol_2g_mb_8', 0.008283979750134231),\n",
       " ('vol_3g_mb_6', 0.0008170134090197137),\n",
       " ('vol_3g_mb_7', 0.0011437882643459234),\n",
       " ('vol_3g_mb_8', 0.010216755162265577),\n",
       " ('night_pck_user_6', 1.9757599814280796e-06),\n",
       " ('night_pck_user_7', 0.0),\n",
       " ('night_pck_user_8', 0.0),\n",
       " ('monthly_2g_6', 0.001178860918650319),\n",
       " ('monthly_2g_7', 0.0008540151307726339),\n",
       " ('monthly_2g_8', 0.002482250530946055),\n",
       " ('sachet_2g_6', 0.0009498528119304991),\n",
       " ('sachet_2g_7', 0.0012747230326319173),\n",
       " ('sachet_2g_8', 0.005066106890423425),\n",
       " ('monthly_3g_6', 0.0005315941327581485),\n",
       " ('monthly_3g_7', 0.0004955242844644428),\n",
       " ('monthly_3g_8', 0.001715665563693029),\n",
       " ('sachet_3g_6', 0.00031608804718760095),\n",
       " ('sachet_3g_7', 0.0007383187974787073),\n",
       " ('sachet_3g_8', 0.00011512377208791548),\n",
       " ('fb_user_6', 0.002914081353352586),\n",
       " ('fb_user_7', 0.004820000227692812),\n",
       " ('fb_user_8', 0.052300717373213075),\n",
       " ('aon', 0.0022330927999574227),\n",
       " ('aug_vbc_3g', 0.0018996298177419927),\n",
       " ('jul_vbc_3g', 0.0004008589117957976),\n",
       " ('jun_vbc_3g', 0.00046953501056817343),\n",
       " ('sep_vbc_3g', 0.0005932178284611293),\n",
       " ('rech_data_6_total', 0.0008686557394525258),\n",
       " ('rech_data_7_total', 0.0021036011673263508),\n",
       " ('Total rech_6', 0.00033846287119815527),\n",
       " ('Total rech_7', 0.0010979708103992583),\n",
       " ('avg_amt_6_7', 0.0005098204242302779)]"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_Tuple(tup):  \n",
    "    return(sorted(tup, key = lambda x: x[1],reverse=True))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sorting Feature Names based on importance in descending order***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('roam_og_mou_8', 0.14697084992987614),\n",
       " ('roam_ic_mou_8', 0.14215100384340487),\n",
       " ('total_ic_mou_8', 0.07634033436774731),\n",
       " ('fb_user_8', 0.052300717373213075),\n",
       " ('total_rech_amt_8', 0.05185539597954208),\n",
       " ('arpu_8', 0.04997759093744338),\n",
       " ('total_rech_data_8', 0.0344285820592214),\n",
       " ('max_rech_amt_8', 0.034178650488380646),\n",
       " ('total_og_mou_8', 0.033345561592081546),\n",
       " ('max_rech_data_8', 0.027833884208403985),\n",
       " ('og_others_8', 0.02677411207547937),\n",
       " ('roam_og_mou_7', 0.023699790380323636),\n",
       " ('loc_ic_mou_8', 0.02338770044172436),\n",
       " ('isd_og_mou_8', 0.020815759711131705),\n",
       " ('roam_ic_mou_7', 0.01932418799101418),\n",
       " ('loc_og_mou_8', 0.019260566543982654),\n",
       " ('count_rech_2g_8', 0.014213226532918495),\n",
       " ('total_rech_num_8', 0.011994429944571675),\n",
       " ('vol_3g_mb_8', 0.010216755162265577),\n",
       " ('spl_ic_mou_8', 0.008370343712221888),\n",
       " ('vol_2g_mb_8', 0.008283979750134231),\n",
       " ('spl_og_mou_6', 0.006759154416626769),\n",
       " ('count_rech_3g_8', 0.005839060243450501),\n",
       " ('std_og_mou_8', 0.005556243977794144),\n",
       " ('spl_ic_mou_6', 0.005295749322722625),\n",
       " ('spl_og_mou_7', 0.005172155252757629),\n",
       " ('sachet_2g_8', 0.005066106890423425),\n",
       " ('fb_user_7', 0.004820000227692812),\n",
       " ('isd_ic_mou_8', 0.004685745344232016),\n",
       " ('og_others_6', 0.004678856789222028),\n",
       " ('offnet_mou_8', 0.004608968351902497),\n",
       " ('std_ic_mou_8', 0.004484934372663194),\n",
       " ('std_og_mou_7', 0.003883967186024259),\n",
       " ('onnet_mou_8', 0.003760534995909619),\n",
       " ('loc_og_mou_7', 0.0033478270757533245),\n",
       " ('total_rech_data_7', 0.0030689426456023744),\n",
       " ('std_og_mou_6', 0.003063559885434841),\n",
       " ('total_ic_mou_7', 0.002961787453630681),\n",
       " ('fb_user_6', 0.002914081353352586),\n",
       " ('total_rech_num_7', 0.0028963481179398514),\n",
       " ('roam_og_mou_6', 0.002823426976749755),\n",
       " ('spl_og_mou_8', 0.0027438315663630285),\n",
       " ('ic_others_8', 0.0027285464664759855),\n",
       " ('max_rech_data_7', 0.002643332915545892),\n",
       " ('monthly_2g_8', 0.002482250530946055),\n",
       " ('aon', 0.0022330927999574227),\n",
       " ('count_rech_2g_7', 0.002182361963848955),\n",
       " ('total_og_mou_7', 0.00214797360600002),\n",
       " ('rech_data_7_total', 0.0021036011673263508),\n",
       " ('loc_ic_mou_7', 0.002048092618519195),\n",
       " ('max_rech_amt_7', 0.0019883863837016607),\n",
       " ('total_rech_data_6', 0.001979397754019947),\n",
       " ('aug_vbc_3g', 0.0018996298177419927),\n",
       " ('isd_ic_mou_6', 0.0018869531076647153),\n",
       " ('max_rech_data_6', 0.0018257003421222379),\n",
       " ('roam_ic_mou_6', 0.0017907085242518947),\n",
       " ('monthly_3g_8', 0.001715665563693029),\n",
       " ('og_others_7', 0.0017022784019672169),\n",
       " ('max_rech_amt_6', 0.0015388201284257629),\n",
       " ('arpu_7', 0.001469338809749534),\n",
       " ('count_rech_3g_7', 0.0014550945183788705),\n",
       " ('total_ic_mou_6', 0.001420734118494782),\n",
       " ('ic_others_6', 0.0013841872464140405),\n",
       " ('count_rech_3g_6', 0.001374925455146684),\n",
       " ('total_rech_amt_7', 0.001289000480204327),\n",
       " ('isd_og_mou_6', 0.0012887225382097866),\n",
       " ('loc_og_mou_6', 0.0012871592444620395),\n",
       " ('std_ic_mou_7', 0.001274857192012496),\n",
       " ('sachet_2g_7', 0.0012747230326319173),\n",
       " ('vol_2g_mb_7', 0.0012607647388504463),\n",
       " ('count_rech_2g_6', 0.0012004017327724877),\n",
       " ('onnet_mou_7', 0.0011906076989066274),\n",
       " ('monthly_2g_6', 0.001178860918650319),\n",
       " ('total_rech_num_6', 0.0011733601019935122),\n",
       " ('vol_3g_mb_7', 0.0011437882643459234),\n",
       " ('isd_og_mou_7', 0.0011407820835001943),\n",
       " ('offnet_mou_7', 0.0011197673996465522),\n",
       " ('Total rech_7', 0.0010979708103992583),\n",
       " ('spl_ic_mou_7', 0.0010881750914075873),\n",
       " ('onnet_mou_6', 0.0010664591255723727),\n",
       " ('vol_2g_mb_6', 0.0010003659601310897),\n",
       " ('std_ic_mou_6', 0.0009730271471843873),\n",
       " ('total_og_mou_6', 0.0009556095554990137),\n",
       " ('sachet_2g_6', 0.0009498528119304991),\n",
       " ('rech_data_6_total', 0.0008686557394525258),\n",
       " ('loc_ic_mou_6', 0.0008589120932630188),\n",
       " ('monthly_2g_7', 0.0008540151307726339),\n",
       " ('vol_3g_mb_6', 0.0008170134090197137),\n",
       " ('offnet_mou_6', 0.0007885593059849056),\n",
       " ('ic_others_7', 0.0007846418629660333),\n",
       " ('sachet_3g_7', 0.0007383187974787073),\n",
       " ('isd_ic_mou_7', 0.0006343196447684852),\n",
       " ('sep_vbc_3g', 0.0005932178284611293),\n",
       " ('monthly_3g_6', 0.0005315941327581485),\n",
       " ('avg_amt_6_7', 0.0005098204242302779),\n",
       " ('monthly_3g_7', 0.0004955242844644428),\n",
       " ('jun_vbc_3g', 0.00046953501056817343),\n",
       " ('arpu_6', 0.000428406128694019),\n",
       " ('jul_vbc_3g', 0.0004008589117957976),\n",
       " ('total_rech_amt_6', 0.0003449232048335955),\n",
       " ('Total rech_6', 0.00033846287119815527),\n",
       " ('sachet_3g_6', 0.00031608804718760095),\n",
       " ('sachet_3g_8', 0.00011512377208791548),\n",
       " ('night_pck_user_6', 1.9757599814280796e-06),\n",
       " ('night_pck_user_7', 0.0),\n",
       " ('night_pck_user_8', 0.0)]"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sort_Tuple(featmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing data frame with Features & importances\n",
    "df_feat=pd.DataFrame(imp,index=df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arpu_6</th>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_7</th>\n",
       "      <td>0.001469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_8</th>\n",
       "      <td>0.049978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <td>0.001191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "arpu_6       0.000428\n",
       "arpu_7       0.001469\n",
       "arpu_8       0.049978\n",
       "onnet_mou_6  0.001066\n",
       "onnet_mou_7  0.001191"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the dataframe based on feature importance\n",
    "final_df = df_feat.sort_values(by=[0], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <td>0.146971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <td>0.142151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <td>0.076340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_user_8</th>\n",
       "      <td>0.052301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <td>0.051855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "roam_og_mou_8     0.146971\n",
       "roam_ic_mou_8     0.142151\n",
       "total_ic_mou_8    0.076340\n",
       "fb_user_8         0.052301\n",
       "total_rech_amt_8  0.051855"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deriving top 21 variables\n",
    "\n",
    "final=final_df[:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <td>0.146971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_8</th>\n",
       "      <td>0.142151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_ic_mou_8</th>\n",
       "      <td>0.076340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb_user_8</th>\n",
       "      <td>0.052301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <td>0.051855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arpu_8</th>\n",
       "      <td>0.049978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_data_8</th>\n",
       "      <td>0.034429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_amt_8</th>\n",
       "      <td>0.034179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <td>0.033346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_rech_data_8</th>\n",
       "      <td>0.027834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>og_others_8</th>\n",
       "      <td>0.026774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <td>0.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_ic_mou_8</th>\n",
       "      <td>0.023388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isd_og_mou_8</th>\n",
       "      <td>0.020816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roam_ic_mou_7</th>\n",
       "      <td>0.019324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_og_mou_8</th>\n",
       "      <td>0.019261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rech_2g_8</th>\n",
       "      <td>0.014213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rech_num_8</th>\n",
       "      <td>0.011994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <td>0.010217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spl_ic_mou_8</th>\n",
       "      <td>0.008370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <td>0.008284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "roam_og_mou_8      0.146971\n",
       "roam_ic_mou_8      0.142151\n",
       "total_ic_mou_8     0.076340\n",
       "fb_user_8          0.052301\n",
       "total_rech_amt_8   0.051855\n",
       "arpu_8             0.049978\n",
       "total_rech_data_8  0.034429\n",
       "max_rech_amt_8     0.034179\n",
       "total_og_mou_8     0.033346\n",
       "max_rech_data_8    0.027834\n",
       "og_others_8        0.026774\n",
       "roam_og_mou_7      0.023700\n",
       "loc_ic_mou_8       0.023388\n",
       "isd_og_mou_8       0.020816\n",
       "roam_ic_mou_7      0.019324\n",
       "loc_og_mou_8       0.019261\n",
       "count_rech_2g_8    0.014213\n",
       "total_rech_num_8   0.011994\n",
       "vol_3g_mb_8        0.010217\n",
       "spl_ic_mou_8       0.008370\n",
       "vol_2g_mb_8        0.008284"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting Bar Graph- Visual Analysis of Important Feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1414f57f0>"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "final.plot.bar() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the top main predictiors of churn are the monthly KPI features for the action phase (3rd month August)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above suggest that the top 25 features ranked in order of importance as produced by our RandomForest implementation are the features that belong to month 8 i.e., the action month. Hence, it is clear that what happens in the action phase has a direct impact on the customer churn of high value customers. Specifically, these features are as follows:\n",
    "\n",
    "1.\t**roam_og_mou_8**\t\t-- *outgoing roaming calls minutes of usage in month 8*\n",
    "2.\t**roam_ic_mou_8**\t\t-- *incoming roaming calls minutes of usage in month 8*\n",
    "3.\t**total_ic_mou_8**\t\t-- *Total incoming minutes of usage in month 8*\n",
    "4.\t**fb_user_8**\t\t\t-- *services of Facebook and similar social networking sites for month 8*\n",
    "5.\t**total_rech_amt_8**\t-- *total recharge amount in month 8*\n",
    "6.\t**arpu_8**\t\t\t\t-- *average revenue per user in month 8*\n",
    "7.\t**total_rech_data_8**\t-- *total data recharge (MB) in month 8*\n",
    "8.\t**max_rech_amt_8**\t\t-- *maximum recharge amount in month 8*\n",
    "9.  **total_og_mou_8**      -- *total outgoing calls minutes of usage in month 8*\n",
    "10.\t**max_rech_amt_8**\t\t-- *maximum recharge amount in month 8*\n",
    "11. **og_others_8**\n",
    "12. **roam_og_mou_7**       -- *outgoing roaming calls minutes of usage in month 7*\n",
    "13. **loc_ic_mou_8**\t\t-- *local incoming minutes of usage in month 8*\n",
    "14. **isd_og_mou_8**        -- *outgoing ISD minutes of usage in month 8*\n",
    "15. **roam_ic_mou_7**       -- *incoming roaming calls minutes of usage in month 8*\n",
    "16.\t**loc_og_mou_8**\t\t-- *local outgoing calls minutes of usage in month 8*\n",
    "17. **count_rech_2g_8**     -- *Number of 2g data recharge in month 8*\n",
    "18. **total_rech_num_8**    -- *total number of recharges done in the month 8*\n",
    "19. **vol_3g_mb_8**         -- *volume of 3G data (MB) consumed for month 8*\n",
    "20. **spl_ic_mou_8**        -- *Special incoming call for the month of 7*\n",
    "21. **vol_2g_mb_8**         -- *volume of 2G data (MB) consumed for month 8*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    " 1. **Local& Roaming calls Mou's be it incoming or outgoing have a very important role for churn predictions.**\n",
    " 2. **Reduction in these KPI's forms a clear indicator of churn.**\n",
    " 3. **Overall, drop in any of these indicator KPI is a signal that the customer is not actively engaging in the services offered by the Network operator and thus may choose to churn in the near future.**\n",
    " 4. **Data Usage and Social Networking sites packages also are a vital factor in retaining customers**\n",
    " \n",
    "    *Next, we will look at some of the stratergic steps which can be taken to retain these predicted churners.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategies to Manage customer churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Monitoring Drop in usage**\n",
    "\n",
    "   --*Telecom company should pay close attention to drop in MoU, ARPU and data usage (2g and 3g) month over month. If feasible, the company should track these numbers week over week. Since billing cycles are typically monthly, a drop in usage numbers will give the company time to react when tracked at weekly level.\n",
    "   --*Contact these customers proactively to find out what's affecting their experience. \n",
    "   --*offer them attractive data recharge coupons or other incentives to continue to use the services, while the company fixes the issues reported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Improving Outgoing services**\n",
    "\n",
    "1. --*The Network operators must futher investigate their outgoing tariffs, plans and campaigns.\n",
    "2. --*There could be a possibility that the outgoing tariffs offered to it's customer are less competitive to the outgoing tariffs of their competitor.\n",
    "3. --*Attractive offers like Discounted outgoing rates during particular hours of the day for these customers or For every X mou, grant customer with some % of X free mou.*\n",
    "4. --*Free monthly outgoing mou's depending on the users past roaming mou usage.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Improving Roaming services**\n",
    "\n",
    "1. --*Churners show higher roaming usage than non-churners.*\n",
    "2. --*The Network operators must futher investigate their roaming tariffs, and quality of service.*\n",
    "3. --*Might be that the roaming tariffs offered are less competitive than their competitor.\n",
    "4. --*It might be that the customer is not getting good quality of service while roaming. In this case, quality of service guarantees with roaming partners and network quality need to be investigated.*\n",
    "5. --*New campaigns which targets the roaming customers can be rolled out. Like Discounted roaming rates during particular hours of the day or Free monthly roaming mou's depending on the users past roaming mou usage.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Offer Attractive packages and monthly recharge plans for \n",
    "        --*2G & 3G Data Recharge packs*\n",
    "        --*Facebook an other scoial Networking Sites*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Telecom_Churn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
